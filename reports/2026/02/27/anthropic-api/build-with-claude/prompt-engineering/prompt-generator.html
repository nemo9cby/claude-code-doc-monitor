<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>build-with-claude/prompt-engineering/prompt-generator - Diff Report</title>
    <link rel="stylesheet" href="../../css/diff.css">
    <style>
        :root {
            --bg-color: #1a1a2e;
            --card-bg: #16213e;
            --text-color: #eee;
            --accent: #0f3460;
            --add-bg: #1a4d1a;
            --del-bg: #4d1a1a;
            --add-text: #4ade80;
            --del-text: #f87171;
        }
        @media (prefers-color-scheme: light) {
            :root {
                --bg-color: #f5f5f5;
                --card-bg: #fff;
                --text-color: #333;
                --accent: #e0e0e0;
                --add-bg: #d4edda;
                --del-bg: #f8d7da;
                --add-text: #155724;
                --del-text: #721c24;
            }
        }
        * { box-sizing: border-box; margin: 0; padding: 0; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: var(--bg-color);
            color: var(--text-color);
            line-height: 1.6;
            padding: 2rem;
        }
        .container { max-width: 1200px; margin: 0 auto; }
        header { margin-bottom: 2rem; }
        h1 { font-size: 1.5rem; margin-bottom: 0.5rem; }
        .meta { color: #888; font-size: 0.9rem; }
        .summary {
            background: var(--card-bg);
            padding: 1rem;
            border-radius: 8px;
            margin-bottom: 2rem;
            display: flex;
            gap: 2rem;
        }
        .stat { display: flex; align-items: center; gap: 0.5rem; }
        .stat.added { color: var(--add-text); }
        .stat.removed { color: var(--del-text); }
        .analysis {
            background: var(--card-bg);
            padding: 1.5rem;
            border-radius: 8px;
            margin-bottom: 2rem;
            border-left: 4px solid #8b5cf6;
        }
        .analysis-header {
            font-weight: 600;
            margin-bottom: 0.75rem;
            color: #8b5cf6;
        }
        .analysis-content {
            white-space: pre-wrap;
            font-size: 0.95rem;
            line-height: 1.7;
        }
        .diff-container {
            background: var(--card-bg);
            border-radius: 8px;
            overflow: hidden;
        }
        .diff-header {
            background: var(--accent);
            padding: 0.75rem 1rem;
            font-weight: 600;
        }
        .diff-content {
            padding: 1rem;
            overflow-x: auto;
        }
        .diff-content ins {
            background: var(--add-bg);
            color: var(--add-text);
            text-decoration: none;
            padding: 0.1em 0.2em;
            border-radius: 2px;
        }
        .diff-content del {
            background: var(--del-bg);
            color: var(--del-text);
            text-decoration: line-through;
            padding: 0.1em 0.2em;
            border-radius: 2px;
        }
        pre {
            background: var(--accent);
            padding: 1rem;
            border-radius: 8px;
            overflow-x: auto;
            font-size: 0.85rem;
            margin-top: 2rem;
        }
        a { color: #60a5fa; }
        .back-link { margin-bottom: 1rem; display: inline-block; }
    </style>
</head>
<body>
    <div class="container">
        <a href="../../../index.html" class="back-link">&larr; Back to daily report</a>

        <header>
            <h1>build-with-claude/prompt-engineering/prompt-generator.md</h1>
            <p class="meta">Changed on 2026-02-27 15:22:26 EST</p>
        </header>

        <div class="summary">
            <div class="stat added">
                <span>+0</span> lines added
            </div>
            <div class="stat removed">
                <span>-0</span> lines removed
            </div>
        </div>

        

        <div class="diff-container">
            <div class="diff-header">Visual Diff</div>
            <div class="diff-content"><span># Console prompting tools&para;<br>&para;<br>---&para;<br>&para;<br>The Claude Console offers a suite of tools to help you build and refine prompts. This page walks through them in the order you'll typically use them: generating a first draft, adding templates and variables, then improving an existing prompt.&para;<br>&para;<br>---&para;<br>&para;<br>## Prompt generator&para;<br>&para;<br>&lt;Note&gt;&para;<br>The prompt generator is compatible with all Claude models, including those with extended thinking capabilities. For prompting tips specific to extended thinking models, see the [extended thinking prompting tips](/docs/en/build-with-claude/prompt-engineering/claude-prompting-best-practices#leverage-thinking-and-interleaved-thinking-capabilities).&para;<br>&lt;/Note&gt;&para;<br>&para;<br>Sometimes, the hardest part of using an AI model is figuring out how to prompt it effectively. The prompt generator guides Claude to create high-quality prompt templates tailored to your specific tasks, following many of our prompt engineering best practices.&para;<br>&para;<br>The prompt generator is particularly useful for solving the "blank page problem"â€”it gives you a jumping-off point for further testing and iteration.&para;<br>&para;<br>&lt;Tip&gt;Try the prompt generator now directly on the [Console](/dashboard).&lt;/Tip&gt;&para;<br>&para;<br>If you're interested in analyzing the underlying prompt and architecture, check out our [prompt generator Google Colab notebook](https://anthropic.com/metaprompt-notebook/). To run the Colab notebook, you'll need an [API key](/settings/keys).&para;<br>&para;<br>---&para;<br>&para;<br>## Prompt templates and variables&para;<br>&para;<br>When deploying an LLM-based application with Claude, your API calls will typically consist of two types of content:&para;<br>- **Fixed content:** Static instructions or context that remain constant across multiple interactions&para;<br>- **Variable content:** Dynamic elements that change with each request or conversation, such as:&para;<br>    - User inputs&para;<br>    - Retrieved content for Retrieval-Augmented Generation (RAG)&para;<br>    - Conversation context such as user account history&para;<br>    - System-generated data such as tool use results fed in from other independent calls to Claude&para;<br>&para;<br>A **prompt template** combines these fixed and variable parts, using placeholders for the dynamic content. In the [Claude Console](/), these placeholders are denoted with **\{\{double brackets\}\}**, making them easily identifiable and allowing for quick testing of different values.&para;<br>&para;<br>You should use prompt templates and variables when you expect any part of your prompt to be repeated in another call to Claude (via the API or the [Claude Console](/). [claude.ai](https://claude.ai/) currently does not support prompt templates or variables).&para;<br>&para;<br>Prompt templates offer several benefits:&para;<br>- **Consistency:** Ensure a consistent structure for your prompts across multiple interactions&para;<br>- **Efficiency:** Easily swap out variable content without rewriting the entire prompt&para;<br>- **Testability:** Quickly test different inputs and edge cases by changing only the variable portion&para;<br>- **Scalability:** Simplify prompt management as your application grows in complexity&para;<br>- **Version control:** Easily track changes to your prompt structure over time by keeping tabs only on the core part of your prompt, separate from dynamic inputs&para;<br>&para;<br>The Console uses prompt templates and variables to power its tooling:&para;<br>- **Prompt generator:** Decides what variables your prompt needs and includes them in the template it outputs&para;<br>- **Prompt improver:** Takes your existing template, including all variables, and maintains them in the improved template it outputs&para;<br>- **[Evaluation tool](/docs/en/test-and-evaluate/eval-tool):** Allows you to easily test, scale, and track versions of your prompts by separating the variable and fixed portions of your prompt template&para;<br>&para;<br>### Example prompt template&para;<br>&para;<br>Consider a simple application that translates English text to Spanish. The translated text would be variable since it changes between users or calls to Claude. You might use this prompt template:&para;<br>&para;<br>```</span><ins style="background:#e6ffe6;">text</ins><span>&para;<br>Translate this text from English to Spanish: {{text}}&para;<br>```&para;<br>&para;<br>&lt;Tip&gt;To level up your prompt variables, wrap them in [XML tags](/docs/en/build-with-claude/prompt-engineering/claude-prompting-best-practices#structure-prompts-with-xml-tags) for clearer structure.&lt;/Tip&gt;&para;<br>&para;<br>---&para;<br>&para;<br>## Prompt improver&para;<br>&para;<br>&lt;Note&gt;&para;<br>The prompt improver is compatible with all Claude models, including those with extended thinking capabilities. For prompting tips specific to extended thinking models, see the [extended thinking prompting tips](/docs/en/build-with-claude/prompt-engineering/claude-prompting-best-practices#leverage-thinking-and-interleaved-thinking-capabilities).&para;<br>&lt;/Note&gt;&para;<br>&para;<br>The prompt improver helps you quickly iterate and improve your prompts through automated analysis and enhancement. It excels at making prompts more robust for complex tasks that require high accuracy.&para;<br>&para;<br>&lt;Frame&gt;&para;<br>  ![Image](/docs/images/prompt_improver.png)&para;<br>&lt;/Frame&gt;&para;<br>&para;<br>### Before you begin&para;<br>&para;<br>You'll need:&para;<br>- A prompt template (see [Prompt templates and variables](#prompt-templates-and-variables) above)&para;<br>- Feedback on current issues with Claude's outputs (optional but recommended)&para;<br>- Example inputs and ideal outputs (optional but recommended)&para;<br>&para;<br>### How the prompt improver works&para;<br>&para;<br>The prompt improver enhances your prompts in 4 steps:&para;<br>&para;<br>1. **Example identification**: Locates and extracts examples from your prompt template&para;<br>2. **Initial draft**: Creates a structured template with clear sections and XML tags&para;<br>3. **Chain of thought refinement**: Adds and refines detailed reasoning instructions&para;<br>4. **Example enhancement**: Updates examples to demonstrate the new reasoning process&para;<br>&para;<br>You can watch these steps happen in real-time in the improvement modal.&para;<br>&para;<br>### What you get&para;<br>&para;<br>The prompt improver generates templates with:&para;<br>- Detailed chain-of-thought instructions that guide Claude's reasoning process and typically improve its performance&para;<br>- Clear organization using XML tags to separate different components&para;<br>- Standardized example formatting that demonstrates step-by-step reasoning from input to output&para;<br>- Strategic prefills that guide Claude's initial responses&para;<br>&para;<br>&lt;Note&gt;&para;<br>While examples appear separately in the Workbench UI, they're included at the start of the first user message in the actual API call. View the raw format by clicking "**\&lt;\/\&gt; Get Code**" or insert examples as raw text via the Examples box.&para;<br>&lt;/Note&gt;&para;<br>&para;<br>### How to use the prompt improver&para;<br>&para;<br>1. Submit your prompt template&para;<br>2. Add any feedback about issues with Claude's current outputs (e.g., "summaries are too basic for expert audiences")&para;<br>3. Include example inputs and ideal outputs&para;<br>4. Review the improved prompt&para;<br>&para;<br>### Generate test examples&para;<br>&para;<br>Don't have examples yet? Use the [Test Case Generator](/docs/en/test-and-evaluate/eval-tool#creating-test-cases) to:&para;<br>1. Generate sample inputs&para;<br>2. Get Claude's responses&para;<br>3. Edit the responses to match your ideal outputs&para;<br>4. Add the polished examples to your prompt&para;<br>&para;<br>### When to use the prompt improver&para;<br>&para;<br>The prompt improver works best for:&para;<br>- Complex tasks requiring detailed reasoning&para;<br>- Situations where accuracy is more important than speed&para;<br>- Problems where Claude's current outputs need significant improvement&para;<br>&para;<br>&lt;Note&gt;&para;<br>For latency or cost-sensitive applications, consider using simpler prompts. The prompt improver creates templates that produce longer, more thorough, but slower responses.&para;<br>&lt;/Note&gt;&para;<br>&para;<br>### Example improvement&para;<br>&para;<br>Here's how the prompt improver enhances a basic classification prompt:&para;<br>&para;<br>&lt;section title="Original prompt"&gt;&para;<br>&para;<br>```text&para;<br>From the following list of Wikipedia article titles, identify which article this sentence came from.&para;<br>Respond with just the article title and nothing else.&para;<br>&para;<br>Article titles:&para;<br>{{titles}}&para;<br>&para;<br>Sentence to classify:&para;<br>{{sentence}}&para;<br>```&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>&lt;section title="Improved prompt"&gt;&para;<br>&para;<br>```text&para;<br>You are an intelligent text classification system specialized in matching sentences to Wikipedia article titles. Your task is to identify which Wikipedia article a given sentence most likely belongs to, based on a provided list of article titles.&para;<br>&para;<br>First, review the following list of Wikipedia article titles:&para;<br>&lt;article_titles&gt;&para;<br>{{titles}}&para;<br>&lt;/article_titles&gt;&para;<br>&para;<br>Now, consider this sentence that needs to be classified:&para;<br>&lt;sentence_to_classify&gt;&para;<br>{{sentence}}&para;<br>&lt;/sentence_to_classify&gt;&para;<br>&para;<br>Your goal is to determine which article title from the provided list best matches the given sentence. Follow these steps:&para;<br>&para;<br>1. List the key concepts from the sentence&para;<br>2. Compare each key concept with the article titles&para;<br>3. Rank the top 3 most relevant titles and explain why they are relevant&para;<br>4. Select the most appropriate article title that best encompasses or relates to the sentence's content&para;<br>&para;<br>Wrap your analysis in &lt;analysis&gt; tags. Include the following:&para;<br>- List of key concepts from the sentence&para;<br>- Comparison of each key concept with the article titles&para;<br>- Ranking of top 3 most relevant titles with explanations&para;<br>- Your final choice and reasoning&para;<br>&para;<br>After your analysis, provide your final answer: the single most appropriate Wikipedia article title from the list.&para;<br>&para;<br>Output only the chosen article title, without any additional text or explanation.&para;<br>```&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>Notice how the improved prompt:&para;<br>- Adds clear step-by-step reasoning instructions&para;<br>- Uses XML tags to organize content&para;<br>- Provides explicit output formatting requirements&para;<br>- Guides Claude through the analysis process&para;<br>&para;<br>### Troubleshooting&para;<br>&para;<br>Common issues and solutions:&para;<br>&para;<br>- **Examples not appearing in output**: Check that examples are properly formatted with XML tags and appear at the start of the first user message&para;<br>- **Chain of thought too verbose**: Add specific instructions about desired output length and level of detail&para;<br>- **Reasoning steps don't match your needs**: Modify the steps section to match your specific use case&para;<br>&para;<br>***&para;<br>&para;<br>## Next steps&para;<br>&para;<br>&lt;CardGroup cols={2}&gt;&para;<br>  &lt;Card title="Start prompt engineering" icon="link" href="/docs/en/build-with-claude/prompt-engineering/claude-prompting-best-practices"&gt;&para;<br>    Learn core techniques with worked examples.&para;<br>  &lt;/Card&gt;&para;<br>  &lt;Card title="Prompt library" icon="link" href="/docs/en/resources/prompt-library/library"&gt;&para;<br>    Get inspired by a curated selection of prompts for various tasks and use cases.&para;<br>  &lt;/Card&gt;&para;<br>  &lt;Card title="Test your prompts" icon="link" href="/docs/en/test-and-evaluate/eval-tool"&gt;&para;<br>    Use the evaluation tool to test your improved prompts.&para;<br>  &lt;/Card&gt;&para;<br>  &lt;Card title="GitHub prompting tutorial" icon="link" href="https://github.com/anthropics/prompt-eng-interactive-tutorial"&gt;&para;<br>    An example-filled tutorial that covers the prompt engineering concepts found in our docs.&para;<br>  &lt;/Card&gt;&para;<br>&lt;/CardGroup&gt;</span></div>
        </div>

        <h2 style="margin-top: 2rem; margin-bottom: 1rem;">Unified Diff</h2>
        <pre><code>--- a/build-with-claude/prompt-engineering/prompt-generator.md
+++ b/build-with-claude/prompt-engineering/prompt-generator.md
@@ -52,7 +52,7 @@
 
 Consider a simple application that translates English text to Spanish. The translated text would be variable since it changes between users or calls to Claude. You might use this prompt template:
 
-```
+```text
 Translate this text from English to Spanish: {{text}}
 ```
 
</code></pre>
    </div>
</body>
</html>