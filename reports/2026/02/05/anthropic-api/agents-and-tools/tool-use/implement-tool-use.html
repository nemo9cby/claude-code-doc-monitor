<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>agents-and-tools/tool-use/implement-tool-use - Diff Report</title>
    <link rel="stylesheet" href="../../css/diff.css">
    <style>
        :root {
            --bg-color: #1a1a2e;
            --card-bg: #16213e;
            --text-color: #eee;
            --accent: #0f3460;
            --add-bg: #1a4d1a;
            --del-bg: #4d1a1a;
            --add-text: #4ade80;
            --del-text: #f87171;
        }
        @media (prefers-color-scheme: light) {
            :root {
                --bg-color: #f5f5f5;
                --card-bg: #fff;
                --text-color: #333;
                --accent: #e0e0e0;
                --add-bg: #d4edda;
                --del-bg: #f8d7da;
                --add-text: #155724;
                --del-text: #721c24;
            }
        }
        * { box-sizing: border-box; margin: 0; padding: 0; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: var(--bg-color);
            color: var(--text-color);
            line-height: 1.6;
            padding: 2rem;
        }
        .container { max-width: 1200px; margin: 0 auto; }
        header { margin-bottom: 2rem; }
        h1 { font-size: 1.5rem; margin-bottom: 0.5rem; }
        .meta { color: #888; font-size: 0.9rem; }
        .summary {
            background: var(--card-bg);
            padding: 1rem;
            border-radius: 8px;
            margin-bottom: 2rem;
            display: flex;
            gap: 2rem;
        }
        .stat { display: flex; align-items: center; gap: 0.5rem; }
        .stat.added { color: var(--add-text); }
        .stat.removed { color: var(--del-text); }
        .analysis {
            background: var(--card-bg);
            padding: 1.5rem;
            border-radius: 8px;
            margin-bottom: 2rem;
            border-left: 4px solid #8b5cf6;
        }
        .analysis-header {
            font-weight: 600;
            margin-bottom: 0.75rem;
            color: #8b5cf6;
        }
        .analysis-content {
            white-space: pre-wrap;
            font-size: 0.95rem;
            line-height: 1.7;
        }
        .diff-container {
            background: var(--card-bg);
            border-radius: 8px;
            overflow: hidden;
        }
        .diff-header {
            background: var(--accent);
            padding: 0.75rem 1rem;
            font-weight: 600;
        }
        .diff-content {
            padding: 1rem;
            overflow-x: auto;
        }
        .diff-content ins {
            background: var(--add-bg);
            color: var(--add-text);
            text-decoration: none;
            padding: 0.1em 0.2em;
            border-radius: 2px;
        }
        .diff-content del {
            background: var(--del-bg);
            color: var(--del-text);
            text-decoration: line-through;
            padding: 0.1em 0.2em;
            border-radius: 2px;
        }
        pre {
            background: var(--accent);
            padding: 1rem;
            border-radius: 8px;
            overflow-x: auto;
            font-size: 0.85rem;
            margin-top: 2rem;
        }
        a { color: #60a5fa; }
        .back-link { margin-bottom: 1rem; display: inline-block; }
    </style>
</head>
<body>
    <div class="container">
        <a href="../../../index.html" class="back-link">&larr; Back to daily report</a>

        <header>
            <h1>agents-and-tools/tool-use/implement-tool-use.md</h1>
            <p class="meta">Changed on 2026-02-05 12:43:36 EST</p>
        </header>

        <div class="summary">
            <div class="stat added">
                <span>+12</span> lines added
            </div>
            <div class="stat removed">
                <span>-15</span> lines removed
            </div>
        </div>

        

        <div class="diff-container">
            <div class="diff-header">Visual Diff</div>
            <div class="diff-content"><span># How to implement tool use&para;<br>&para;<br>---&para;<br>&para;<br>## Choosing a model&para;<br>&para;<br>We recommend using the latest Claude </span><del style="background:#ffe6e6;">Sonnet (4.5) or Claude </del><span>Opus (4.</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>) model for complex tools and ambiguous queries; </span><ins style="background:#e6ffe6;">i</ins><span>t</span><del style="background:#ffe6e6;">hey</del><span> handle</span><ins style="background:#e6ffe6;">s</ins><span> multiple tools better and seek</span><ins style="background:#e6ffe6;">s</ins><span> clarification when needed.&para;<br>&para;<br>Use Claude Haiku models for straightforward tools, but note they may infer missing parameters.&para;<br>&para;<br>&lt;Tip&gt;&para;<br>If using Claude with tool use and extended thinking, refer to our guide [here](/docs/en/build-with-claude/extended-thinking) for more information.&para;<br>&lt;/Tip&gt;&para;<br>&para;<br>## Specifying client tools&para;<br>&para;<br>Client tools (both Anthropic-defined and user-defined) are specified in the `tools` top-level parameter of the API request. Each tool definition includes:&para;<br>&para;<br>| Parameter      | Description                                                                                         |&para;<br>| :------------- | :-------------------------------------------------------------------------------------------------- |&para;<br>| `name`         | The name of the tool. Must match the regex `^[a-zA-Z0-9_-]{1,64}$`.                                 |&para;<br>| `description`  | A detailed plaintext description of what the tool does, when it should be used, and how it behaves. |&para;<br>| `input_schema` | A [JSON Schema](https://json-schema.org/) object defining the expected parameters for the tool.     |&para;<br>| `input_examples` | (Optional, beta) An array of example input objects to help Claude understand how to use the tool. See [Providing tool use examples](#providing-tool-use-examples). |&para;<br>&para;<br>&lt;section title="Example simple tool definition"&gt;&para;<br>&para;<br>```json JSON&para;<br>{&para;<br>  "name": "get_weather",&para;<br>  "description": "Get the current weather in a given location",&para;<br>  "input_schema": {&para;<br>    "type": "object",&para;<br>    "properties": {&para;<br>      "location": {&para;<br>        "type": "string",&para;<br>        "description": "The city and state, e.g. San Francisco, CA"&para;<br>      },&para;<br>      "unit": {&para;<br>        "type": "string",&para;<br>        "enum": ["celsius", "fahrenheit"],&para;<br>        "description": "The unit of temperature, either 'celsius' or 'fahrenheit'"&para;<br>      }&para;<br>    },&para;<br>    "required": ["location"]&para;<br>  }&para;<br>}&para;<br>```&para;<br>&para;<br>This tool, named `get_weather`, expects an input object with a required `location` string and an optional `unit` string that must be either "celsius" or "fahrenheit".&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>### Tool use system prompt&para;<br>&para;<br>When you call the Claude API with the `tools` parameter, we construct a special system prompt from the tool definitions, tool configuration, and any user-specified system prompt. The constructed prompt is designed to instruct the model to use the specified tool(s) and provide the necessary context for the tool to operate properly:&para;<br>&para;<br>```&para;<br>In this environment you have access to a set of tools you can use to answer the user's question.&para;<br>{{ FORMATTING INSTRUCTIONS }}&para;<br>String and scalar parameters should be specified as is, while lists and objects should use JSON format. Note that spaces for string values are not stripped. The output is not expected to be valid XML and is parsed with regular expressions.&para;<br>Here are the functions available in JSONSchema format:&para;<br>{{ TOOL DEFINITIONS IN JSON SCHEMA }}&para;<br>{{ USER SYSTEM PROMPT }}&para;<br>{{ TOOL CONFIGURATION }}&para;<br>```&para;<br>&para;<br>### Best practices for tool definitions&para;<br>&para;<br>To get the best performance out of Claude when using tools, follow these guidelines:&para;<br>&para;<br>- **Provide extremely detailed descriptions.** This is by far the most important factor in tool performance. Your descriptions should explain every detail about the tool, including:&para;<br>  - What the tool does&para;<br>  - When it should be used (and when it shouldn't)&para;<br>  - What each parameter means and how it affects the tool's behavior&para;<br>  - Any important caveats or limitations, such as what information the tool does not return if the tool name is unclear. The more context you can give Claude about your tools, the better it will be at deciding when and how to use them. Aim for at least 3-4 sentences per tool description, more if the tool is complex.&para;<br>- **Prioritize descriptions, but consider using `input_examples` for complex tools.** Clear descriptions are most important, but for tools with complex inputs, nested objects, or format-sensitive parameters, you can use the `input_examples` field (beta) to provide schema-validated examples. See [Providing tool use examples](#providing-tool-use-examples) for details.&para;<br>&para;<br>&lt;section title="Example of a good tool description"&gt;&para;<br>&para;<br>```json JSON&para;<br>{&para;<br>  "name": "get_stock_price",&para;<br>  "description": "Retrieves the current stock price for a given ticker symbol. The ticker symbol must be a valid symbol for a publicly traded company on a major US stock exchange like NYSE or NASDAQ. The tool will return the latest trade price in USD. It should be used when the user asks about the current or most recent price of a specific stock. It will not provide any other information about the stock or company.",&para;<br>  "input_schema": {&para;<br>    "type": "object",&para;<br>    "properties": {&para;<br>      "ticker": {&para;<br>        "type": "string",&para;<br>        "description": "The stock ticker symbol, e.g. AAPL for Apple Inc."&para;<br>      }&para;<br>    },&para;<br>    "required": ["ticker"]&para;<br>  }&para;<br>}&para;<br>```&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>&lt;section title="Example poor tool description"&gt;&para;<br>&para;<br>```json JSON&para;<br>{&para;<br>  "name": "get_stock_price",&para;<br>  "description": "Gets the stock price for a ticker.",&para;<br>  "input_schema": {&para;<br>    "type": "object",&para;<br>    "properties": {&para;<br>      "ticker": {&para;<br>        "type": "string"&para;<br>      }&para;<br>    },&para;<br>    "required": ["ticker"]&para;<br>  }&para;<br>}&para;<br>```&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>The good description clearly explains what the tool does, when to use it, what data it returns, and what the `ticker` parameter means. The poor description is too brief and leaves Claude with many open questions about the tool's behavior and usage.&para;<br>&para;<br>## Providing tool use examples&para;<br>&para;<br>You can provide concrete examples of valid tool inputs to help Claude understand how to use your tools more effectively. This is particularly useful for complex tools with nested objects, optional parameters, or format-sensitive inputs.&para;<br>&para;<br>&lt;Info&gt;&para;<br>Tool use examples is a beta feature. Include the appropriate [beta header](/docs/en/api/beta-headers) for your provider:&para;<br>&para;<br>| Provider | Beta header | Supported models |&para;<br>|----------|-------------|------------------|&para;<br>| Claude API,&lt;br/&gt;Microsoft Foundry | `advanced-tool-use-2025-11-20` | All models |&para;<br>| Vertex AI,&lt;br/&gt;Amazon Bedrock | `tool-examples-2025-10-29` | Claude Opus 4.</span><del style="background:#ffe6e6;">5 only</del><ins style="background:#e6ffe6;">6, Claude Opus 4.5</ins><span> |&para;<br>&lt;/Info&gt;&para;<br>&para;<br>### Basic usage&para;<br>&para;<br>Add an optional `input_examples` field to your tool definition with an array of example input objects. Each example must be valid according to the tool's `input_schema`:&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>```python Python&para;<br>import anthropic&para;<br>&para;<br>client = anthropic.Anthropic()&para;<br>&para;<br>response = client.messages.create(&para;<br>    model="claude-</span><del style="background:#ffe6e6;">sonnet-4-5-20250929</del><ins style="background:#e6ffe6;">opus-4-6</ins><span>",&para;<br>    max_tokens=1024,&para;<br>    betas=["advanced-tool-use-2025-11-20"],&para;<br>    tools=[&para;<br>        {&para;<br>            "name": "get_weather",&para;<br>            "description": "Get the current weather in a given location",&para;<br>            "input_schema": {&para;<br>                "type": "object",&para;<br>                "properties": {&para;<br>                    "location": {&para;<br>                        "type": "string",&para;<br>                        "description": "The city and state, e.g. San Francisco, CA"&para;<br>                    },&para;<br>                    "unit": {&para;<br>                        "type": "string",&para;<br>                        "enum": ["celsius", "fahrenheit"],&para;<br>                        "description": "The unit of temperature"&para;<br>                    }&para;<br>                },&para;<br>                "required": ["location"]&para;<br>            },&para;<br>            "input_examples": [&para;<br>                {&para;<br>                    "location": "San Francisco, CA",&para;<br>                    "unit": "fahrenheit"&para;<br>                },&para;<br>                {&para;<br>                    "location": "Tokyo, Japan",&para;<br>                    "unit": "celsius"&para;<br>                },&para;<br>                {&para;<br>                    "location": "New York, NY"  # 'unit' is optional&para;<br>                }&para;<br>            ]&para;<br>        }&para;<br>    ],&para;<br>    messages=[&para;<br>        {"role": "user", "content": "What's the weather like in San Francisco?"}&para;<br>    ]&para;<br>)&para;<br>```&para;<br>&para;<br>```typescript TypeScript&para;<br>import Anthropic from "@anthropic-ai/sdk";&para;<br>&para;<br>const client = new Anthropic();&para;<br>&para;<br>const response = await client.messages.create({&para;<br>  model: "claude-</span><del style="background:#ffe6e6;">sonnet-4-5-20250929</del><ins style="background:#e6ffe6;">opus-4-6</ins><span>",&para;<br>  max_tokens: 1024,&para;<br>  betas: ["advanced-tool-use-2025-11-20"],&para;<br>  tools: [&para;<br>    {&para;<br>      name: "get_weather",&para;<br>      description: "Get the current weather in a given location",&para;<br>      input_schema: {&para;<br>        type: "object",&para;<br>        properties: {&para;<br>          location: {&para;<br>            type: "string",&para;<br>            description: "The city and state, e.g. San Francisco, CA",&para;<br>          },&para;<br>          unit: {&para;<br>            type: "string",&para;<br>            enum: ["celsius", "fahrenheit"],&para;<br>            description: "The unit of temperature",&para;<br>          },&para;<br>        },&para;<br>        required: ["location"],&para;<br>      },&para;<br>      input_examples: [&para;<br>        {&para;<br>          location: "San Francisco, CA",&para;<br>          unit: "fahrenheit",&para;<br>        },&para;<br>        {&para;<br>          location: "Tokyo, Japan",&para;<br>          unit: "celsius",&para;<br>        },&para;<br>        {&para;<br>          location: "New York, NY",&para;<br>          // Demonstrates that 'unit' is optional&para;<br>        },&para;<br>      ],&para;<br>    },&para;<br>  ],&para;<br>  messages: [{ role: "user", content: "What's the weather like in San Francisco?" }],&para;<br>});&para;<br>```&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>Examples are included in the prompt alongside your tool schema, showing Claude concrete patterns for well-formed tool calls. This helps Claude understand when to include optional parameters, what formats to use, and how to structure complex inputs.&para;<br>&para;<br>### Requirements and limitations&para;<br>&para;<br>- **Schema validation** - Each example must be valid according to the tool's `input_schema`. Invalid examples return a 400 error&para;<br>- **Not supported for server-side tools** - Only user-defined tools can have input examples&para;<br>- **Token cost** - Examples add to prompt tokens: ~20-50 tokens for simple examples, ~100-200 tokens for complex nested objects&para;<br>&para;<br>## Tool runner (beta)&para;<br>&para;<br>The tool runner provides an out-of-the-box solution for executing tools with Claude. Instead of manually handling tool calls, tool results, and conversation management, the tool runner automatically:&para;<br>&para;<br>- Executes tools when Claude calls them&para;<br>- Handles the request/response cycle&para;<br>- Manages conversation state&para;<br>- Provides type safety and validation&para;<br>&para;<br>We recommend that you use the tool runner for most tool use implementations.&para;<br>&para;<br>&lt;Note&gt;&para;<br>The tool runner is currently in beta and available in the [Python](https://github.com/anthropics/anthropic-sdk-python/blob/main/tools.md), [TypeScript](https://github.com/anthropics/anthropic-sdk-typescript/blob/main/helpers.md#tool-helpers), and [Ruby](https://github.com/anthropics/anthropic-sdk-ruby/blob/main/helpers.md#3-auto-looping-tool-runner-beta) SDKs.&para;<br>&lt;/Note&gt;&para;<br>&para;<br>&lt;Tip&gt;&para;<br>**Automatic context management with compaction**&para;<br>&para;<br>The tool runner supports automatic [compaction](/docs/en/build-with-claude/context-editing#client-side-compaction-sdk), which generates summaries when token usage exceeds a threshold. This allows long-running agentic tasks to continue beyond context window limits.&para;<br>&lt;/Tip&gt;&para;<br>&para;<br>### Basic usage&para;<br>&para;<br>Define tools using the SDK helpers, then use the tool runner to execute them.&para;<br>&para;<br>&lt;Tabs&gt;&para;<br>&lt;Tab title="Python"&gt;&para;<br>&para;<br>Use the `@beta_tool` decorator to define tools with type hints and docstrings.&para;<br>&para;<br>&lt;Note&gt;&para;<br>If you're using the async client, replace `@beta_tool` with `@beta_async_tool` and define the function with `async def`.&para;<br>&lt;/Note&gt;&para;<br>&para;<br>```python&para;<br>import anthropic&para;<br>import json&para;<br>from anthropic import beta_tool&para;<br>&para;<br># Initialize client&para;<br>client = anthropic.Anthropic()&para;<br>&para;<br># Define tools using the decorator&para;<br>@beta_tool&para;<br>def get_weather(location: str, unit: str = "fahrenheit") -&gt; str:&para;<br>    """Get the current weather in a given location.&para;<br>&para;<br>    Args:&para;<br>        location: The city and state, e.g. San Francisco, CA&para;<br>        unit: Temperature unit, either 'celsius' or 'fahrenheit'&para;<br>    """&para;<br>    # In a full implementation, you'd call a weather API here&para;<br>    return json.dumps({"temperature": "20°C", "condition": "Sunny"})&para;<br>&para;<br>@beta_tool&para;<br>def calculate_sum(a: int, b: int) -&gt; str:&para;<br>    """Add two numbers together.&para;<br>&para;<br>    Args:&para;<br>        a: First number&para;<br>        b: Second number&para;<br>    """&para;<br>    return str(a + b)&para;<br>&para;<br># Use the tool runner&para;<br>runner = client.beta.messages.tool_runner(&para;<br>    model="claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>",&para;<br>    max_tokens=1024,&para;<br>    tools=[get_weather, calculate_sum],&para;<br>    messages=[&para;<br>        {"role": "user", "content": "What's the weather like in Paris? Also, what's 15 + 27?"}&para;<br>    ]&para;<br>)&para;<br>for message in runner:&para;<br>    print(message.content[0].text)&para;<br>```&para;<br>&para;<br>The `@beta_tool` decorator inspects the function arguments and docstring to extract a JSON schema representation. For example, `calculate_sum` becomes:&para;<br>&para;<br>```json&para;<br>{&para;<br>  "name": "calculate_sum",&para;<br>  "description": "Adds two integers together.",&para;<br>  "input_schema": {&para;<br>    "additionalProperties": false,&para;<br>    "properties": {&para;<br>      "left": {&para;<br>        "description": "The first integer to add.",&para;<br>        "title": "Left",&para;<br>        "type": "integer"&para;<br>      },&para;<br>      "right": {&para;<br>        "description": "The second integer to add.",&para;<br>        "title": "Right",&para;<br>        "type": "integer"&para;<br>      }&para;<br>    },&para;<br>    "required": ["left", "right"],&para;<br>    "type": "object"&para;<br>  }&para;<br>}&para;<br>```&para;<br>&para;<br>&lt;/Tab&gt;&para;<br>&lt;Tab title="TypeScript"&gt;&para;<br>&para;<br>Use `betaZodTool()` for type-safe tool definitions with Zod validation, or `betaTool()` for JSON Schema-based definitions.&para;<br>&para;<br>TypeScript offers two approaches for defining tools:&para;<br>&para;<br>**Using Zod (recommended)** - Use `betaZodTool()` for type-safe tool definitions with Zod validation (requires Zod 3.25.0 or higher):&para;<br>&para;<br>```typescript&para;<br>import { Anthropic } from '@anthropic-ai/sdk';&para;<br>import { betaZodTool } from '@anthropic-ai/sdk/helpers/beta/zod';&para;<br>import { z } from 'zod';&para;<br>&para;<br>const anthropic = new Anthropic();&para;<br>&para;<br>const getWeatherTool = betaZodTool({&para;<br>  name: 'get_weather',&para;<br>  description: 'Get the current weather in a given location',&para;<br>  inputSchema: z.object({&para;<br>    location: z.string().describe('The city and state, e.g. San Francisco, CA'),&para;<br>    unit: z.enum(['celsius', 'fahrenheit']).default('fahrenheit')&para;<br>      .describe('Temperature unit')&para;<br>  }),&para;<br>  run: async (input) =&gt; {&para;<br>    // In a full implementation, you'd call a weather API here&para;<br>    return JSON.stringify({temperature: '20°C', condition: 'Sunny'});&para;<br>  }&para;<br>});&para;<br>&para;<br>const runner = anthropic.beta.messages.toolRunner({&para;<br>  model: 'claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>',&para;<br>  max_tokens: 1024,&para;<br>  tools: [getWeatherTool],&para;<br>  messages: [{ role: 'user', content: "What's the weather like in Paris?" }]&para;<br>});&para;<br>&para;<br>for await (const message of runner) {&para;<br>  console.log(message.content[0].text);&para;<br>}&para;<br>```&para;<br>&para;<br>**Using JSON Schema** - Use `betaTool()` for type-safe tool definitions without Zod:&para;<br>&para;<br>&lt;Note&gt;&para;<br>The input generated by Claude will not be validated at runtime. Perform validation inside the `run` function if needed.&para;<br>&lt;/Note&gt;&para;<br>&para;<br>```typescript&para;<br>import { Anthropic } from '@anthropic-ai/sdk';&para;<br>import { betaTool } from '@anthropic-ai/sdk/helpers/beta/json-schema';&para;<br>&para;<br>const anthropic = new Anthropic();&para;<br>&para;<br>const calculateSumTool = betaTool({&para;<br>  name: 'calculate_sum',&para;<br>  description: 'Add two numbers together',&para;<br>  inputSchema: {&para;<br>    type: 'object',&para;<br>    properties: {&para;<br>      a: { type: 'number', description: 'First number' },&para;<br>      b: { type: 'number', description: 'Second number' }&para;<br>    },&para;<br>    required: ['a', 'b']&para;<br>  },&para;<br>  run: async (input) =&gt; {&para;<br>    return String(input.a + input.b);&para;<br>  }&para;<br>});&para;<br>&para;<br>const runner = anthropic.beta.messages.toolRunner({&para;<br>  model: 'claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>',&para;<br>  max_tokens: 1024,&para;<br>  tools: [calculateSumTool],&para;<br>  messages: [{ role: 'user', content: "What's 15 + 27?" }]&para;<br>});&para;<br>&para;<br>for await (const message of runner) {&para;<br>  console.log(message.content[0].text);&para;<br>}&para;<br>```&para;<br>&para;<br>&lt;/Tab&gt;&para;<br>&lt;Tab title="Ruby"&gt;&para;<br>&para;<br>Use the `Anthropic::BaseTool` class to define tools with typed input schemas.&para;<br>&para;<br>```ruby&para;<br>require "anthropic"&para;<br>&para;<br># Initialize client&para;<br>client = Anthropic::Client.new&para;<br>&para;<br># Define input schema&para;<br>class GetWeatherInput &lt; Anthropic::BaseModel&para;<br>  required :location, String, doc: "The city and state, e.g. San Francisco, CA"&para;<br>  optional :unit, Anthropic::InputSchema::EnumOf["celsius", "fahrenheit"],&para;<br>           doc: "Temperature unit"&para;<br>end&para;<br>&para;<br># Define tool&para;<br>class GetWeather &lt; Anthropic::BaseTool&para;<br>  doc "Get the current weather in a given location"&para;<br>  input_schema GetWeatherInput&para;<br>&para;<br>  def call(input)&para;<br>    # In a full implementation, you'd call a weather API here&para;<br>    JSON.generate({temperature: "20°C", condition: "Sunny"})&para;<br>  end&para;<br>end&para;<br>&para;<br>class CalculateSumInput &lt; Anthropic::BaseModel&para;<br>  required :a, Integer, doc: "First number"&para;<br>  required :b, Integer, doc: "Second number"&para;<br>end&para;<br>&para;<br>class CalculateSum &lt; Anthropic::BaseTool&para;<br>  doc "Add two numbers together"&para;<br>  input_schema CalculateSumInput&para;<br>&para;<br>  def call(input)&para;<br>    (input.a + input.b).to_s&para;<br>  end&para;<br>end&para;<br>&para;<br># Use the tool runner&para;<br>runner = client.beta.messages.tool_runner(&para;<br>  model: "claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>",&para;<br>  max_tokens: 1024,&para;<br>  tools: [GetWeather.new, CalculateSum.new],&para;<br>  messages: [&para;<br>    {role: "user", content: "What's the weather like in Paris? Also, what's 15 + 27?"}&para;<br>  ]&para;<br>)&para;<br>&para;<br>runner.each_message do |message|&para;<br>  message.content.each do |block|&para;<br>    puts block.text if block.respond_to?(:text)&para;<br>  end&para;<br>end&para;<br>```&para;<br>&para;<br>The `Anthropic::BaseTool` class uses the `doc` method for the tool description and `input_schema` to define the expected parameters. The SDK automatically converts this to the appropriate JSON schema format.&para;<br>&para;<br>&lt;/Tab&gt;&para;<br>&lt;/Tabs&gt;&para;<br>&para;<br>The tool function must return a content block or content block array, including text, images, or document blocks. This allows tools to return rich, multimodal responses. Returned strings will be converted to a text content block. If you want to return a structured JSON object to Claude, encode it to a JSON string before returning it. Numbers, booleans, or other non-string primitives must also be converted to strings.&para;<br>&para;<br>### Iterating over the tool runner&para;<br>&para;<br>The tool runner is an iterable that yields messages from Claude. This is often referred to as a "tool call loop". Each iteration, the runner checks if Claude requested a tool use. If so, it calls the tool and sends the result back to Claude automatically, then yields the next message from Claude to continue your loop.&para;<br>&para;<br>You can end the loop at any iteration with a `break` statement. The runner will loop until Claude returns a message without a tool use.&para;<br>&para;<br>If you don't need intermediate messages, you can get the final message directly:&para;<br>&para;<br>&lt;Tabs&gt;&para;<br>&lt;Tab title="Python"&gt;&para;<br>&para;<br>Use `runner.until_done()` to get the final message.&para;<br>&para;<br>```python&para;<br>runner = client.beta.messages.tool_runner(&para;<br>    model="claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>",&para;<br>    max_tokens=1024,&para;<br>    tools=[get_weather, calculate_sum],&para;<br>    messages=[&para;<br>        {"role": "user", "content": "What's the weather like in Paris? Also, what's 15 + 27?"}&para;<br>    ]&para;<br>)&para;<br>final_message = runner.until_done()&para;<br>print(final_message.content[0].text)&para;<br>```&para;<br>&para;<br>&lt;/Tab&gt;&para;<br>&lt;Tab title="TypeScript"&gt;&para;<br>&para;<br>Simply `await` the runner to get the final message.&para;<br>&para;<br>```typescript&para;<br>const runner = anthropic.beta.messages.toolRunner({&para;<br>  model: 'claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>',&para;<br>  max_tokens: 1024,&para;<br>  tools: [getWeatherTool],&para;<br>  messages: [{ role: 'user', content: "What's the weather like in Paris?" }]&para;<br>});&para;<br>&para;<br>const finalMessage = await runner;&para;<br>console.log(finalMessage.content[0].text);&para;<br>```&para;<br>&para;<br>&lt;/Tab&gt;&para;<br>&lt;Tab title="Ruby"&gt;&para;<br>&para;<br>Use `runner.run_until_finished` to get all messages.&para;<br>&para;<br>```ruby&para;<br>runner = client.beta.messages.tool_runner(&para;<br>  model: "claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>",&para;<br>  max_tokens: 1024,&para;<br>  tools: [GetWeather.new, CalculateSum.new],&para;<br>  messages: [&para;<br>    {role: "user", content: "What's the weather like in Paris? Also, what's 15 + 27?"}&para;<br>  ]&para;<br>)&para;<br>&para;<br>all_messages = runner.run_until_finished&para;<br>all_messages.each { |msg| puts msg.content }&para;<br>```&para;<br>&para;<br>&lt;/Tab&gt;&para;<br>&lt;/Tabs&gt;&para;<br>&para;<br>### Advanced usage&para;<br>&para;<br>Within the loop, you can fully customize the tool runner's next request to the Messages API. The runner automatically appends tool results to the message history, so you don't need to manually manage them. You can optionally inspect the tool result for logging or debugging, and modify the request parameters before the next API call.&para;<br>&para;<br>&lt;Tabs&gt;&para;<br>&lt;Tab title="Python"&gt;&para;<br>&para;<br>Use `generate_tool_call_response()` to optionally inspect the tool result (the runner appends it automatically). Use `set_messages_params()` and `append_messages()` to modify the request.&para;<br>&para;<br>```python&para;<br>runner = client.beta.messages.tool_runner(&para;<br>    model="claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>",&para;<br>    max_tokens=1024,&para;<br>    tools=[get_weather],&para;<br>    messages=[{"role": "user", "content": "What's the weather in San Francisco?"}]&para;<br>)&para;<br>for message in runner:&para;<br>    # Optional: inspect the tool response (automatically appended by the runner)&para;<br>    tool_response = runner.generate_tool_call_response()&para;<br>    if tool_response:&para;<br>        print(f"Tool result: {tool_response}")&para;<br>&para;<br>    # Customize the next request&para;<br>    runner.set_messages_params(lambda params: {&para;<br>        **params,&para;<br>        "max_tokens": 2048  # Increase tokens for next request&para;<br>    })&para;<br>&para;<br>    # Or add additional messages&para;<br>    runner.append_messages(&para;<br>        {"role": "user", "content": "Please be concise in your response."}&para;<br>    )&para;<br>```&para;<br>&para;<br>&lt;/Tab&gt;&para;<br>&lt;Tab title="TypeScript"&gt;&para;<br>&para;<br>Use `generateToolResponse()` to optionally inspect the tool result (the runner appends it automatically). Use `setMessagesParams()` and `pushMessages()` to modify the request.&para;<br>&para;<br>```typescript&para;<br>const runner = anthropic.beta.messages.toolRunner({&para;<br>  model: 'claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>',&para;<br>  max_tokens: 1024,&para;<br>  tools: [getWeatherTool],&para;<br>  messages: [{ role: 'user', content: "What's the weather in San Francisco?" }]&para;<br>});&para;<br>&para;<br>for await (const message of runner) {&para;<br>  // Optional: inspect the tool result message (automatically appended by the runner)&para;<br>  const toolResultMessage = await runner.generateToolResponse();&para;<br>  if (toolResultMessage) {&para;<br>    console.log('Tool result:', toolResultMessage);&para;<br>  }&para;<br>&para;<br>  // Customize the next request&para;<br>  runner.setMessagesParams(params =&gt; ({&para;<br>    ...params,&para;<br>    max_tokens: 2048  // Increase tokens for next request&para;<br>  }));&para;<br>&para;<br>  // Or add additional messages&para;<br>  runner.pushMessages(&para;<br>    { role: 'user', content: 'Please be concise in your response.' }&para;<br>  );&para;<br>}&para;<br>```&para;<br>&para;<br>&lt;/Tab&gt;&para;<br>&lt;Tab title="Ruby"&gt;&para;<br>&para;<br>Use `next_message` for step-by-step control. Use `feed_messages` to inject messages and `params` to access parameters.&para;<br>&para;<br>```ruby&para;<br>runner = client.beta.messages.tool_runner(&para;<br>  model: "claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>",&para;<br>  max_tokens: 1024,&para;<br>  tools: [GetWeather.new],&para;<br>  messages: [{role: "user", content: "What's the weather in San Francisco?"}]&para;<br>)&para;<br>&para;<br># Manual step-by-step control&para;<br>message = runner.next_message&para;<br>puts message.content&para;<br>&para;<br># Inject follow-up messages&para;<br>runner.feed_messages([&para;<br>  {role: "user", content: "Also check Boston"}&para;<br>])&para;<br>&para;<br># Access current parameters&para;<br>puts runner.params&para;<br>```&para;<br>&para;<br>&lt;/Tab&gt;&para;<br>&lt;/Tabs&gt;&para;<br>&para;<br>#### Debugging tool execution&para;<br>&para;<br>When a tool throws an exception, the tool runner catches it and returns the error to Claude as a tool result with `is_error: true`. By default, only the exception message is included, not the full stack trace.&para;<br>&para;<br>To view full stack traces and debug information, set the `ANTHROPIC_LOG` environment variable:&para;<br>&para;<br>```bash&para;<br># View info-level logs including tool errors&para;<br>export ANTHROPIC_LOG=info&para;<br>&para;<br># View debug-level logs for more verbose output&para;<br>export ANTHROPIC_LOG=debug&para;<br>```&para;<br>&para;<br>When enabled, the SDK logs full exception details (using Python's `logging` module, the console in TypeScript, or Ruby's logger), including the complete stack trace when a tool fails.&para;<br>&para;<br>#### Intercepting tool errors&para;<br>&para;<br>By default, tool errors are passed back to Claude, which can then respond appropriately. However, you may want to detect errors and handle them differently—for example, to stop execution early or implement custom error handling.&para;<br>&para;<br>Use the tool response method to intercept tool results and check for errors before they're sent to Claude:&para;<br>&para;<br>&lt;Tabs&gt;&para;<br>&lt;Tab title="Python"&gt;&para;<br>&para;<br>```python&para;<br>import json&para;<br>&para;<br>runner = client.beta.messages.tool_runner(&para;<br>    model="claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>",&para;<br>    max_tokens=1024,&para;<br>    tools=[my_tool],&para;<br>    messages=[{"role": "user", "content": "Run the tool"}]&para;<br>)&para;<br>&para;<br>for message in runner:&para;<br>    tool_response = runner.generate_tool_call_response()&para;<br>&para;<br>    if tool_response:&para;<br>        # Check if any tool result has an error&para;<br>        for block in tool_response.content:&para;<br>            if block.is_error:&para;<br>                # Option 1: Raise an exception to stop the loop&para;<br>                raise RuntimeError(f"Tool failed: {json.dumps(block.content)}")&para;<br>&para;<br>                # Option 2: Log and continue (let Claude handle it)&para;<br>                # logger.error(f"Tool error: {json.dumps(block.content)}")&para;<br>&para;<br>    # Process the message normally&para;<br>    print(message.content)&para;<br>```&para;<br>&para;<br>&lt;/Tab&gt;&para;<br>&lt;Tab title="TypeScript"&gt;&para;<br>&para;<br>```typescript&para;<br>const runner = anthropic.beta.messages.toolRunner({&para;<br>  model: 'claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>',&para;<br>  max_tokens: 1024,&para;<br>  tools: [myTool],&para;<br>  messages: [{ role: 'user', content: 'Run the tool' }]&para;<br>});&para;<br>&para;<br>for await (const message of runner) {&para;<br>  const toolResultMessage = await runner.generateToolResponse();&para;<br>&para;<br>  if (toolResultMessage) {&para;<br>    // Check if any tool result has an error&para;<br>    for (const block of toolResultMessage.content) {&para;<br>      if (block.type === 'tool_result' &amp;&amp; block.is_error) {&para;<br>        // Option 1: Throw to stop the loop&para;<br>        throw new Error(`Tool failed: ${JSON.stringify(block.content)}`);&para;<br>&para;<br>        // Option 2: Log and continue (let Claude handle it)&para;<br>        // console.error(`Tool error: ${JSON.stringify(block.content)}`);&para;<br>      }&para;<br>    }&para;<br>  }&para;<br>&para;<br>  // Process the message normally&para;<br>  console.log(message.content);&para;<br>}&para;<br>```&para;<br>&para;<br>&lt;/Tab&gt;&para;<br>&lt;Tab title="Ruby"&gt;&para;<br>&para;<br>```ruby&para;<br>runner = client.beta.messages.tool_runner(&para;<br>  model: "claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>",&para;<br>  max_tokens: 1024,&para;<br>  tools: [MyTool.new],&para;<br>  messages: [{role: "user", content: "Run the tool"}]&para;<br>)&para;<br>&para;<br>runner.each_message do |message|&para;<br>  # Get the tool response to check for errors&para;<br>  # Note: The runner automatically handles tool execution and appends results&para;<br>  # This is just for error checking/logging purposes&para;<br>  tool_results = runner.params[:messages].last&para;<br>&para;<br>  if tool_results &amp;&amp; tool_results[:role] == "user"&para;<br>    tool_results[:content].each do |block|&para;<br>      if block[:type] == "tool_result" &amp;&amp; block[:is_error]&para;<br>        # Option 1: Raise an exception to stop the loop&para;<br>        raise "Tool failed: #{block[:content]}"&para;<br>&para;<br>        # Option 2: Log and continue (let Claude handle it)&para;<br>        # logger.error("Tool error: #{block[:content]}")&para;<br>      end&para;<br>    end&para;<br>  end&para;<br>&para;<br>  puts message.content&para;<br>end&para;<br>```&para;<br>&para;<br>&lt;/Tab&gt;&para;<br>&lt;/Tabs&gt;&para;<br>&para;<br>#### Modifying tool results&para;<br>&para;<br>You can modify tool results before they're sent back to Claude. This is useful for adding metadata like `cache_control` to enable [prompt caching](/docs/en/build-with-claude/prompt-caching) on tool results, or for transforming the tool output.&para;<br>&para;<br>Use the tool response method to get the tool result, modify it, then add your modified version to the messages:&para;<br>&para;<br>&lt;Tabs&gt;&para;<br>&lt;Tab title="Python"&gt;&para;<br>&para;<br>```python&para;<br>runner = client.beta.messages.tool_runner(&para;<br>    model="claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>",&para;<br>    max_tokens=1024,&para;<br>    tools=[search_documents],&para;<br>    messages=[{"role": "user", "content": "Search for information about the climate of San Francisco"}]&para;<br>)&para;<br>&para;<br>for message in runner:&para;<br>    tool_response = runner.generate_tool_call_response()&para;<br>&para;<br>    if tool_response:&para;<br>        # Modify the tool result to add cache control&para;<br>        for block in tool_response.content:&para;<br>            if block.type == "tool_result":&para;<br>                # Add cache_control to cache this tool result&para;<br>                block.cache_control = {"type": "ephemeral"}&para;<br>&para;<br>        # Append the modified response (this prevents auto-append of original)&para;<br>        runner.append_messages(message, tool_response)&para;<br>&para;<br>    print(message.content)&para;<br>```&para;<br>&para;<br>&lt;/Tab&gt;&para;<br>&lt;Tab title="TypeScript"&gt;&para;<br>&para;<br>```typescript&para;<br>const runner = anthropic.beta.messages.toolRunner({&para;<br>  model: 'claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>',&para;<br>  max_tokens: 1024,&para;<br>  tools: [searchDocuments],&para;<br>  messages: [{ role: 'user', content: 'Search for information about the climate of San Francisco' }]&para;<br>});&para;<br>&para;<br>for await (const message of runner) {&para;<br>  const toolResultMessage = await runner.generateToolResponse();&para;<br>&para;<br>  if (toolResultMessage) {&para;<br>    // Modify the tool result to add cache control&para;<br>    for (const block of toolResultMessage.content) {&para;<br>      if (block.type === 'tool_result') {&para;<br>        // Add cache_control to cache this tool result&para;<br>        block.cache_control = { type: 'ephemeral' };&para;<br>      }&para;<br>    }&para;<br>&para;<br>    // Push the modified message (this prevents auto-append of original)&para;<br>    runner.pushMessages(message, toolResultMessage);&para;<br>  }&para;<br>&para;<br>  console.log(message.content);&para;<br>}&para;<br>```&para;<br>&para;<br>&lt;/Tab&gt;&para;<br>&lt;Tab title="Ruby"&gt;&para;<br>&para;<br>```ruby&para;<br>runner = client.beta.messages.tool_runner(&para;<br>  model: "claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>",&para;<br>  max_tokens: 1024,&para;<br>  tools: [SearchDocuments.new],&para;<br>  messages: [{role: "user", content: "Search for information about the climate of San Francisco"}]&para;<br>)&para;<br>&para;<br>loop do&para;<br>  message = runner.next_message&para;<br>  break unless message&para;<br>&para;<br>  # Access the most recent tool results from the messages array&para;<br>  # The runner automatically adds tool results, but we can modify them&para;<br>  tool_results_message = runner.params[:messages].last&para;<br>&para;<br>  if tool_results_message &amp;&amp; tool_results_message[:role] == "user"&para;<br>    tool_results_message[:content].each do |block|&para;<br>      if block[:type] == "tool_result"&para;<br>        # Modify the tool result to add cache control&para;<br>        block[:cache_control] = {type: "ephemeral"}&para;<br>      end&para;<br>    end&para;<br>  end&para;<br>&para;<br>  puts message.content&para;<br>  break if message.stop_reason != "tool_use"&para;<br>end&para;<br>```&para;<br>&para;<br>&lt;/Tab&gt;&para;<br>&lt;/Tabs&gt;&para;<br>&para;<br>&lt;Tip&gt;&para;<br>Adding `cache_control` to tool results is particularly useful when tools return large amounts of data (like document search results) that you want to cache for subsequent API calls. See [Prompt caching](/docs/en/build-with-claude/prompt-caching) for more details on caching strategies.&para;<br>&lt;/Tip&gt;&para;<br>&para;<br>### Streaming&para;<br>&para;<br>Enable streaming to receive events as they arrive. Each iteration yields a stream object that you can iterate for events.&para;<br>&para;<br>&lt;Tabs&gt;&para;<br>&lt;Tab title="Python"&gt;&para;<br>&para;<br>Set `stream=True` and use `get_final_message()` to get the accumulated message.&para;<br>&para;<br>```python&para;<br>runner = client.beta.messages.tool_runner(&para;<br>    model="claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>",&para;<br>    max_tokens=1024,&para;<br>    tools=[calculate_sum],&para;<br>    messages=[{"role": "user", "content": "What is 15 + 27?"}],&para;<br>    stream=True&para;<br>)&para;<br>&para;<br># When streaming, the runner returns BetaMessageStream&para;<br>for message_stream in runner:&para;<br>    for event in message_stream:&para;<br>        print('event:', event)&para;<br>    print('message:', message_stream.get_final_message())&para;<br>&para;<br>print(runner.until_done())&para;<br>```&para;<br>&para;<br>&lt;/Tab&gt;&para;<br>&lt;Tab title="TypeScript"&gt;&para;<br>&para;<br>Set `stream: true` and use `finalMessage()` to get the accumulated message.&para;<br>&para;<br>```typescript&para;<br>const runner = anthropic.beta.messages.toolRunner({&para;<br>  model: 'claude-</span><del style="background:#ffe6e6;">sonnet-4-5-20250929</del><ins style="background:#e6ffe6;">opus-4-6</ins><span>',&para;<br>  max_tokens: 1000,&para;<br>  messages: [{ role: 'user', content: 'What is the weather in San Francisco?' }],&para;<br>  tools: [getWeatherTool],&para;<br>  stream: true,&para;<br>});&para;<br>&para;<br>// When streaming, the runner returns BetaMessageStream&para;<br>for await (const messageStream of runner) {&para;<br>  for await (const event of messageStream) {&para;<br>    console.log('event:', event);&para;<br>  }&para;<br>  console.log('message:', await messageStream.finalMessage());&para;<br>}&para;<br>&para;<br>console.log(await runner);&para;<br>```&para;<br>&para;<br>&lt;/Tab&gt;&para;<br>&lt;Tab title="Ruby"&gt;&para;<br>&para;<br>Use `each_streaming` to iterate over streaming events.&para;<br>&para;<br>```ruby&para;<br>runner = client.beta.messages.tool_runner(&para;<br>  model: "claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>",&para;<br>  max_tokens: 1024,&para;<br>  tools: [CalculateSum.new],&para;<br>  messages: [{role: "user", content: "What is 15 + 27?"}]&para;<br>)&para;<br>&para;<br>runner.each_streaming do |event|&para;<br>  case event&para;<br>  when Anthropic::Streaming::TextEvent&para;<br>    print event.text&para;<br>  when Anthropic::Streaming::ToolUseEvent&para;<br>    puts "\nTool called: #{event.tool_name}"&para;<br>  end&para;<br>end&para;<br>```&para;<br>&para;<br>&lt;/Tab&gt;&para;<br>&lt;/Tabs&gt;&para;<br>&para;<br>&lt;Note&gt;&para;<br>The SDK tool runner is in beta. The rest of this document covers manual tool implementation.&para;<br>&lt;/Note&gt;&para;<br>&para;<br>## Controlling Claude's output&para;<br>&para;<br>### Forcing tool use&para;<br>&para;<br>In some cases, you may want Claude to use a specific tool to answer the user's question, even if Claude thinks it can provide an answer without using a tool. You can do this by specifying the tool in the `tool_choice` field like so:&para;<br>&para;<br>```&para;<br>tool_choice = {"type": "tool", "name": "get_weather"}&para;<br>```&para;<br>&para;<br>When working with the tool_choice parameter, we have four possible options:&para;<br>&para;<br>- `auto` allows Claude to decide whether to call any provided tools or not. This is the default value when `tools` are provided.&para;<br>- `any` tells Claude that it must use one of the provided tools, but doesn't force a particular tool.&para;<br>- `tool` allows us to force Claude to always use a particular tool.&para;<br>- `none` prevents Claude from using any tools. This is the default value when no `tools` are provided.&para;<br>&para;<br>&lt;Note&gt;&para;<br>When using [prompt caching](/docs/en/build-with-claude/prompt-caching#what-invalidates-the-cache), changes to the `tool_choice` parameter will invalidate cached message blocks. Tool definitions and system prompts remain cached, but message content must be reprocessed.&para;<br>&lt;/Note&gt;&para;<br>&para;<br>This diagram illustrates how each option works:&para;<br>&para;<br>&lt;Frame&gt;&para;<br>  ![Image](/docs/images/tool_choice.png)&para;<br>&lt;/Frame&gt;&para;<br>&para;<br>Note that when you have `tool_choice` as `any` or `tool`, we will prefill the assistant message to force a tool to be used. This means that the models will not emit a natural language response or explanation before `tool_use` content blocks, even if explicitly asked to do so.&para;<br>&para;<br>&lt;Note&gt;&para;<br>When using [extended thinking](/docs/en/build-with-claude/extended-thinking) with tool use, `tool_choice: {"type": "any"}` and `tool_choice: {"type": "tool", "name": "..."}` are not supported and will result in an error. Only `tool_choice: {"type": "auto"}` (the default) and `tool_choice: {"type": "none"}` are compatible with extended thinking.&para;<br>&lt;/Note&gt;&para;<br>&para;<br>Our testing has shown that this should not reduce performance. If you would like the model to provide natural language context or explanations while still requesting that the model use a specific tool, you can use `{"type": "auto"}` for `tool_choice` (the default) and add explicit instructions in a `user` message. For example: `What's the weather like in London? Use the get_weather tool in your response.`&para;<br>&para;<br>&lt;Tip&gt;&para;<br>**Guaranteed tool calls with strict tools**&para;<br>&para;<br>Combine `tool_choice: {"type": "any"}` with [strict tool use](/docs/en/build-with-claude/structured-outputs) to guarantee both that one of your tools will be called AND that the tool inputs strictly follow your schema. Set `strict: true` on your tool definitions to enable schema validation.&para;<br>&lt;/Tip&gt;&para;<br>&para;<br>### JSON output&para;<br>&para;<br>Tools do not necessarily need to be client functions — you can use tools anytime you want the model to return JSON output that follows a provided schema. For example, you might use a `record_summary` tool with a particular schema. See [Tool use with Claude](/docs/en/agents-and-tools/tool-use/overview) for a full working example.&para;<br>&para;<br>### Model responses with tools&para;<br>&para;<br>When using tools, Claude will often comment on what it's doing or respond naturally to the user before invoking tools.&para;<br>&para;<br>For example, given the prompt "What's the weather like in San Francisco right now, and what time is it there?", Claude might respond with:&para;<br>&para;<br>```json JSON&para;<br>{&para;<br>  "role": "assistant",&para;<br>  "content": [&para;<br>    {&para;<br>      "type": "text",&para;<br>      "text": "I'll help you check the current weather and time in San Francisco."&para;<br>    },&para;<br>    {&para;<br>      "type": "tool_use",&para;<br>      "id": "toolu_01A09q90qw90lq917835lq9",&para;<br>      "name": "get_weather",&para;<br>      "input": {"location": "San Francisco, CA"}&para;<br>    }&para;<br>  ]&para;<br>}&para;<br>```&para;<br>&para;<br>This natural response style helps users understand what Claude is doing and creates a more conversational interaction. You can guide the style and content of these responses through your system prompts and by providing `&lt;examples&gt;` in your prompts.&para;<br>&para;<br>It's important to note that Claude may use various phrasings and approaches when explaining its actions. Your code should treat these responses like any other assistant-generated text, and not rely on specific formatting conventions.&para;<br>&para;<br>### Parallel tool use&para;<br>&para;<br>By default, Claude may use multiple tools to answer a user query. You can disable this behavior by:&para;<br>&para;<br>- Setting `disable_parallel_tool_use=true` when tool_choice type is `auto`, which ensures that Claude uses **at most one** tool&para;<br>- Setting `disable_parallel_tool_use=true` when tool_choice type is `any` or `tool`, which ensures that Claude uses **exactly one** tool&para;<br>&para;<br>&lt;section title="Complete parallel tool use example"&gt;&para;<br>&para;<br>&lt;Note&gt;&para;<br>**Simpler with Tool runner**: The example below shows manual parallel tool handling. For most use cases, [tool runner](#tool-runner-beta) automatically handle parallel tool execution with much less code.&para;<br>&lt;/Note&gt;&para;<br>&para;<br>Here's a complete example showing how to properly format parallel tool calls in the message history:&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>```python Python&para;<br>import anthropic&para;<br>&para;<br>client = anthropic.Anthropic()&para;<br>&para;<br># Define tools&para;<br>tools = [&para;<br>    {&para;<br>        "name": "get_weather",&para;<br>        "description": "Get the current weather in a given location",&para;<br>        "input_schema": {&para;<br>            "type": "object",&para;<br>            "properties": {&para;<br>                "location": {&para;<br>                    "type": "string",&para;<br>                    "description": "The city and state, e.g. San Francisco, CA"&para;<br>                }&para;<br>            },&para;<br>            "required": ["location"]&para;<br>        }&para;<br>    },&para;<br>    {&para;<br>        "name": "get_time",&para;<br>        "description": "Get the current time in a given timezone",&para;<br>        "input_schema": {&para;<br>            "type": "object",&para;<br>            "properties": {&para;<br>                "timezone": {&para;<br>                    "type": "string",&para;<br>                    "description": "The timezone, e.g. America/New_York"&para;<br>                }&para;<br>            },&para;<br>            "required": ["timezone"]&para;<br>        }&para;<br>    }&para;<br>]&para;<br>&para;<br># Initial request&para;<br>response = client.messages.create(&para;<br>    model="claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>",&para;<br>    max_tokens=1024,&para;<br>    tools=tools,&para;<br>    messages=[&para;<br>        {&para;<br>            "role": "user",&para;<br>            "content": "What's the weather in SF and NYC, and what time is it there?"&para;<br>        }&para;<br>    ]&para;<br>)&para;<br>&para;<br># Claude's response with parallel tool calls&para;<br>print("Claude wants to use tools:", response.stop_reason == "tool_use")&para;<br>print("Number of tool calls:", len([c for c in response.content if c.type == "tool_use"]))&para;<br>&para;<br># Build the conversation with tool results&para;<br>messages = [&para;<br>    {&para;<br>        "role": "user",&para;<br>        "content": "What's the weather in SF and NYC, and what time is it there?"&para;<br>    },&para;<br>    {&para;<br>        "role": "assistant",&para;<br>        "content": response.content  # Contains multiple tool_use blocks&para;<br>    },&para;<br>    {&para;<br>        "role": "user",&para;<br>        "content": [&para;<br>            {&para;<br>                "type": "tool_result",&para;<br>                "tool_use_id": "toolu_01",  # Must match the ID from tool_use&para;<br>                "content": "San Francisco: 68°F, partly cloudy"&para;<br>            },&para;<br>            {&para;<br>                "type": "tool_result",&para;<br>                "tool_use_id": "toolu_02",&para;<br>                "content": "New York: 45°F, clear skies"&para;<br>            },&para;<br>            {&para;<br>                "type": "tool_result",&para;<br>                "tool_use_id": "toolu_03",&para;<br>                "content": "San Francisco time: 2:30 PM PST"&para;<br>            },&para;<br>            {&para;<br>                "type": "tool_result",&para;<br>                "tool_use_id": "toolu_04",&para;<br>                "content": "New York time: 5:30 PM EST"&para;<br>            }&para;<br>        ]&para;<br>    }&para;<br>]&para;<br>&para;<br># Get final response&para;<br>final_response = client.messages.create(&para;<br>    model="claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>",&para;<br>    max_tokens=1024,&para;<br>    tools=tools,&para;<br>    messages=messages&para;<br>)&para;<br>&para;<br>print(final_response.content[0].text)&para;<br>```&para;<br>&para;<br>```typescript TypeScript&para;<br>import { Anthropic } from '@anthropic-ai/sdk';&para;<br>&para;<br>const anthropic = new Anthropic();&para;<br>&para;<br>// Define tools&para;<br>const tools = [&para;<br>  {&para;<br>    name: "get_weather",&para;<br>    description: "Get the current weather in a given location",&para;<br>    input_schema: {&para;<br>      type: "object",&para;<br>      properties: {&para;<br>        location: {&para;<br>          type: "string",&para;<br>          description: "The city and state, e.g. San Francisco, CA"&para;<br>        }&para;<br>      },&para;<br>      required: ["location"]&para;<br>    }&para;<br>  },&para;<br>  {&para;<br>    name: "get_time",&para;<br>    description: "Get the current time in a given timezone",&para;<br>    input_schema: {&para;<br>      type: "object",&para;<br>      properties: {&para;<br>        timezone: {&para;<br>          type: "string",&para;<br>          description: "The timezone, e.g. America/New_York"&para;<br>        }&para;<br>      },&para;<br>      required: ["timezone"]&para;<br>    }&para;<br>  }&para;<br>];&para;<br>&para;<br>// Initial request&para;<br>const response = await anthropic.messages.create({&para;<br>  model: "claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>",&para;<br>  max_tokens: 1024,&para;<br>  tools: tools,&para;<br>  messages: [&para;<br>    {&para;<br>      role: "user",&para;<br>      content: "What's the weather in SF and NYC, and what time is it there?"&para;<br>    }&para;<br>  ]&para;<br>});&para;<br>&para;<br>// Build conversation with tool results&para;<br>const messages = [&para;<br>  {&para;<br>    role: "user",&para;<br>    content: "What's the weather in SF and NYC, and what time is it there?"&para;<br>  },&para;<br>  {&para;<br>    role: "assistant",&para;<br>    content: response.content  // Contains multiple tool_use blocks&para;<br>  },&para;<br>  {&para;<br>    role: "user",&para;<br>    content: [&para;<br>      {&para;<br>        type: "tool_result",&para;<br>        tool_use_id: "toolu_01",  // Must match the ID from tool_use&para;<br>        content: "San Francisco: 68°F, partly cloudy"&para;<br>      },&para;<br>      {&para;<br>        type: "tool_result",&para;<br>        tool_use_id: "toolu_02",&para;<br>        content: "New York: 45°F, clear skies"&para;<br>      },&para;<br>      {&para;<br>        type: "tool_result",&para;<br>        tool_use_id: "toolu_03",&para;<br>        content: "San Francisco time: 2:30 PM PST"&para;<br>      },&para;<br>      {&para;<br>        type: "tool_result",&para;<br>        tool_use_id: "toolu_04",&para;<br>        content: "New York time: 5:30 PM EST"&para;<br>      }&para;<br>    ]&para;<br>  }&para;<br>];&para;<br>&para;<br>// Get final response&para;<br>const finalResponse = await anthropic.messages.create({&para;<br>  model: "claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>",&para;<br>  max_tokens: 1024,&para;<br>  tools: tools,&para;<br>  messages: messages&para;<br>});&para;<br>&para;<br>console.log(finalResponse.content[0].text);&para;<br>```&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>The assistant message with parallel tool calls would look like this:&para;<br>&para;<br>```json&para;<br>{&para;<br>  "role": "assistant",&para;<br>  "content": [&para;<br>    {&para;<br>      "type": "text",&para;<br>      "text": "I'll check the weather and time for both San Francisco and New York City."&para;<br>    },&para;<br>    {&para;<br>      "type": "tool_use",&para;<br>      "id": "toolu_01",&para;<br>      "name": "get_weather",&para;<br>      "input": {"location": "San Francisco, CA"}&para;<br>    },&para;<br>    {&para;<br>      "type": "tool_use",&para;<br>      "id": "toolu_02",&para;<br>      "name": "get_weather",&para;<br>      "input": {"location": "New York, NY"}&para;<br>    },&para;<br>    {&para;<br>      "type": "tool_use",&para;<br>      "id": "toolu_03",&para;<br>      "name": "get_time",&para;<br>      "input": {"timezone": "America/Los_Angeles"}&para;<br>    },&para;<br>    {&para;<br>      "type": "tool_use",&para;<br>      "id": "toolu_04",&para;<br>      "name": "get_time",&para;<br>      "input": {"timezone": "America/New_York"}&para;<br>    }&para;<br>  ]&para;<br>}&para;<br>```&para;<br>&para;<br>&lt;/section&gt;&para;<br>&lt;section title="Complete test script for parallel tools"&gt;&para;<br>&para;<br>Here's a complete, runnable script to test and verify parallel tool calls are working correctly:&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>```python Python&para;<br>#!/usr/bin/env python3&para;<br>"""Test script to verify parallel tool calls with the Claude API"""&para;<br>&para;<br>import os&para;<br>from anthropic import Anthropic&para;<br>&para;<br># Initialize client&para;<br>client = Anthropic(api_key=os.environ.get("ANTHROPIC_API_KEY"))&para;<br>&para;<br># Define tools&para;<br>tools = [&para;<br>    {&para;<br>        "name": "get_weather",&para;<br>        "description": "Get the current weather in a given location",&para;<br>        "input_schema": {&para;<br>            "type": "object",&para;<br>            "properties": {&para;<br>                "location": {&para;<br>                    "type": "string",&para;<br>                    "description": "The city and state, e.g. San Francisco, CA"&para;<br>                }&para;<br>            },&para;<br>            "required": ["location"]&para;<br>        }&para;<br>    },&para;<br>    {&para;<br>        "name": "get_time",&para;<br>        "description": "Get the current time in a given timezone",&para;<br>        "input_schema": {&para;<br>            "type": "object",&para;<br>            "properties": {&para;<br>                "timezone": {&para;<br>                    "type": "string",&para;<br>                    "description": "The timezone, e.g. America/New_York"&para;<br>                }&para;<br>            },&para;<br>            "required": ["timezone"]&para;<br>        }&para;<br>    }&para;<br>]&para;<br>&para;<br># Test conversation with parallel tool calls&para;<br>messages = [&para;<br>    {&para;<br>        "role": "user",&para;<br>        "content": "What's the weather in SF and NYC, and what time is it there?"&para;<br>    }&para;<br>]&para;<br>&para;<br># Make initial request&para;<br>print("Requesting parallel tool calls...")&para;<br>response = client.messages.create(&para;<br>    model="claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>",&para;<br>    max_tokens=1024,&para;<br>    messages=messages,&para;<br>    tools=tools&para;<br>)&para;<br>&para;<br># Check for parallel tool calls&para;<br>tool_uses = [block for block in response.content if block.type == "tool_use"]&para;<br>print(f"\n✓ Claude made {len(tool_uses)} tool calls")&para;<br>&para;<br>if len(tool_uses) &gt; 1:&para;<br>    print("✓ Parallel tool calls detected!")&para;<br>    for tool in tool_uses:&para;<br>        print(f"  - {tool.name}: {tool.input}")&para;<br>else:&para;<br>    print("✗ No parallel tool calls detected")&para;<br>&para;<br># Simulate tool execution and format results correctly&para;<br>tool_results = []&para;<br>for tool_use in tool_uses:&para;<br>    if tool_use.name == "get_weather":&para;<br>        if "San Francisco" in str(tool_use.input):&para;<br>            result = "San Francisco: 68°F, partly cloudy"&para;<br>        else:&para;<br>            result = "New York: 45°F, clear skies"&para;<br>    else:  # get_time&para;<br>        if "Los_Angeles" in str(tool_use.input):&para;<br>            result = "2:30 PM PST"&para;<br>        else:&para;<br>            result = "5:30 PM EST"&para;<br>&para;<br>    tool_results.append({&para;<br>        "type": "tool_result",&para;<br>        "tool_use_id": tool_use.id,&para;<br>        "content": result&para;<br>    })&para;<br>&para;<br># Continue conversation with tool results&para;<br>messages.extend([&para;<br>    {"role": "assistant", "content": response.content},&para;<br>    {"role": "user", "content": tool_results}  # All results in one message!&para;<br>])&para;<br>&para;<br># Get final response&para;<br>print("\nGetting final response...")&para;<br>final_response = client.messages.create(&para;<br>    model="claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>",&para;<br>    max_tokens=1024,&para;<br>    messages=messages,&para;<br>    tools=tools&para;<br>)&para;<br>&para;<br>print(f"\nClaude's response:\n{final_response.content[0].text}")&para;<br>&para;<br># Verify formatting&para;<br>print("\n--- Verification ---")&para;<br>print(f"✓ Tool results sent in single user message: {len(tool_results)} results")&para;<br>print("✓ No text before tool results in content array")&para;<br>print("✓ Conversation formatted correctly for future parallel tool use")&para;<br>```&para;<br>&para;<br>```typescript TypeScript&para;<br>#!/usr/bin/env node&para;<br>// Test script to verify parallel tool calls with the Claude API&para;<br>&para;<br>import { Anthropic } from '@anthropic-ai/sdk';&para;<br>&para;<br>const anthropic = new Anthropic({&para;<br>  apiKey: process.env.ANTHROPIC_API_KEY&para;<br>});&para;<br>&para;<br>// Define tools&para;<br>const tools = [&para;<br>  {&para;<br>    name: "get_weather",&para;<br>    description: "Get the current weather in a given location",&para;<br>    input_schema: {&para;<br>      type: "object",&para;<br>      properties: {&para;<br>        location: {&para;<br>          type: "string",&para;<br>          description: "The city and state, e.g. San Francisco, CA"&para;<br>        }&para;<br>      },&para;<br>      required: ["location"]&para;<br>    }&para;<br>  },&para;<br>  {&para;<br>    name: "get_time",&para;<br>    description: "Get the current time in a given timezone",&para;<br>    input_schema: {&para;<br>      type: "object",&para;<br>      properties: {&para;<br>        timezone: {&para;<br>          type: "string",&para;<br>          description: "The timezone, e.g. America/New_York"&para;<br>        }&para;<br>      },&para;<br>      required: ["timezone"]&para;<br>    }&para;<br>  }&para;<br>];&para;<br>&para;<br>async function testParallelTools() {&para;<br>  // Make initial request&para;<br>  console.log("Requesting parallel tool calls...");&para;<br>  const response = await anthropic.messages.create({&para;<br>    model: "claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>",&para;<br>    max_tokens: 1024,&para;<br>    messages: [{&para;<br>      role: "user",&para;<br>      content: "What's the weather in SF and NYC, and what time is it there?"&para;<br>    }],&para;<br>    tools: tools&para;<br>  });&para;<br>&para;<br>  // Check for parallel tool calls&para;<br>  const toolUses = response.content.filter(block =&gt; block.type === "tool_use");&para;<br>  console.log(`\n✓ Claude made ${toolUses.length} tool calls`);&para;<br>&para;<br>  if (toolUses.length &gt; 1) {&para;<br>    console.log("✓ Parallel tool calls detected!");&para;<br>    toolUses.forEach(tool =&gt; {&para;<br>      console.log(`  - ${tool.name}: ${JSON.stringify(tool.input)}`);&para;<br>    });&para;<br>  } else {&para;<br>    console.log("✗ No parallel tool calls detected");&para;<br>  }&para;<br>&para;<br>  // Simulate tool execution and format results correctly&para;<br>  const toolResults = toolUses.map(toolUse =&gt; {&para;<br>    let result;&para;<br>    if (toolUse.name === "get_weather") {&para;<br>      result = toolUse.input.location.includes("San Francisco")&para;<br>        ? "San Francisco: 68°F, partly cloudy"&para;<br>        : "New York: 45°F, clear skies";&para;<br>    } else {&para;<br>      result = toolUse.input.timezone.includes("Los_Angeles")&para;<br>        ? "2:30 PM PST"&para;<br>        : "5:30 PM EST";&para;<br>    }&para;<br>&para;<br>    return {&para;<br>      type: "tool_result",&para;<br>      tool_use_id: toolUse.id,&para;<br>      content: result&para;<br>    };&para;<br>  });&para;<br>&para;<br>  // Get final response with correct formatting&para;<br>  console.log("\nGetting final response...");&para;<br>  const finalResponse = await anthropic.messages.create({&para;<br>    model: "claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>",&para;<br>    max_tokens: 1024,&para;<br>    messages: [&para;<br>      { role: "user", content: "What's the weather in SF and NYC, and what time is it there?" },&para;<br>      { role: "assistant", content: response.content },&para;<br>      { role: "user", content: toolResults }  // All results in one message!&para;<br>    ],&para;<br>    tools: tools&para;<br>  });&para;<br>&para;<br>  console.log(`\nClaude's response:\n${finalResponse.content[0].text}`);&para;<br>&para;<br>  // Verify formatting&para;<br>  console.log("\n--- Verification ---");&para;<br>  console.log(`✓ Tool results sent in single user message: ${toolResults.length} results`);&para;<br>  console.log("✓ No text before tool results in content array");&para;<br>  console.log("✓ Conversation formatted correctly for future parallel tool use");&para;<br>}&para;<br>&para;<br>testParallelTools().catch(console.error);&para;<br>```&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>This script demonstrates:&para;<br>- How to properly format parallel tool calls and results&para;<br>- How to verify that parallel calls are being made&para;<br>- The correct message structure that encourages future parallel tool use&para;<br>- Common mistakes to avoid (like text before tool results)&para;<br>&para;<br>Run this script to test your implementation and ensure Claude is making parallel tool calls effectively.&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>#### Maximizing parallel tool use&para;<br>&para;<br>While Claude 4 models have excellent parallel tool use capabilities by default, you can increase the likelihood of parallel tool execution across all models with targeted prompting:&para;<br>&para;<br>&lt;section title="System prompts for parallel tool use"&gt;&para;<br>&para;<br>For Claude 4 models (Opus 4, and Sonnet 4), add this to your system prompt:&para;<br>```text&para;<br>For maximum efficiency, whenever you need to perform multiple independent operations, invoke all relevant tools simultaneously rather than sequentially.&para;<br>```&para;<br>&para;<br>For even stronger parallel tool use (recommended if the default isn't sufficient), use:&para;<br>```text&para;<br>&lt;use_parallel_tool_calls&gt;&para;<br>For maximum efficiency, whenever you perform multiple independent operations, invoke all relevant tools simultaneously rather than sequentially. Prioritize calling tools in parallel whenever possible. For example, when reading 3 files, run 3 tool calls in parallel to read all 3 files into context at the same time. When running multiple read-only commands like `ls` or `list_dir`, always run all of the commands in parallel. Err on the side of maximizing parallel tool calls rather than running too many tools sequentially.&para;<br>&lt;/use_parallel_tool_calls&gt;&para;<br>```&para;<br>&para;<br>&lt;/section&gt;&para;<br>&lt;section title="User message prompting"&gt;&para;<br>&para;<br>You can also encourage parallel tool use within specific user messages:&para;<br>&para;<br>```python&para;<br># Instead of:&para;<br>"What's the weather in Paris? Also check London."&para;<br>&para;<br># Use:&para;<br>"Check the weather in Paris and London simultaneously."&para;<br>&para;<br># Or be explicit:&para;<br>"Please use parallel tool calls to get the weather for Paris, London, and Tokyo at the same time."&para;<br>```&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>&lt;Warning&gt;&para;<br>**Parallel tool use with Claude Sonnet 3.7**&para;<br>&para;<br>Claude Sonnet 3.7 may be less likely to make make parallel tool calls in a response, even when you have not set `disable_parallel_tool_use`. We recommend [upgrading to Claude 4 models](/docs/en/about-claude/models/migrati</span><del style="background:#ffe6e6;">ng-to-claude-4</del><ins style="background:#e6ffe6;">on-guide</ins><span>), which have built-in token-efficient tool use and improved parallel tool calling.&para;<br>&para;<br>If you're still using Claude Sonnet 3.7, you can enable the `token-efficient-tools-2025-02-19` [beta header](/docs/en/api/beta-headers), which helps encourage Claude to use parallel tools. You can also introduce a "batch tool" that can act as a meta-tool to wrap invocations to other tools simultaneously.&para;<br>&para;<br>See [this example](https://platform.claude.com/cookbook/tool-use-parallel-tools) in our cookbook for how to use this workaround.&para;<br>&para;<br>&lt;/Warning&gt;&para;<br>&para;<br>## Handling tool use and tool result content blocks&para;<br>&para;<br>&lt;Note&gt;&para;<br>**Simpler with Tool runner**: The manual tool handling described in this section is automatically managed by [tool runner](#tool-runner-beta). Use this section when you need custom control over tool execution.&para;<br>&lt;/Note&gt;&para;<br>&para;<br>Claude's response differs based on whether it uses a client or server tool.&para;<br>&para;<br>### Handling results from client tools&para;<br>&para;<br>The response will have a `stop_reason` of `tool_use` and one or more `tool_use` content blocks that include:&para;<br>&para;<br>- `id`: A unique identifier for this particular tool use block. This will be used to match up the tool results later.&para;<br>- `name`: The name of the tool being used.&para;<br>- `input`: An object containing the input being passed to the tool, conforming to the tool's `input_schema`.&para;<br>&para;<br>&lt;section title="Example API response with a `tool_use` content block"&gt;&para;<br>&para;<br>```json JSON&para;<br>{&para;<br>  "id": "msg_01Aq9w938a90dw8q",&para;<br>  "model": "claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>",&para;<br>  "stop_reason": "tool_use",&para;<br>  "role": "assistant",&para;<br>  "content": [&para;<br>    {&para;<br>      "type": "text",&para;<br>      "text": "I'll check the current weather in San Francisco for you."&para;<br>    },&para;<br>    {&para;<br>      "type": "tool_use",&para;<br>      "id": "toolu_01A09q90qw90lq917835lq9",&para;<br>      "name": "get_weather",&para;<br>      "input": {"location": "San Francisco, CA", "unit": "celsius"}&para;<br>    }&para;<br>  ]&para;<br>}&para;<br>```&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>When you receive a tool use response for a client tool, you should:&para;<br>&para;<br>1. Extract the `name`, `id`, and `input` from the `tool_use` block.&para;<br>2. Run the actual tool in your codebase corresponding to that tool name, passing in the tool `input`.&para;<br>3. Continue the conversation by sending a new message with the `role` of `user`, and a `content` block containing the `tool_result` type and the following information:&para;<br>   - `tool_use_id`: The `id` of the tool use request this is a result for.&para;<br>   - `content`: The result of the tool, as a string (e.g. `"content": "15 degrees"`), a list of nested content blocks (e.g. `"content": [{"type": "text", "text": "15 degrees"}]`), or a list of document blocks (e.g. `"content": ["type": "document", "source": {"type": "text", "media_type": "text/plain", "data": "15 degrees"}]`). These content blocks can use the `text`, `image`, or `document` types.&para;<br>   - `is_error` (optional): Set to `true` if the tool execution resulted in an error.&para;<br>&para;<br>&lt;Note&gt;&para;<br>**Important formatting requirements**:&para;<br>- Tool result blocks must immediately follow their corresponding tool use blocks in the message history. You cannot include any messages between the assistant's tool use message and the user's tool result message.&para;<br>- In the user message containing tool results, the tool_result blocks must come FIRST in the content array. Any text must come AFTER all tool results.&para;<br>&para;<br>For example, this will cause a 400 error:&para;<br>```json&para;<br>{"role": "user", "content": [&para;<br>  {"type": "text", "text": "Here are the results:"},  // ❌ Text before tool_result&para;<br>  {"type": "tool_result", "tool_use_id": "toolu_01", ...}&para;<br>]}&para;<br>```&para;<br>&para;<br>This is correct:&para;<br>```json&para;<br>{"role": "user", "content": [&para;<br>  {"type": "tool_result", "tool_use_id": "toolu_01", ...},&para;<br>  {"type": "text", "text": "What should I do next?"}  // ✅ Text after tool_result&para;<br>]}&para;<br>```&para;<br>&para;<br>If you receive an error like "tool_use ids were found without tool_result blocks immediately after", check that your tool results are formatted correctly.&para;<br>&lt;/Note&gt;&para;<br>&para;<br>&lt;section title="Example of successful tool result"&gt;&para;<br>&para;<br>```json JSON&para;<br>{&para;<br>  "role": "user",&para;<br>  "content": [&para;<br>    {&para;<br>      "type": "tool_result",&para;<br>      "tool_use_id": "toolu_01A09q90qw90lq917835lq9",&para;<br>      "content": "15 degrees"&para;<br>    }&para;<br>  ]&para;<br>}&para;<br>```&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>&lt;section title="Example of tool result with images"&gt;&para;<br>&para;<br>```json JSON&para;<br>{&para;<br>  "role": "user",&para;<br>  "content": [&para;<br>    {&para;<br>      "type": "tool_result",&para;<br>      "tool_use_id": "toolu_01A09q90qw90lq917835lq9",&para;<br>      "content": [&para;<br>        {"type": "text", "text": "15 degrees"},&para;<br>        {&para;<br>          "type": "image",&para;<br>          "source": {&para;<br>            "type": "base64",&para;<br>            "media_type": "image/jpeg",&para;<br>            "data": "/9j/4AAQSkZJRg...",&para;<br>          }&para;<br>        }&para;<br>      ]&para;<br>    }&para;<br>  ]&para;<br>}&para;<br>```&para;<br>&para;<br>&lt;/section&gt;&para;<br>&lt;section title="Example of empty tool result"&gt;&para;<br>&para;<br>```json JSON&para;<br>{&para;<br>  "role": "user",&para;<br>  "content": [&para;<br>    {&para;<br>      "type": "tool_result",&para;<br>      "tool_use_id": "toolu_01A09q90qw90lq917835lq9",&para;<br>    }&para;<br>  ]&para;<br>}&para;<br>```&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>&lt;section title="Example of tool result with documents"&gt;&para;<br>&para;<br>```json JSON&para;<br>{&para;<br>  "role": "user",&para;<br>  "content": [&para;<br>    {&para;<br>      "type": "tool_result",&para;<br>      "tool_use_id": "toolu_01A09q90qw90lq917835lq9",&para;<br>      "content": [&para;<br>        {"type": "text", "text": "The weather is"},&para;<br>        {&para;<br>          "type": "document",&para;<br>          "source": {&para;<br>            "type": "text",&para;<br>            "media_type": "text/plain",&para;<br>            "data": "15 degrees"&para;<br>          }&para;<br>        }&para;<br>      ]&para;<br>    }&para;<br>  ]&para;<br>}&para;<br>```&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>After receiving the tool result, Claude will use that information to continue generating a response to the original user prompt.&para;<br>&para;<br>### Handling results from server tools&para;<br>&para;<br>Claude executes the tool internally and incorporates the results directly into its response without requiring additional user interaction.&para;<br>&para;<br>&lt;Tip&gt;&para;<br>  **Differences from other APIs**&para;<br>&para;<br>Unlike APIs that separate tool use or use special roles like `tool` or `function`, the Claude API integrates tools directly into the `user` and `assistant` message structure.&para;<br>&para;<br>Messages contain arrays of `text`, `image`, `tool_use`, and `tool_result` blocks. `user` messages include client content and `tool_result`, while `assistant` messages contain AI-generated content and `tool_use`.&para;<br>&para;<br>&lt;/Tip&gt;&para;<br>&para;<br>### Handling the `max_tokens` stop reason&para;<br>&para;<br>If Claude's [response is cut off due to hitting the `max_tokens` limit](/docs/en/build-with-claude/handling-stop-reasons#max-tokens), and the truncated response contains an incomplete tool use block, you'll need to retry the request with a higher `max_tokens` value to get the full tool use.&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>```python Python&para;<br># Check if response was truncated during tool use&para;<br>if response.stop_reason == "max_tokens":&para;<br>    # Check if the last content block is an incomplete tool_use&para;<br>    last_block = response.content[-1]&para;<br>    if last_block.type == "tool_use":&para;<br>        # Send the request with higher max_tokens&para;<br>        response = client.messages.create(&para;<br>            model="claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>",&para;<br>            max_tokens=4096,  # Increased limit&para;<br>            messages=messages,&para;<br>            tools=tools&para;<br>        )&para;<br>```&para;<br>&para;<br>```typescript TypeScript&para;<br>// Check if response was truncated during tool use&para;<br>if (response.stop_reason === "max_tokens") {&para;<br>  // Check if the last content block is an incomplete tool_use&para;<br>  const lastBlock = response.content[response.content.length - 1];&para;<br>  if (lastBlock.type === "tool_use") {&para;<br>    // Send the request with higher max_tokens&para;<br>    response = await anthropic.messages.create({&para;<br>      model: "claude-</span><del style="background:#ffe6e6;">sonnet</del><ins style="background:#e6ffe6;">opus</ins><span>-4-</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>",&para;<br>      max_tokens: 4096, // Increased limit&para;<br>      messages: messages,&para;<br>      tools: tools&para;<br>    });&para;<br>  }&para;<br>}&para;<br>```&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>#### Handling the `pause_turn` stop reason&para;<br>&para;<br>When using server tools like web search, the API may return a `pause_turn` stop reason, indicating that the API has paused a long-running turn.&para;<br>&para;<br>Here's how to handle the `pause_turn` stop reason:&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>```python Python&para;<br>import anthropic&para;<br>&para;<br>client = anthropic.Anthropic()&para;<br>&para;<br># Initial request with web search&para;<br>response = client.messages.create(&para;<br>    model="claude-3-7-sonnet-latest",&para;<br>    max_tokens=1024,&para;<br>    messages=[&para;<br>        {&para;<br>            "role": "user",&para;<br>            "content": "Search for comprehensive information about quantum computing breakthroughs in 2025"&para;<br>        }&para;<br>    ],&para;<br>    tools=[{&para;<br>        "type": "web_search_20250305",&para;<br>        "name": "web_search",&para;<br>        "max_uses": 10&para;<br>    }]&para;<br>)&para;<br>&para;<br># Check if the response has pause_turn stop reason&para;<br>if response.stop_reason == "pause_turn":&para;<br>    # Continue the conversation with the paused content&para;<br>    messages = [&para;<br>        {"role": "user", "content": "Search for comprehensive information about quantum computing breakthroughs in 2025"},&para;<br>        {"role": "assistant", "content": response.content}&para;<br>    ]&para;<br>&para;<br>    # Send the continuation request&para;<br>    continuation = client.messages.create(&para;<br>        model="claude-3-7-sonnet-latest",&para;<br>        max_tokens=1024,&para;<br>        messages=messages,&para;<br>        tools=[{&para;<br>            "type": "web_search_20250305",&para;<br>            "name": "web_search",&para;<br>            "max_uses": 10&para;<br>        }]&para;<br>    )&para;<br>&para;<br>    print(continuation)&para;<br>else:&para;<br>    print(response)&para;<br>```&para;<br>&para;<br>```typescript TypeScript&para;<br>import { Anthropic } from '@anthropic-ai/sdk';&para;<br>&para;<br>const anthropic = new Anthropic();&para;<br>&para;<br>// Initial request with web search&para;<br>const response = await anthropic.messages.create({&para;<br>  model: "claude-3-7-sonnet-latest",&para;<br>  max_tokens: 1024,&para;<br>  messages: [&para;<br>    {&para;<br>      role: "user",&para;<br>      content: "Search for comprehensive information about quantum computing breakthroughs in 2025"&para;<br>    }&para;<br>  ],&para;<br>  tools: [{&para;<br>    type: "web_search_20250305",&para;<br>    name: "web_search",&para;<br>    max_uses: 10&para;<br>  }]&para;<br>});&para;<br>&para;<br>// Check if the response has pause_turn stop reason&para;<br>if (response.stop_reason === "pause_turn") {&para;<br>  // Continue the conversation with the paused content&para;<br>  const messages = [&para;<br>    { role: "user", content: "Search for comprehensive information about quantum computing breakthroughs in 2025" },&para;<br>    { role: "assistant", content: response.content }&para;<br>  ];&para;<br>&para;<br>  // Send the continuation request&para;<br>  const continuation = await anthropic.messages.create({&para;<br>    model: "claude-3-7-sonnet-latest",&para;<br>    max_tokens: 1024,&para;<br>    messages: messages,&para;<br>    tools: [{&para;<br>      type: "web_search_20250305",&para;<br>      name: "web_search",&para;<br>      max_uses: 10&para;<br>    }]&para;<br>  });&para;<br>&para;<br>  console.log(continuation);&para;<br>} else {&para;<br>  console.log(response);&para;<br>}&para;<br>```&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>When handling `pause_turn`:&para;<br>- **Continue the conversation**: Pass the paused response back as-is in a subsequent request to let Claude continue its turn&para;<br>- **Modify if needed**: You can optionally modify the content before continuing if you want to interrupt or redirect the conversation&para;<br>- **Preserve tool state**: Include the same tools in the continuation request to maintain functionality&para;<br>&para;<br>## Troubleshooting errors&para;<br>&para;<br>&lt;Note&gt;&para;<br>**Built-in Error Handling**: [Tool runner](#tool-runner-beta) provide automatic error handling for most common scenarios. This section covers manual error handling for advanced use cases.&para;<br>&lt;/Note&gt;&para;<br>&para;<br>There are a few different types of errors that can occur when using tools with Claude:&para;<br>&para;<br>&lt;section title="Tool execution error"&gt;&para;<br>&para;<br>If the tool itself throws an error during execution (e.g. a network error when fetching weather data), you can return the error message in the `content` along with `"is_error": true`:&para;<br>&para;<br>```json JSON&para;<br>{&para;<br>  "role": "user",&para;<br>  "content": [&para;<br>    {&para;<br>      "type": "tool_result",&para;<br>      "tool_use_id": "toolu_01A09q90qw90lq917835lq9",&para;<br>      "content": "ConnectionError: the weather service API is not available (HTTP 500)",&para;<br>      "is_error": true&para;<br>    }&para;<br>  ]&para;<br>}&para;<br>```&para;<br>&para;<br>Claude will then incorporate this error into its response to the user, e.g. "I'm sorry, I was unable to retrieve the current weather because the weather service API is not available. Please try again later."&para;<br>&para;<br>&lt;/section&gt;&para;<br>&lt;section title="Invalid tool name"&gt;&para;<br>&para;<br>If Claude's attempted use of a tool is invalid (e.g. missing required parameters), it usually means that the there wasn't enough information for Claude to use the tool correctly. Your best bet during development is to try the request again with more-detailed `description` values in your tool definitions.&para;<br>&para;<br>However, you can also continue the conversation forward with a `tool_result` that indicates the error, and Claude will try to use the tool again with the missing information filled in:&para;<br>&para;<br>```json JSON&para;<br>{&para;<br>  "role": "user",&para;<br>  "content": [&para;<br>    {&para;<br>      "type": "tool_result",&para;<br>      "tool_use_id": "toolu_01A09q90qw90lq917835lq9",&para;<br>      "content": "Error: Missing required 'location' parameter",&para;<br>      "is_error": true&para;<br>    }&para;<br>  ]&para;<br>}&para;<br>```&para;<br>&para;<br>If a tool request is invalid or missing parameters, Claude will retry 2-3 times with corrections before apologizing to the user.&para;<br>&para;<br>&lt;Tip&gt;&para;<br>To eliminate invalid tool calls entirely, use [strict tool use](/docs/en/build-with-claude/structured-outputs) with `strict: true` on your tool definitions. This guarantees that tool inputs will always match your schema exactly, preventing missing parameters and type mismatches.&para;<br>&lt;/Tip&gt;&para;<br>&para;<br>&lt;/section&gt;&para;<br>&lt;section title="&lt;search_quality_reflection&gt; tags"&gt;&para;<br>&para;<br>To prevent Claude from reflecting on search quality with \&lt;search_quality_reflection&gt; tags, add "Do not reflect on the quality of the returned search results in your response" to your prompt.&para;<br>&para;<br>&lt;/section&gt;&para;<br>&lt;section title="Server tool errors"&gt;&para;<br>&para;<br>When server tools encounter errors (e.g., network issues with Web Search), Claude will transparently handle these errors and attempt to provide an alternative response or explanation to the user. Unlike client tools, you do not need to handle `is_error` results for server tools.&para;<br>&para;<br>For web search specifically, possible error codes include:&para;<br>- `too_many_requests`: Rate limit exceeded&para;<br>- `invalid_input`: Invalid search query parameter&para;<br>- `max_uses_exceeded`: Maximum web search tool uses exceeded&para;<br>- `query_too_long`: Query exceeds maximum length&para;<br>- `unavailable`: An internal error occurred&para;<br>&para;<br>&lt;/section&gt;&para;<br>&lt;section title="Parallel tool calls not working"&gt;&para;<br>&para;<br>If Claude isn't making parallel tool calls when expected, check these common issues:&para;<br>&para;<br>**1. Incorrect tool result formatting**&para;<br>&para;<br>The most common issue is formatting tool results incorrectly in the conversation history. This "teaches" Claude to avoid parallel calls.&para;<br>&para;<br>Specifically for parallel tool use:&para;<br>- ❌ **Wrong**: Sending separate user messages for each tool result&para;<br>- ✅ **Correct**: All tool results must be in a single user message&para;<br>&para;<br>```json&para;<br>// ❌ This reduces parallel tool use&para;<br>[&para;<br>  {"role": "assistant", "content": [tool_use_1, tool_use_2]},&para;<br>  {"role": "user", "content": [tool_result_1]},&para;<br>  {"role": "user", "content": [tool_result_2]}  // Separate message&para;<br>]&para;<br>&para;<br>// ✅ This maintains parallel tool use&para;<br>[&para;<br>  {"role": "assistant", "content": [tool_use_1, tool_use_2]},&para;<br>  {"role": "user", "content": [tool_result_1, tool_result_2]}  // Single message&para;<br>]&para;<br>```&para;<br>&para;<br>See the [general formatting requirements above](#handling-tool-use-and-tool-result-content-blocks) for other formatting rules.&para;<br>&para;<br>**2. Weak prompting**&para;<br>&para;<br>Default prompting may not be sufficient. Use stronger language:&para;<br>&para;<br>```text&para;<br>&lt;use_parallel_tool_calls&gt;&para;<br>For maximum efficiency, whenever you perform multiple independent operations,&para;<br>invoke all relevant tools simultaneously rather than sequentially.&para;<br>Prioritize calling tools in parallel whenever possible.&para;<br>&lt;/use_parallel_tool_calls&gt;&para;<br>```&para;<br>&para;<br>**3. Measuring parallel tool usage**&para;<br>&para;<br>To verify parallel tool calls are working:&para;<br>&para;<br>```python&para;<br># Calculate average tools per tool-calling message&para;<br>tool_call_messages = [msg for msg in messages if any(&para;<br>    block.type == "tool_use" for block in msg.content&para;<br>)]&para;<br>total_tool_calls = sum(&para;<br>    len([b for b in msg.content if b.type == "tool_use"])&para;<br>    for msg in tool_call_messages&para;<br>)&para;<br>avg_tools_per_message = total_tool_calls / len(tool_call_messages)&para;<br>print(f"Average tools per message: {avg_tools_per_message}")&para;<br># Should be &gt; 1.0 if parallel calls are working&para;<br>```&para;<br>&para;<br>**4. Model-specific behavior**&para;<br>&para;<br>- Claude</span><ins style="background:#e6ffe6;"> Opus 4.6, Sonnet 4.5,</ins><span> Opus 4.5, Opus 4.1, and Sonnet 4: Excel at parallel tool use with minimal prompting&para;<br>- Claude Sonnet 3.7: May need stronger prompting or the `token-efficient-tools-2025-02-19` [beta header](/docs/en/api/beta-headers). Consider [upgrading to Claude 4](/docs/en/about-claude/models/migrati</span><del style="background:#ffe6e6;">ng-to-claude-4</del><ins style="background:#e6ffe6;">on-guide</ins><span>).&para;<br>- Claude Haiku: Less likely to use parallel tools without explicit prompting&para;<br>&para;<br>&lt;/section&gt;</span></div>
        </div>

        <h2 style="margin-top: 2rem; margin-bottom: 1rem;">Unified Diff</h2>
        <pre><code>--- a/agents-and-tools/tool-use/implement-tool-use.md
+++ b/agents-and-tools/tool-use/implement-tool-use.md
@@ -4,7 +4,7 @@
 
 ## Choosing a model
 
-We recommend using the latest Claude Sonnet (4.5) or Claude Opus (4.5) model for complex tools and ambiguous queries; they handle multiple tools better and seek clarification when needed.
+We recommend using the latest Claude Opus (4.6) model for complex tools and ambiguous queries; it handles multiple tools better and seeks clarification when needed.
 
 Use Claude Haiku models for straightforward tools, but note they may infer missing parameters.
 
@@ -129,7 +129,7 @@
 | Provider | Beta header | Supported models |
 |----------|-------------|------------------|
 | Claude API,&lt;br/&gt;Microsoft Foundry | `advanced-tool-use-2025-11-20` | All models |
-| Vertex AI,&lt;br/&gt;Amazon Bedrock | `tool-examples-2025-10-29` | Claude Opus 4.5 only |
+| Vertex AI,&lt;br/&gt;Amazon Bedrock | `tool-examples-2025-10-29` | Claude Opus 4.6, Claude Opus 4.5 |
 &lt;/Info&gt;
 
 ### Basic usage
@@ -143,7 +143,7 @@
 client = anthropic.Anthropic()
 
 response = client.messages.create(
-    model=&#34;claude-sonnet-4-5-20250929&#34;,
+    model=&#34;claude-opus-4-6&#34;,
     max_tokens=1024,
     betas=[&#34;advanced-tool-use-2025-11-20&#34;],
     tools=[
@@ -192,7 +192,7 @@
 const client = new Anthropic();
 
 const response = await client.messages.create({
-  model: &#34;claude-sonnet-4-5-20250929&#34;,
+  model: &#34;claude-opus-4-6&#34;,
   max_tokens: 1024,
   betas: [&#34;advanced-tool-use-2025-11-20&#34;],
   tools: [
@@ -309,7 +309,7 @@
 
 # Use the tool runner
 runner = client.beta.messages.tool_runner(
-    model=&#34;claude-sonnet-4-5&#34;,
+    model=&#34;claude-opus-4-6&#34;,
     max_tokens=1024,
     tools=[get_weather, calculate_sum],
     messages=[
@@ -377,7 +377,7 @@
 });
 
 const runner = anthropic.beta.messages.toolRunner({
-  model: &#39;claude-sonnet-4-5&#39;,
+  model: &#39;claude-opus-4-6&#39;,
   max_tokens: 1024,
   tools: [getWeatherTool],
   messages: [{ role: &#39;user&#39;, content: &#34;What&#39;s the weather like in Paris?&#34; }]
@@ -417,7 +417,7 @@
 });
 
 const runner = anthropic.beta.messages.toolRunner({
-  model: &#39;claude-sonnet-4-5&#39;,
+  model: &#39;claude-opus-4-6&#39;,
   max_tokens: 1024,
   tools: [calculateSumTool],
   messages: [{ role: &#39;user&#39;, content: &#34;What&#39;s 15 + 27?&#34; }]
@@ -473,7 +473,7 @@
 
 # Use the tool runner
 runner = client.beta.messages.tool_runner(
-  model: &#34;claude-sonnet-4-5&#34;,
+  model: &#34;claude-opus-4-6&#34;,
   max_tokens: 1024,
   tools: [GetWeather.new, CalculateSum.new],
   messages: [
@@ -510,7 +510,7 @@
 
 ```python
 runner = client.beta.messages.tool_runner(
-    model=&#34;claude-sonnet-4-5&#34;,
+    model=&#34;claude-opus-4-6&#34;,
     max_tokens=1024,
     tools=[get_weather, calculate_sum],
     messages=[
@@ -528,7 +528,7 @@
 
 ```typescript
 const runner = anthropic.beta.messages.toolRunner({
-  model: &#39;claude-sonnet-4-5&#39;,
+  model: &#39;claude-opus-4-6&#39;,
   max_tokens: 1024,
   tools: [getWeatherTool],
   messages: [{ role: &#39;user&#39;, content: &#34;What&#39;s the weather like in Paris?&#34; }]
@@ -545,7 +545,7 @@
 
 ```ruby
 runner = client.beta.messages.tool_runner(
-  model: &#34;claude-sonnet-4-5&#34;,
+  model: &#34;claude-opus-4-6&#34;,
   max_tokens: 1024,
   tools: [GetWeather.new, CalculateSum.new],
   messages: [
@@ -571,7 +571,7 @@
 
 ```python
 runner = client.beta.messages.tool_runner(
-    model=&#34;claude-sonnet-4-5&#34;,
+    model=&#34;claude-opus-4-6&#34;,
     max_tokens=1024,
     tools=[get_weather],
     messages=[{&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;What&#39;s the weather in San Francisco?&#34;}]
@@ -601,7 +601,7 @@
 
 ```typescript
 const runner = anthropic.beta.messages.toolRunner({
-  model: &#39;claude-sonnet-4-5&#39;,
+  model: &#39;claude-opus-4-6&#39;,
   max_tokens: 1024,
   tools: [getWeatherTool],
   messages: [{ role: &#39;user&#39;, content: &#34;What&#39;s the weather in San Francisco?&#34; }]
@@ -634,7 +634,7 @@
 
 ```ruby
 runner = client.beta.messages.tool_runner(
-  model: &#34;claude-sonnet-4-5&#34;,
+  model: &#34;claude-opus-4-6&#34;,
   max_tokens: 1024,
   tools: [GetWeather.new],
   messages: [{role: &#34;user&#34;, content: &#34;What&#39;s the weather in San Francisco?&#34;}]
@@ -685,7 +685,7 @@
 import json
 
 runner = client.beta.messages.tool_runner(
-    model=&#34;claude-sonnet-4-5&#34;,
+    model=&#34;claude-opus-4-6&#34;,
     max_tokens=1024,
     tools=[my_tool],
     messages=[{&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Run the tool&#34;}]
@@ -713,7 +713,7 @@
 
 ```typescript
 const runner = anthropic.beta.messages.toolRunner({
-  model: &#39;claude-sonnet-4-5&#39;,
+  model: &#39;claude-opus-4-6&#39;,
   max_tokens: 1024,
   tools: [myTool],
   messages: [{ role: &#39;user&#39;, content: &#39;Run the tool&#39; }]
@@ -745,7 +745,7 @@
 
 ```ruby
 runner = client.beta.messages.tool_runner(
-  model: &#34;claude-sonnet-4-5&#34;,
+  model: &#34;claude-opus-4-6&#34;,
   max_tokens: 1024,
   tools: [MyTool.new],
   messages: [{role: &#34;user&#34;, content: &#34;Run the tool&#34;}]
@@ -787,7 +787,7 @@
 
 ```python
 runner = client.beta.messages.tool_runner(
-    model=&#34;claude-sonnet-4-5&#34;,
+    model=&#34;claude-opus-4-6&#34;,
     max_tokens=1024,
     tools=[search_documents],
     messages=[{&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Search for information about the climate of San Francisco&#34;}]
@@ -814,7 +814,7 @@
 
 ```typescript
 const runner = anthropic.beta.messages.toolRunner({
-  model: &#39;claude-sonnet-4-5&#39;,
+  model: &#39;claude-opus-4-6&#39;,
   max_tokens: 1024,
   tools: [searchDocuments],
   messages: [{ role: &#39;user&#39;, content: &#39;Search for information about the climate of San Francisco&#39; }]
@@ -845,7 +845,7 @@
 
 ```ruby
 runner = client.beta.messages.tool_runner(
-  model: &#34;claude-sonnet-4-5&#34;,
+  model: &#34;claude-opus-4-6&#34;,
   max_tokens: 1024,
   tools: [SearchDocuments.new],
   messages: [{role: &#34;user&#34;, content: &#34;Search for information about the climate of San Francisco&#34;}]
@@ -891,7 +891,7 @@
 
 ```python
 runner = client.beta.messages.tool_runner(
-    model=&#34;claude-sonnet-4-5&#34;,
+    model=&#34;claude-opus-4-6&#34;,
     max_tokens=1024,
     tools=[calculate_sum],
     messages=[{&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;What is 15 + 27?&#34;}],
@@ -914,7 +914,7 @@
 
 ```typescript
 const runner = anthropic.beta.messages.toolRunner({
-  model: &#39;claude-sonnet-4-5-20250929&#39;,
+  model: &#39;claude-opus-4-6&#39;,
   max_tokens: 1000,
   messages: [{ role: &#39;user&#39;, content: &#39;What is the weather in San Francisco?&#39; }],
   tools: [getWeatherTool],
@@ -939,7 +939,7 @@
 
 ```ruby
 runner = client.beta.messages.tool_runner(
-  model: &#34;claude-sonnet-4-5&#34;,
+  model: &#34;claude-opus-4-6&#34;,
   max_tokens: 1024,
   tools: [CalculateSum.new],
   messages: [{role: &#34;user&#34;, content: &#34;What is 15 + 27?&#34;}]
@@ -1090,7 +1090,7 @@
 
 # Initial request
 response = client.messages.create(
-    model=&#34;claude-sonnet-4-5&#34;,
+    model=&#34;claude-opus-4-6&#34;,
     max_tokens=1024,
     tools=tools,
     messages=[
@@ -1144,7 +1144,7 @@
 
 # Get final response
 final_response = client.messages.create(
-    model=&#34;claude-sonnet-4-5&#34;,
+    model=&#34;claude-opus-4-6&#34;,
     max_tokens=1024,
     tools=tools,
     messages=messages
@@ -1192,7 +1192,7 @@
 
 // Initial request
 const response = await anthropic.messages.create({
-  model: &#34;claude-sonnet-4-5&#34;,
+  model: &#34;claude-opus-4-6&#34;,
   max_tokens: 1024,
   tools: tools,
   messages: [
@@ -1242,7 +1242,7 @@
 
 // Get final response
 const finalResponse = await anthropic.messages.create({
-  model: &#34;claude-sonnet-4-5&#34;,
+  model: &#34;claude-opus-4-6&#34;,
   max_tokens: 1024,
   tools: tools,
   messages: messages
@@ -1349,7 +1349,7 @@
 # Make initial request
 print(&#34;Requesting parallel tool calls...&#34;)
 response = client.messages.create(
-    model=&#34;claude-sonnet-4-5&#34;,
+    model=&#34;claude-opus-4-6&#34;,
     max_tokens=1024,
     messages=messages,
     tools=tools
@@ -1395,7 +1395,7 @@
 # Get final response
 print(&#34;\nGetting final response...&#34;)
 final_response = client.messages.create(
-    model=&#34;claude-sonnet-4-5&#34;,
+    model=&#34;claude-opus-4-6&#34;,
     max_tokens=1024,
     messages=messages,
     tools=tools
@@ -1456,7 +1456,7 @@
   // Make initial request
   console.log(&#34;Requesting parallel tool calls...&#34;);
   const response = await anthropic.messages.create({
-    model: &#34;claude-sonnet-4-5&#34;,
+    model: &#34;claude-opus-4-6&#34;,
     max_tokens: 1024,
     messages: [{
       role: &#34;user&#34;,
@@ -1501,7 +1501,7 @@
   // Get final response with correct formatting
   console.log(&#34;\nGetting final response...&#34;);
   const finalResponse = await anthropic.messages.create({
-    model: &#34;claude-sonnet-4-5&#34;,
+    model: &#34;claude-opus-4-6&#34;,
     max_tokens: 1024,
     messages: [
       { role: &#34;user&#34;, content: &#34;What&#39;s the weather in SF and NYC, and what time is it there?&#34; },
@@ -1573,7 +1573,7 @@
 &lt;Warning&gt;
 **Parallel tool use with Claude Sonnet 3.7**
 
-Claude Sonnet 3.7 may be less likely to make make parallel tool calls in a response, even when you have not set `disable_parallel_tool_use`. We recommend [upgrading to Claude 4 models](/docs/en/about-claude/models/migrating-to-claude-4), which have built-in token-efficient tool use and improved parallel tool calling.
+Claude Sonnet 3.7 may be less likely to make make parallel tool calls in a response, even when you have not set `disable_parallel_tool_use`. We recommend [upgrading to Claude 4 models](/docs/en/about-claude/models/migration-guide), which have built-in token-efficient tool use and improved parallel tool calling.
 
 If you&#39;re still using Claude Sonnet 3.7, you can enable the `token-efficient-tools-2025-02-19` [beta header](/docs/en/api/beta-headers), which helps encourage Claude to use parallel tools. You can also introduce a &#34;batch tool&#34; that can act as a meta-tool to wrap invocations to other tools simultaneously.
 
@@ -1602,7 +1602,7 @@
 ```json JSON
 {
   &#34;id&#34;: &#34;msg_01Aq9w938a90dw8q&#34;,
-  &#34;model&#34;: &#34;claude-sonnet-4-5&#34;,
+  &#34;model&#34;: &#34;claude-opus-4-6&#34;,
   &#34;stop_reason&#34;: &#34;tool_use&#34;,
   &#34;role&#34;: &#34;assistant&#34;,
   &#34;content&#34;: [
@@ -1769,7 +1769,7 @@
     if last_block.type == &#34;tool_use&#34;:
         # Send the request with higher max_tokens
         response = client.messages.create(
-            model=&#34;claude-sonnet-4-5&#34;,
+            model=&#34;claude-opus-4-6&#34;,
             max_tokens=4096,  # Increased limit
             messages=messages,
             tools=tools
@@ -1784,7 +1784,7 @@
   if (lastBlock.type === &#34;tool_use&#34;) {
     // Send the request with higher max_tokens
     response = await anthropic.messages.create({
-      model: &#34;claude-sonnet-4-5&#34;,
+      model: &#34;claude-opus-4-6&#34;,
       max_tokens: 4096, // Increased limit
       messages: messages,
       tools: tools
@@ -2036,8 +2036,8 @@
 
 **4. Model-specific behavior**
 
-- Claude Opus 4.5, Opus 4.1, and Sonnet 4: Excel at parallel tool use with minimal prompting
-- Claude Sonnet 3.7: May need stronger prompting or the `token-efficient-tools-2025-02-19` [beta header](/docs/en/api/beta-headers). Consider [upgrading to Claude 4](/docs/en/about-claude/models/migrating-to-claude-4).
+- Claude Opus 4.6, Sonnet 4.5, Opus 4.5, Opus 4.1, and Sonnet 4: Excel at parallel tool use with minimal prompting
+- Claude Sonnet 3.7: May need stronger prompting or the `token-efficient-tools-2025-02-19` [beta header](/docs/en/api/beta-headers). Consider [upgrading to Claude 4](/docs/en/about-claude/models/migration-guide).
 - Claude Haiku: Less likely to use parallel tools without explicit prompting
 
 &lt;/section&gt;</code></pre>
    </div>
</body>
</html>