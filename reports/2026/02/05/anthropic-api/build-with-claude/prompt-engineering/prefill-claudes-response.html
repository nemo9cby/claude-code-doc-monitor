<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>build-with-claude/prompt-engineering/prefill-claudes-response - Diff Report</title>
    <link rel="stylesheet" href="../../css/diff.css">
    <style>
        :root {
            --bg-color: #1a1a2e;
            --card-bg: #16213e;
            --text-color: #eee;
            --accent: #0f3460;
            --add-bg: #1a4d1a;
            --del-bg: #4d1a1a;
            --add-text: #4ade80;
            --del-text: #f87171;
        }
        @media (prefers-color-scheme: light) {
            :root {
                --bg-color: #f5f5f5;
                --card-bg: #fff;
                --text-color: #333;
                --accent: #e0e0e0;
                --add-bg: #d4edda;
                --del-bg: #f8d7da;
                --add-text: #155724;
                --del-text: #721c24;
            }
        }
        * { box-sizing: border-box; margin: 0; padding: 0; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: var(--bg-color);
            color: var(--text-color);
            line-height: 1.6;
            padding: 2rem;
        }
        .container { max-width: 1200px; margin: 0 auto; }
        header { margin-bottom: 2rem; }
        h1 { font-size: 1.5rem; margin-bottom: 0.5rem; }
        .meta { color: #888; font-size: 0.9rem; }
        .summary {
            background: var(--card-bg);
            padding: 1rem;
            border-radius: 8px;
            margin-bottom: 2rem;
            display: flex;
            gap: 2rem;
        }
        .stat { display: flex; align-items: center; gap: 0.5rem; }
        .stat.added { color: var(--add-text); }
        .stat.removed { color: var(--del-text); }
        .analysis {
            background: var(--card-bg);
            padding: 1.5rem;
            border-radius: 8px;
            margin-bottom: 2rem;
            border-left: 4px solid #8b5cf6;
        }
        .analysis-header {
            font-weight: 600;
            margin-bottom: 0.75rem;
            color: #8b5cf6;
        }
        .analysis-content {
            white-space: pre-wrap;
            font-size: 0.95rem;
            line-height: 1.7;
        }
        .diff-container {
            background: var(--card-bg);
            border-radius: 8px;
            overflow: hidden;
        }
        .diff-header {
            background: var(--accent);
            padding: 0.75rem 1rem;
            font-weight: 600;
        }
        .diff-content {
            padding: 1rem;
            overflow-x: auto;
        }
        .diff-content ins {
            background: var(--add-bg);
            color: var(--add-text);
            text-decoration: none;
            padding: 0.1em 0.2em;
            border-radius: 2px;
        }
        .diff-content del {
            background: var(--del-bg);
            color: var(--del-text);
            text-decoration: line-through;
            padding: 0.1em 0.2em;
            border-radius: 2px;
        }
        pre {
            background: var(--accent);
            padding: 1rem;
            border-radius: 8px;
            overflow-x: auto;
            font-size: 0.85rem;
            margin-top: 2rem;
        }
        a { color: #60a5fa; }
        .back-link { margin-bottom: 1rem; display: inline-block; }
    </style>
</head>
<body>
    <div class="container">
        <a href="../../../index.html" class="back-link">&larr; Back to daily report</a>

        <header>
            <h1>build-with-claude/prompt-engineering/prefill-claudes-response.md</h1>
            <p class="meta">Changed on 2026-02-05 12:43:36 EST</p>
        </header>

        <div class="summary">
            <div class="stat added">
                <span>+39</span> lines added
            </div>
            <div class="stat removed">
                <span>-48</span> lines removed
            </div>
        </div>

        

        <div class="diff-container">
            <div class="diff-header">Visual Diff</div>
            <div class="diff-content"><span># Pr</span><del style="background:#ffe6e6;">efill Claude's response for greater output control</del><ins style="background:#e6ffe6;">ompt engineering overview</ins><span>&para;<br>&para;<br>---&para;<br>&para;<br>&lt;Note&gt;&para;<br>While these tips apply broadly to all Claude models, you can find prompting tips specific to extended thinking models [here](/docs/en/build-with-claude/prompt-engineering/extended-thinking-tips).&para;<br>&lt;/Note&gt;&para;<br>&para;<br></span><del style="background:#ffe6e6;">&lt;Note&gt;&para;<br>Prefilling is only available for non-extended thinking modes. It's not currently supported with extended thinking.&para;<br>&lt;/Note&gt;&para;<br>&para;<br>When using Claude, you have the unique ability to guide its responses by prefilling the `Assistant` message. This powerful technique allows you to direct Claude's actions, skip preambles, enforce specific formats like JSON or XML, and even help Claude maintain character consistency in role-play scenarios.&para;<br>&para;<br>In some cases where Claude is not performing as expected, a few prefilled sentences can vastly improve Claude's performance. A little prefilling goes a long way!&para;<br>&para;<br>## How to prefill Claude's response&para;<br>&para;<br>To prefill, include the desired initial text in the `Assistant` message (Claude's response will continue from where the `Assistant` message leaves off):&para;<br>&para;<br>```python&para;<br>import anthropic&para;<br>&para;<br>client = anthropic.Anthropic()&para;<br>response = client.messages.create(&para;<br>    model="claude-sonnet-4-5",&para;<br>    max_tokens=1024,&para;<br>    messages=[&para;<br>        {"role": "user", "content": "What is your favorite color?"},&para;<br>        {"role": "assistant", "content": "As an AI assistant, I don't have a favorite color, But if I had to pick, it would be green because"}  # Prefill here&para;<br>    ]&para;<br>)&para;<br>```&para;<br>&para;<br>&lt;Warning&gt;&para;<br>  The prefill content cannot end with trailing whitespace. A prefill like `"As an AI assistant, I "` (with a space at the end) will result in an error.&para;<br>&lt;/Warning&gt;&para;<br>&para;<br>### Examples&para;<br>&para;<br>#### Example 1: Controlling output formatting and skipping the preamble&para;<br>&para;<br>&lt;Tip&gt;**Power user tip**: Prefilling `{` forces Claude to skip the preamble and directly output the JSON object. This is cleaner, more concise, and easier for programs to parse without additional processing.&para;<br>For guaranteed JSON output that conforms to a specific schema, consider using [Structured Outputs](/docs/en/build-with-claude/structured-outputs) instead of prefilling. Structured outputs ensure Claude's response always matches your defined JSON schema, making it ideal for production applications that require strict format compliance.&lt;/Tip&gt;&para;<br>&para;<br>    &lt;section title="Example: Structured data extraction without prefilling"&gt;&para;<br>&para;<br>    | Role | Content |&para;<br>    | ---- | ------- |&para;<br>    | User | Extract the name, size, price, and color from this product description as a JSON object:&lt;br/&gt;&lt;br/&gt;\&lt;description&gt;&lt;br/&gt;The SmartHome Mini is a compact smart home assistant available in black or white for only \$49.99. At just 5 inches wide, it lets you control lights, thermostats, and other connected devices via voice or app—no matter where you place it in your home. This affordable little hub brings convenient hands-free control to your smart devices.&lt;br/&gt;\&lt;/description&gt; |&para;<br>    | Assistant | Here's the extracted information in JSON format:&lt;br/&gt;&lt;br/&gt;\`\`\`json&lt;br/&gt;\{&lt;br/&gt;  "name": "SmartHome Mini",&lt;br/&gt;  "size": "5 inches wide",&lt;br/&gt;  "price": "\$49.99",&lt;br/&gt;  "colors": ["black", "white"]&lt;br/&gt;\}&lt;br/&gt;\`\`\`&lt;br/&gt;&lt;br/&gt;I've extracted the following details from the product description:&lt;br/&gt;- **Name**: SmartHome Mini&lt;br/&gt;- **Size**: 5 inches wide&lt;br/&gt;- **Price**: \$49.99&lt;br/&gt;- **Colors**: Available in black and white&lt;br/&gt;&lt;br/&gt;The JSON object provides a structured format that's easy for programs to parse and use. Let me know if you need any modifications or have any other questions! |&para;<br>    &para;<br>&lt;/section&gt;&para;<br>&para;<br>    &lt;section title="Example: Structured data extraction with prefilling"&gt;&para;<br>&para;<br>    | Role | Content |&para;<br>    | ---- | ------- |&para;<br>    | User | Extract the name, size, price, and color from this product description as a JSON object:&lt;br/&gt;&lt;br/&gt;\&lt;description&gt;&lt;br/&gt;The SmartHome Mini is a compact smart home assistant available in black or white for only \$49.99. At just 5 inches wide, it lets you control lights, thermostats, and other connected devices via voice or app—no matter where you place it in your home. This affordable little hub brings convenient hands-free control to your smart devices.&lt;br/&gt;\&lt;/description&gt; |&para;<br>    | Assistant (prefill) | \{ |&para;<br>    | Assistant (Claude's response) | "name": "SmartHome Mini",&lt;br/&gt;"size": "5 inches wide",&lt;br/&gt;"price": "\$49.99",&lt;br/&gt;"colors": [&lt;br/&gt;  "black",&lt;br/&gt;  "white"&lt;br/&gt;]&lt;br/&gt;\} |&para;<br>    &para;<br>&lt;/section&gt;&para;<br>&para;<br>#### Example 2: Maintaining character in roleplay scenarios&para;<br>&para;<br>&lt;Tip&gt;**Role-play tip**: Prefilling a bracketed `[ROLE_NAME]` can remind Claude stay in character, even for longer and more complex conversations. This is especially powerful when combined with role prompting in the `system` parameter.&lt;/Tip&gt;&para;<br>&para;<br>    &lt;section title="Example: Maintaining character without role prompting"&gt;&para;<br>&para;<br>    | Role | Content |&para;<br>    | ---- | ------- |&para;<br>    | User (50 conversation turns in with "Sherlock Holmes" Claude) | What do you deduce about the owner of this shoe? \&lt;image&gt;muddy_shoe.jpg\&lt;/image&gt; |&para;<br>    | Assistant | As an AI assistant, I would be happy to analyze the image of a muddy shoe as if you had provided it. Here's my deduction... |&para;<br>    &para;<br>&lt;/section&gt;&para;<br>&para;<br>    &lt;section title="Example: Maintaining character with role prompting"&gt;&para;<br>&para;<br>    | Role | Content |&para;<br>    | ---- | ------- |&para;<br>    | User (50 conversation turns in with "Sherlock Holmes" Claude) | What do you deduce about the owner of this shoe? &lt;br/&gt;\&lt;image&gt;muddy_shoe.jpg\&lt;/image&gt; |&para;<br>    | Assistant (prefill) | [Sherlock Holmes] |&para;<br>    | Assistant (Claude's response) | Ah, what have we here? A most curious specimen, Watson! Let us examine this shoe with a discerning eye. The mud, you see, is not your common London clay, but rather the distinctive reddish hue of the iron-rich soil found only in the environs of Hampstead Heath. And yet, the wear on the sole suggests a gait more suited to the cobblestones of Whitechapel than the gentle slopes of the Heath.&lt;br/&gt;&lt;br/&gt;Now, observe the laces! They are tied with a particular knot favored by those in the medical profession—doubtless a habit acquired during years of tying surgical gowns. But the scuff marks on the toe box tell a different tale: they are consistent with the kicking motion one might employ in the martial arts, specifically Baritsu.&lt;br/&gt;&lt;br/&gt;We may conclude, then, that our absent shoe owner is a doctor, possibly a surgeon, who resides in Whitechapel but frequents Hampstead Heath—perhaps for a secret Baritsu practice, away from prying eyes. A most intriguing case, Watson! We must make haste; the game is afoot! |&para;<br>    &para;<br>&lt;/section&gt;&para;<br>&para;<br>---&para;<br>&para;<br>&lt;CardGroup cols={3}&gt;&para;<br>  &lt;Card title="Working with Messages" icon="messages" href="/docs/en/build-with-claude/working-with-messages"&gt;&para;<br>    See more examples of prefill and other Messages API patterns.&para;<br>  &lt;/Card&gt;&para;<br>  &lt;Card title="Prompt library" icon="link" href="/docs/en/resources/prompt-library/library"&gt;&para;<br>    Get inspired by a curated selection of prompts for various tasks and use cases.&para;<br>  &lt;/Card</del><ins style="background:#e6ffe6;">## Before prompt engineering&para;<br>&para;<br>This guide assumes that you have:&para;<br>1. A clear definition of the success criteria for your use case&para;<br>2. Some ways to empirically test against those criteria&para;<br>3. A first draft prompt you want to improve&para;<br>&para;<br>If not, we highly suggest you spend time establishing that first. Check out [Define your success criteria](/docs/en/test-and-evaluate/define-success) and [Create strong empirical evaluations](/docs/en/test-and-evaluate/develop-tests) for tips and guidance.&para;<br>&para;<br>&lt;Card title="Prompt generator" icon="link" href="/dashboard"&gt;&para;<br>  Don't have a first draft prompt? Try the prompt generator in the Claude Console!&para;<br>&lt;/Card&gt;&para;<br>&para;<br>***&para;<br>&para;<br>## When to prompt engineer&para;<br>&para;<br>  This guide focuses on success criteria that are controllable through prompt engineering.&para;<br>  Not every success criteria or failing eval is best solved by prompt engineering. For example, latency and cost can be sometimes more easily improved by selecting a different model.&para;<br>&para;<br>&lt;section title="Prompting vs. finetuning"&gt;&para;<br>&para;<br>  Prompt engineering is far faster than other methods of model behavior control, such as finetuning, and can often yield leaps in performance in far less time. Here are some reasons to consider prompt engineering over finetuning:&lt;br/&gt;&para;<br>  - **Resource efficiency**: Fine-tuning requires high-end GPUs and large memory, while prompt engineering only needs text input, making it much more resource-friendly.&para;<br>  - **Cost-effectiveness**: For cloud-based AI services, fine-tuning incurs significant costs. Prompt engineering uses the base model, which is typically cheaper.&para;<br>  - **Maintaining model updates**: When providers update models, fine-tuned versions might need retraining. Prompts usually work across versions without changes.&para;<br>  - **Time-saving**: Fine-tuning can take hours or even days. In contrast, prompt engineering provides nearly instantaneous results, allowing for quick problem-solving.&para;<br>  - **Minimal data needs**: Fine-tuning needs substantial task-specific, labeled data, which can be scarce or expensive. Prompt engineering works with few-shot or even zero-shot learning.&para;<br>  - **Flexibility &amp; rapid iteration**: Quickly try various approaches, tweak prompts, and see immediate results. This rapid experimentation is difficult with fine-tuning.&para;<br>  - **Domain adaptation**: Easily adapt models to new domains by providing domain-specific context in prompts, without retraining.&para;<br>  - **Comprehension improvements**: Prompt engineering is far more effective than finetuning at helping models better understand and utilize external content such as retrieved documents&para;<br>  - **Preserves general knowledge**: Fine-tuning risks catastrophic forgetting, where the model loses general knowledge. Prompt engineering maintains the model's broad capabilities.&para;<br>  - **Transparency**: Prompts are human-readable, showing exactly what information the model receives. This transparency aids in understanding and debugging.&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>***&para;<br>&para;<br>## How to prompt engineer&para;<br>&para;<br>The prompt engineering pages in this section have been organized from most broadly effective techniques to more specialized techniques. When troubleshooting performance, we suggest you try these techniques in order, although the actual impact of each technique will depend on your use case.&para;<br>1. [Prompt generator](/docs/en/build-with-claude/prompt-engineering/prompt-generator)&para;<br>2. [Be clear and direct](/docs/en/build-with-claude/prompt-engineering/be-clear-and-direct)&para;<br>3. [Use examples (multishot)](/docs/en/build-with-claude/prompt-engineering/multishot-prompting)&para;<br>4. [Let Claude think (chain of thought)](/docs/en/build-with-claude/prompt-engineering/chain-of-thought)&para;<br>5. [Use XML tags](/docs/en/build-with-claude/prompt-engineering/use-xml-tags)&para;<br>6. [Give Claude a role (system prompts)](/docs/en/build-with-claude/prompt-engineering/system-prompts)&para;<br>7. [Chain complex prompts](/docs/en/build-with-claude/prompt-engineering/chain-prompts)&para;<br>8. [Long context tips](/docs/en/build-with-claude/prompt-engineering/long-context-tips)&para;<br>&para;<br>***&para;<br>&para;<br>## Prompt engineering tutorial&para;<br>&para;<br>If you're an interactive learner, you can dive into our interactive tutorials instead!&para;<br>&para;<br>&lt;CardGroup cols={2}</ins><span>&gt;&para;<br>  &lt;Card title="GitHub prompting tutorial" icon="link" href="https://github.com/anthropics/prompt-eng-interactive-tutorial"&gt;&para;<br>    An example-filled tutorial that covers the prompt engineering concepts found in our docs.&para;<br>  &lt;/Card&gt;&para;<br>  &lt;Card title="Google Sheets prompting tutorial" icon="link" href="https://docs.google.com/spreadsheets/d/19jzLgRruG9kjUQNKtCg1ZjdD6l6weA6qRXG5zLIAhC8"&gt;&para;<br>    A lighter weight version of our prompt engineering tutorial via an interactive spreadsheet.&para;<br>  &lt;/Card&gt;&para;<br>&lt;/CardGroup&gt;</span></div>
        </div>

        <h2 style="margin-top: 2rem; margin-bottom: 1rem;">Unified Diff</h2>
        <pre><code>--- a/build-with-claude/prompt-engineering/prefill-claudes-response.md
+++ b/build-with-claude/prompt-engineering/prefill-claudes-response.md
@@ -1,4 +1,4 @@
-# Prefill Claude&#39;s response for greater output control
+# Prompt engineering overview
 
 ---
 
@@ -6,94 +6,63 @@
 While these tips apply broadly to all Claude models, you can find prompting tips specific to extended thinking models [here](/docs/en/build-with-claude/prompt-engineering/extended-thinking-tips).
 &lt;/Note&gt;
 
-&lt;Note&gt;
-Prefilling is only available for non-extended thinking modes. It&#39;s not currently supported with extended thinking.
-&lt;/Note&gt;
+## Before prompt engineering
 
-When using Claude, you have the unique ability to guide its responses by prefilling the `Assistant` message. This powerful technique allows you to direct Claude&#39;s actions, skip preambles, enforce specific formats like JSON or XML, and even help Claude maintain character consistency in role-play scenarios.
+This guide assumes that you have:
+1. A clear definition of the success criteria for your use case
+2. Some ways to empirically test against those criteria
+3. A first draft prompt you want to improve
 
-In some cases where Claude is not performing as expected, a few prefilled sentences can vastly improve Claude&#39;s performance. A little prefilling goes a long way!
+If not, we highly suggest you spend time establishing that first. Check out [Define your success criteria](/docs/en/test-and-evaluate/define-success) and [Create strong empirical evaluations](/docs/en/test-and-evaluate/develop-tests) for tips and guidance.
 
-## How to prefill Claude&#39;s response
+&lt;Card title=&#34;Prompt generator&#34; icon=&#34;link&#34; href=&#34;/dashboard&#34;&gt;
+  Don&#39;t have a first draft prompt? Try the prompt generator in the Claude Console!
+&lt;/Card&gt;
 
-To prefill, include the desired initial text in the `Assistant` message (Claude&#39;s response will continue from where the `Assistant` message leaves off):
+***
 
-```python
-import anthropic
+## When to prompt engineer
 
-client = anthropic.Anthropic()
-response = client.messages.create(
-    model=&#34;claude-sonnet-4-5&#34;,
-    max_tokens=1024,
-    messages=[
-        {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;What is your favorite color?&#34;},
-        {&#34;role&#34;: &#34;assistant&#34;, &#34;content&#34;: &#34;As an AI assistant, I don&#39;t have a favorite color, But if I had to pick, it would be green because&#34;}  # Prefill here
-    ]
-)
-```
+  This guide focuses on success criteria that are controllable through prompt engineering.
+  Not every success criteria or failing eval is best solved by prompt engineering. For example, latency and cost can be sometimes more easily improved by selecting a different model.
 
-&lt;Warning&gt;
-  The prefill content cannot end with trailing whitespace. A prefill like `&#34;As an AI assistant, I &#34;` (with a space at the end) will result in an error.
-&lt;/Warning&gt;
+&lt;section title=&#34;Prompting vs. finetuning&#34;&gt;
 
-### Examples
+  Prompt engineering is far faster than other methods of model behavior control, such as finetuning, and can often yield leaps in performance in far less time. Here are some reasons to consider prompt engineering over finetuning:&lt;br/&gt;
+  - **Resource efficiency**: Fine-tuning requires high-end GPUs and large memory, while prompt engineering only needs text input, making it much more resource-friendly.
+  - **Cost-effectiveness**: For cloud-based AI services, fine-tuning incurs significant costs. Prompt engineering uses the base model, which is typically cheaper.
+  - **Maintaining model updates**: When providers update models, fine-tuned versions might need retraining. Prompts usually work across versions without changes.
+  - **Time-saving**: Fine-tuning can take hours or even days. In contrast, prompt engineering provides nearly instantaneous results, allowing for quick problem-solving.
+  - **Minimal data needs**: Fine-tuning needs substantial task-specific, labeled data, which can be scarce or expensive. Prompt engineering works with few-shot or even zero-shot learning.
+  - **Flexibility &amp; rapid iteration**: Quickly try various approaches, tweak prompts, and see immediate results. This rapid experimentation is difficult with fine-tuning.
+  - **Domain adaptation**: Easily adapt models to new domains by providing domain-specific context in prompts, without retraining.
+  - **Comprehension improvements**: Prompt engineering is far more effective than finetuning at helping models better understand and utilize external content such as retrieved documents
+  - **Preserves general knowledge**: Fine-tuning risks catastrophic forgetting, where the model loses general knowledge. Prompt engineering maintains the model&#39;s broad capabilities.
+  - **Transparency**: Prompts are human-readable, showing exactly what information the model receives. This transparency aids in understanding and debugging.
 
-#### Example 1: Controlling output formatting and skipping the preamble
-
-&lt;Tip&gt;**Power user tip**: Prefilling `{` forces Claude to skip the preamble and directly output the JSON object. This is cleaner, more concise, and easier for programs to parse without additional processing.
-For guaranteed JSON output that conforms to a specific schema, consider using [Structured Outputs](/docs/en/build-with-claude/structured-outputs) instead of prefilling. Structured outputs ensure Claude&#39;s response always matches your defined JSON schema, making it ideal for production applications that require strict format compliance.&lt;/Tip&gt;
-
-    &lt;section title=&#34;Example: Structured data extraction without prefilling&#34;&gt;
-
-    | Role | Content |
-    | ---- | ------- |
-    | User | Extract the name, size, price, and color from this product description as a JSON object:&lt;br/&gt;&lt;br/&gt;\&lt;description&gt;&lt;br/&gt;The SmartHome Mini is a compact smart home assistant available in black or white for only \$49.99. At just 5 inches wide, it lets you control lights, thermostats, and other connected devices via voice or app—no matter where you place it in your home. This affordable little hub brings convenient hands-free control to your smart devices.&lt;br/&gt;\&lt;/description&gt; |
-    | Assistant | Here&#39;s the extracted information in JSON format:&lt;br/&gt;&lt;br/&gt;\`\`\`json&lt;br/&gt;\{&lt;br/&gt;  &#34;name&#34;: &#34;SmartHome Mini&#34;,&lt;br/&gt;  &#34;size&#34;: &#34;5 inches wide&#34;,&lt;br/&gt;  &#34;price&#34;: &#34;\$49.99&#34;,&lt;br/&gt;  &#34;colors&#34;: [&#34;black&#34;, &#34;white&#34;]&lt;br/&gt;\}&lt;br/&gt;\`\`\`&lt;br/&gt;&lt;br/&gt;I&#39;ve extracted the following details from the product description:&lt;br/&gt;- **Name**: SmartHome Mini&lt;br/&gt;- **Size**: 5 inches wide&lt;br/&gt;- **Price**: \$49.99&lt;br/&gt;- **Colors**: Available in black and white&lt;br/&gt;&lt;br/&gt;The JSON object provides a structured format that&#39;s easy for programs to parse and use. Let me know if you need any modifications or have any other questions! |
-    
 &lt;/section&gt;
 
-    &lt;section title=&#34;Example: Structured data extraction with prefilling&#34;&gt;
+***
 
-    | Role | Content |
-    | ---- | ------- |
-    | User | Extract the name, size, price, and color from this product description as a JSON object:&lt;br/&gt;&lt;br/&gt;\&lt;description&gt;&lt;br/&gt;The SmartHome Mini is a compact smart home assistant available in black or white for only \$49.99. At just 5 inches wide, it lets you control lights, thermostats, and other connected devices via voice or app—no matter where you place it in your home. This affordable little hub brings convenient hands-free control to your smart devices.&lt;br/&gt;\&lt;/description&gt; |
-    | Assistant (prefill) | \{ |
-    | Assistant (Claude&#39;s response) | &#34;name&#34;: &#34;SmartHome Mini&#34;,&lt;br/&gt;&#34;size&#34;: &#34;5 inches wide&#34;,&lt;br/&gt;&#34;price&#34;: &#34;\$49.99&#34;,&lt;br/&gt;&#34;colors&#34;: [&lt;br/&gt;  &#34;black&#34;,&lt;br/&gt;  &#34;white&#34;&lt;br/&gt;]&lt;br/&gt;\} |
-    
-&lt;/section&gt;
+## How to prompt engineer
 
-#### Example 2: Maintaining character in roleplay scenarios
+The prompt engineering pages in this section have been organized from most broadly effective techniques to more specialized techniques. When troubleshooting performance, we suggest you try these techniques in order, although the actual impact of each technique will depend on your use case.
+1. [Prompt generator](/docs/en/build-with-claude/prompt-engineering/prompt-generator)
+2. [Be clear and direct](/docs/en/build-with-claude/prompt-engineering/be-clear-and-direct)
+3. [Use examples (multishot)](/docs/en/build-with-claude/prompt-engineering/multishot-prompting)
+4. [Let Claude think (chain of thought)](/docs/en/build-with-claude/prompt-engineering/chain-of-thought)
+5. [Use XML tags](/docs/en/build-with-claude/prompt-engineering/use-xml-tags)
+6. [Give Claude a role (system prompts)](/docs/en/build-with-claude/prompt-engineering/system-prompts)
+7. [Chain complex prompts](/docs/en/build-with-claude/prompt-engineering/chain-prompts)
+8. [Long context tips](/docs/en/build-with-claude/prompt-engineering/long-context-tips)
 
-&lt;Tip&gt;**Role-play tip**: Prefilling a bracketed `[ROLE_NAME]` can remind Claude stay in character, even for longer and more complex conversations. This is especially powerful when combined with role prompting in the `system` parameter.&lt;/Tip&gt;
+***
 
-    &lt;section title=&#34;Example: Maintaining character without role prompting&#34;&gt;
+## Prompt engineering tutorial
 
-    | Role | Content |
-    | ---- | ------- |
-    | User (50 conversation turns in with &#34;Sherlock Holmes&#34; Claude) | What do you deduce about the owner of this shoe? \&lt;image&gt;muddy_shoe.jpg\&lt;/image&gt; |
-    | Assistant | As an AI assistant, I would be happy to analyze the image of a muddy shoe as if you had provided it. Here&#39;s my deduction... |
-    
-&lt;/section&gt;
+If you&#39;re an interactive learner, you can dive into our interactive tutorials instead!
 
-    &lt;section title=&#34;Example: Maintaining character with role prompting&#34;&gt;
-
-    | Role | Content |
-    | ---- | ------- |
-    | User (50 conversation turns in with &#34;Sherlock Holmes&#34; Claude) | What do you deduce about the owner of this shoe? &lt;br/&gt;\&lt;image&gt;muddy_shoe.jpg\&lt;/image&gt; |
-    | Assistant (prefill) | [Sherlock Holmes] |
-    | Assistant (Claude&#39;s response) | Ah, what have we here? A most curious specimen, Watson! Let us examine this shoe with a discerning eye. The mud, you see, is not your common London clay, but rather the distinctive reddish hue of the iron-rich soil found only in the environs of Hampstead Heath. And yet, the wear on the sole suggests a gait more suited to the cobblestones of Whitechapel than the gentle slopes of the Heath.&lt;br/&gt;&lt;br/&gt;Now, observe the laces! They are tied with a particular knot favored by those in the medical profession—doubtless a habit acquired during years of tying surgical gowns. But the scuff marks on the toe box tell a different tale: they are consistent with the kicking motion one might employ in the martial arts, specifically Baritsu.&lt;br/&gt;&lt;br/&gt;We may conclude, then, that our absent shoe owner is a doctor, possibly a surgeon, who resides in Whitechapel but frequents Hampstead Heath—perhaps for a secret Baritsu practice, away from prying eyes. A most intriguing case, Watson! We must make haste; the game is afoot! |
-    
-&lt;/section&gt;
-
----
-
-&lt;CardGroup cols={3}&gt;
-  &lt;Card title=&#34;Working with Messages&#34; icon=&#34;messages&#34; href=&#34;/docs/en/build-with-claude/working-with-messages&#34;&gt;
-    See more examples of prefill and other Messages API patterns.
-  &lt;/Card&gt;
-  &lt;Card title=&#34;Prompt library&#34; icon=&#34;link&#34; href=&#34;/docs/en/resources/prompt-library/library&#34;&gt;
-    Get inspired by a curated selection of prompts for various tasks and use cases.
-  &lt;/Card&gt;
+&lt;CardGroup cols={2}&gt;
   &lt;Card title=&#34;GitHub prompting tutorial&#34; icon=&#34;link&#34; href=&#34;https://github.com/anthropics/prompt-eng-interactive-tutorial&#34;&gt;
     An example-filled tutorial that covers the prompt engineering concepts found in our docs.
   &lt;/Card&gt;
</code></pre>
    </div>
</body>
</html>