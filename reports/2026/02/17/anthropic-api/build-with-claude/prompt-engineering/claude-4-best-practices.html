<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>build-with-claude/prompt-engineering/claude-4-best-practices - Diff Report</title>
    <link rel="stylesheet" href="../../css/diff.css">
    <style>
        :root {
            --bg-color: #1a1a2e;
            --card-bg: #16213e;
            --text-color: #eee;
            --accent: #0f3460;
            --add-bg: #1a4d1a;
            --del-bg: #4d1a1a;
            --add-text: #4ade80;
            --del-text: #f87171;
        }
        @media (prefers-color-scheme: light) {
            :root {
                --bg-color: #f5f5f5;
                --card-bg: #fff;
                --text-color: #333;
                --accent: #e0e0e0;
                --add-bg: #d4edda;
                --del-bg: #f8d7da;
                --add-text: #155724;
                --del-text: #721c24;
            }
        }
        * { box-sizing: border-box; margin: 0; padding: 0; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: var(--bg-color);
            color: var(--text-color);
            line-height: 1.6;
            padding: 2rem;
        }
        .container { max-width: 1200px; margin: 0 auto; }
        header { margin-bottom: 2rem; }
        h1 { font-size: 1.5rem; margin-bottom: 0.5rem; }
        .meta { color: #888; font-size: 0.9rem; }
        .summary {
            background: var(--card-bg);
            padding: 1rem;
            border-radius: 8px;
            margin-bottom: 2rem;
            display: flex;
            gap: 2rem;
        }
        .stat { display: flex; align-items: center; gap: 0.5rem; }
        .stat.added { color: var(--add-text); }
        .stat.removed { color: var(--del-text); }
        .analysis {
            background: var(--card-bg);
            padding: 1.5rem;
            border-radius: 8px;
            margin-bottom: 2rem;
            border-left: 4px solid #8b5cf6;
        }
        .analysis-header {
            font-weight: 600;
            margin-bottom: 0.75rem;
            color: #8b5cf6;
        }
        .analysis-content {
            white-space: pre-wrap;
            font-size: 0.95rem;
            line-height: 1.7;
        }
        .diff-container {
            background: var(--card-bg);
            border-radius: 8px;
            overflow: hidden;
        }
        .diff-header {
            background: var(--accent);
            padding: 0.75rem 1rem;
            font-weight: 600;
        }
        .diff-content {
            padding: 1rem;
            overflow-x: auto;
        }
        .diff-content ins {
            background: var(--add-bg);
            color: var(--add-text);
            text-decoration: none;
            padding: 0.1em 0.2em;
            border-radius: 2px;
        }
        .diff-content del {
            background: var(--del-bg);
            color: var(--del-text);
            text-decoration: line-through;
            padding: 0.1em 0.2em;
            border-radius: 2px;
        }
        pre {
            background: var(--accent);
            padding: 1rem;
            border-radius: 8px;
            overflow-x: auto;
            font-size: 0.85rem;
            margin-top: 2rem;
        }
        a { color: #60a5fa; }
        .back-link { margin-bottom: 1rem; display: inline-block; }
    </style>
</head>
<body>
    <div class="container">
        <a href="../../../index.html" class="back-link">&larr; Back to daily report</a>

        <header>
            <h1>build-with-claude/prompt-engineering/claude-4-best-practices.md</h1>
            <p class="meta">Changed on 2026-02-17 13:51:08 EST</p>
        </header>

        <div class="summary">
            <div class="stat added">
                <span>+48</span> lines added
            </div>
            <div class="stat removed">
                <span>-14</span> lines removed
            </div>
        </div>

        

        <div class="diff-container">
            <div class="diff-header">Visual Diff</div>
            <div class="diff-content"><span># Prompting best practices&para;<br>&para;<br>---&para;<br>&para;<br>This guide provides prompt engineering techniques for Claude's latest models, including Claude Opus 4.6, Claude Sonnet 4.</span><del style="background:#ffe6e6;">5</del><ins style="background:#e6ffe6;">6</ins><span>, and Claude Haiku 4.5. These models have been trained for more precise instruction following than previous generations of Claude models.&para;<br></span><ins style="background:#e6ffe6;">&para;<br></ins><span>&lt;Tip&gt;&para;<br>  For an overview of model capabilities, see the [models overview](/docs/en/about-claude/models/overview). For details on what's new in Claude 4.6, see [What's new in Claude 4.6](/docs/en/about-claude/models/whats-new-claude-4-6). For migration guidance, see the [Migration guide](/docs/en/about-claude/models/migration-guide).&para;<br>&lt;/Tip&gt;&para;<br>&para;<br>## General principles&para;<br>&para;<br>### Be explicit with your instructions&para;<br>&para;<br>Claude responds well to clear, explicit instructions. Being specific about your desired output can help enhance results. If you want "above and beyond" behavior, explicitly request it rather than relying on the model to infer this from vague prompts.&para;<br>&para;<br>&lt;section title="Example: Creating an analytics dashboard"&gt;&para;<br>&para;<br>**Less effective:**&para;<br>```text&para;<br>Create an analytics dashboard&para;<br>```&para;<br>&para;<br>**More effective:**&para;<br>```text&para;<br>Create an analytics dashboard. Include as many relevant features and interactions as possible. Go beyond the basics to create a fully-featured implementation.&para;<br>```&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>### Add context to improve performance&para;<br>&para;<br>Providing context or motivation behind your instructions, such as explaining to Claude why such behavior is important, can help Claude better understand your goals and deliver more targeted responses.&para;<br>&para;<br>&lt;section title="Example: Formatting preferences"&gt;&para;<br>&para;<br>**Less effective:**&para;<br>```text&para;<br>NEVER use ellipses&para;<br>```&para;<br>&para;<br>**More effective:**&para;<br>```text&para;<br>Your response will be read aloud by a text-to-speech engine, so never use ellipses since the text-to-speech engine will not know how to pronounce them.&para;<br>```&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>Claude is smart enough to generalize from the explanation.&para;<br>&para;<br>### Be vigilant with examples &amp; details&para;<br>&para;<br>Claude pays close attention to details and examples as part of its precise instruction following capabilities. Ensure that your examples align with the behaviors you want to encourage and minimize behaviors you want to avoid.&para;<br>&para;<br>### Long-horizon reasoning and state tracking&para;<br>&para;<br>Claude's latest models excel at long-horizon reasoning tasks with exceptional state tracking capabilities. Claude maintains orientation across extended sessions by focusing on incremental progress—making steady advances on a few things at a time rather than attempting everything at once. This capability especially emerges over multiple context windows or task iterations, where Claude can work on a complex task, save the state, and continue with a fresh context window.&para;<br>&para;<br>#### Context awareness and multi-window workflows&para;<br>&para;<br>Claude </span><del style="background:#ffe6e6;">Opus </del><span>4.6 and Claude 4.5 models feature [context awareness](/docs/en/build-with-claude/context-windows#context-awareness-in-claude-sonnet-</span><ins style="background:#e6ffe6;">46-sonnet-</ins><span>45-and-haiku-45), enabling the model to track its remaining context window (i.e. "token budget") throughout a conversation. This enables Claude to execute tasks and manage context more effectively by understanding how much space it has to work.&para;<br>&para;<br>**Managing context limits:**&para;<br>&para;<br>If you are using Claude in an agent harness that compacts context or allows saving context to external files (like in Claude Code), we suggest adding this information to your prompt so Claude can behave accordingly. Otherwise, Claude may sometimes naturally try to wrap up work as it approaches the context limit. Below is an example prompt:&para;<br>&para;<br>```text Sample prompt&para;<br>Your context window will be automatically compacted as it approaches its limit, allowing you to continue working indefinitely from where you left off. Therefore, do not stop tasks early due to token budget concerns. As you approach your token budget limit, save your current progress and state to memory before the context window refreshes. Always be as persistent and autonomous as possible and complete tasks fully, even if the end of your budget is approaching. Never artificially stop any task early regardless of the context remaining.&para;<br>```&para;<br>&para;<br>The [memory tool](/docs/en/agents-and-tools/tool-use/memory-tool) pairs naturally with context awareness for seamless context transitions.&para;<br>&para;<br>#### Multi-context window workflows&para;<br>&para;<br>For tasks spanning multiple context windows:&para;<br>&para;<br>1. **Use a different prompt for the very first context window**: Use the first context window to set up a framework (write tests, create setup scripts), then use future context windows to iterate on a todo-list.&para;<br>&para;<br>2. **Have the model write tests in a structured format**: Ask Claude to create tests before starting work and keep track of them in a structured format (e.g., `tests.json`). This leads to better long-term ability to iterate. Remind Claude of the importance of tests: "It is unacceptable to remove or edit tests because this could lead to missing or buggy functionality."&para;<br>&para;<br>3. **Set up quality of life tools**: Encourage Claude to create setup scripts (e.g., `init.sh`) to gracefully start servers, run test suites, and linters. This prevents repeated work when continuing from a fresh context window.&para;<br>&para;<br>4. **Starting fresh vs compacting**: When a context window is cleared, consider starting with a brand new context window rather than using compaction. Claude's latest models are extremely effective at discovering state from the local filesystem. In some cases, you may want to take advantage of this over compaction. Be prescriptive about how it should start:&para;<br>   - "Call pwd; you can only read and write files in this directory."&para;<br>   - "Review progress.txt, tests.json, and the git logs."&para;<br>   - "Manually run through a fundamental integration test before moving on to implementing new features."&para;<br>&para;<br>5. **Provide verification tools**: As the length of autonomous tasks grows, Claude needs to verify correctness without continuous human feedback. Tools like Playwright MCP server or computer use capabilities for testing UIs are helpful.&para;<br>&para;<br>6. **Encourage complete usage of context**: Prompt Claude to efficiently complete components before moving on:&para;<br>&para;<br>```text Sample prompt&para;<br>This is a very long task, so it may be beneficial to plan out your work clearly. It's encouraged to spend your entire output context working on the task - just make sure you don't run out of context with significant uncommitted work. Continue working systematically until you have completed this task.&para;<br>```&para;<br>&para;<br>#### State management best practices&para;<br>&para;<br>- **Use structured formats for state data**: When tracking structured information (like test results or task status), use JSON or other structured formats to help Claude understand schema requirements&para;<br>- **Use unstructured text for progress notes**: Freeform progress notes work well for tracking general progress and context&para;<br>- **Use git for state tracking**: Git provides a log of what's been done and checkpoints that can be restored. Claude's latest models perform especially well in using git to track state across multiple sessions.&para;<br>- **Emphasize incremental progress**: Explicitly ask Claude to keep track of its progress and focus on incremental work&para;<br>&para;<br>&lt;section title="Example: State tracking"&gt;&para;<br>&para;<br>```json&para;<br>// Structured state file (tests.json)&para;<br>{&para;<br>  "tests": [&para;<br>    {"id": 1, "name": "authentication_flow", "status": "passing"},&para;<br>    {"id": 2, "name": "user_management", "status": "failing"},&para;<br>    {"id": 3, "name": "api_endpoints", "status": "not_started"}&para;<br>  ],&para;<br>  "total": 200,&para;<br>  "passing": 150,&para;<br>  "failing": 25,&para;<br>  "not_started": 25&para;<br>}&para;<br>```&para;<br>&para;<br>```text&para;<br>// Progress notes (progress.txt)&para;<br>Session 3 progress:&para;<br>- Fixed authentication token validation&para;<br>- Updated user model to handle edge cases&para;<br>- Next: investigate user_management test failures (test #2)&para;<br>- Note: Do not remove tests as this could lead to missing functionality&para;<br>```&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>### Communication style&para;<br>&para;<br>Claude's latest models have a more concise and natural communication style compared to previous models:&para;<br>&para;<br>- **More direct and grounded**: Provides fact-based progress reports rather than self-celebratory updates&para;<br>- **More conversational**: Slightly more fluent and colloquial, less machine-like&para;<br>- **Less verbose**: May skip detailed summaries for efficiency unless prompted otherwise&para;<br>&para;<br>This communication style accurately reflects what has been accomplished without unnecessary elaboration.&para;<br>&para;<br>## Guidance for specific situations&para;<br>&para;<br>### Balance verbosity&para;<br>&para;<br>Claude's latest models tend toward efficiency and may skip verbal summaries after tool calls, jumping directly to the next action. While this creates a streamlined workflow, you may prefer more visibility into its reasoning process.&para;<br>&para;<br>If you want Claude to provide updates as it works:&para;<br>&para;<br>```text Sample prompt&para;<br>After completing a task that involves tool use, provide a quick summary of the work you've done.&para;<br>```&para;<br>&para;<br>### Tool usage patterns&para;<br>&para;<br>Claude's latest models are trained for precise instruction following and benefit from explicit direction to use specific tools. If you say "can you suggest some changes," Claude will sometimes provide suggestions rather than implementing them—even if making changes might be what you intended.&para;<br>&para;<br>For Claude to take action, be more explicit:&para;<br>&para;<br>&lt;section title="Example: Explicit instructions"&gt;&para;<br>&para;<br>**Less effective (Claude will only suggest):**&para;<br>```text&para;<br>Can you suggest some changes to improve this function?&para;<br>```&para;<br>&para;<br>**More effective (Claude will make the changes):**&para;<br>```text&para;<br>Change this function to improve its performance.&para;<br>```&para;<br>&para;<br>Or:&para;<br>```text&para;<br>Make these edits to the authentication flow.&para;<br>```&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>To make Claude more proactive about taking action by default, you can add this to your system prompt:&para;<br>&para;<br>```text Sample prompt for proactive action&para;<br>&lt;default_to_action&gt;&para;<br>By default, implement changes rather than only suggesting them. If the user's intent is unclear, infer the most useful likely action and proceed, using tools to discover any missing details instead of guessing. Try to infer the user's intent about whether a tool call (e.g., file edit or read) is intended or not, and act accordingly.&para;<br>&lt;/default_to_action&gt;&para;<br>```&para;<br>&para;<br>On the other hand, if you want the model to be more hesitant by default, less prone to jumping straight into implementations, and only take action if requested, you can steer this behavior with a prompt like the below:&para;<br>&para;<br>```text Sample prompt for conservative action&para;<br>&lt;do_not_act_before_instructions&gt;&para;<br>Do not jump into implementatation or changes files unless clearly instructed to make changes. When the user's intent is ambiguous, default to providing information, doing research, and providing recommendations rather than taking action. Only proceed with edits, modifications, or implementations when the user explicitly requests them.&para;<br>&lt;/do_not_act_before_instructions&gt;&para;<br>```&para;<br>&para;<br>### Tool usage and triggering&para;<br>&para;<br>Claude Opus 4.5 and Claude </span><del style="background:#ffe6e6;">Opus 4.6</del><ins style="background:#e6ffe6;">4.6 models</ins><span> are more responsive to the system prompt than previous models. If your prompts were designed to reduce undertriggering on tools or skills, these models may now overtrigger. The fix is to dial back any aggressive language. Where you might have said "CRITICAL: You MUST use this tool when...", you can use more normal prompting like "Use this tool when...".&para;<br>&para;<br>### Balancing autonomy and safety&para;<br>&para;<br>Without guidance, Claude Opus 4.6 may take actions that are difficult to reverse or affect shared systems, such as deleting files, force-pushing, or posting to external services. If you want Claude Opus 4.6 to confirm before taking potentially risky actions, add guidance to your prompt:&para;<br>&para;<br>```text Sample prompt&para;<br>Consider the reversibility and potential impact of your actions. You are encouraged to take local, reversible actions like editing files or running tests, but for actions that are hard to reverse, affect shared systems, or could be destructive, ask the user before proceeding.&para;<br>&para;<br>Examples of actions that warrant confirmation:&para;<br>- Destructive operations: deleting files or branches, dropping database tables, rm -rf&para;<br>- Hard to reverse operations: git push --force, git reset --hard, amending published commits&para;<br>- Operations visible to others: pushing code, commenting on PRs/issues, sending messages, modifying shared infrastructure&para;<br>&para;<br>When encountering obstacles, do not use destructive actions as a shortcut. For example, don't bypass safety checks (e.g. --no-verify) or discard unfamiliar files that may be in-progress work.&para;<br>```&para;<br>&para;<br>### Overthinking and excessive thoroughness&para;<br>&para;<br>Claude </span><del style="background:#ffe6e6;">Opus 4.6 does</del><ins style="background:#e6ffe6;">4.6 models do</ins><span> significantly more upfront exploration than previous models, especially at higher `effort` settings. This initial work often helps to optimize the final results, but the model</span><ins style="background:#e6ffe6;">s</ins><span> may gather extensive context or pursue multiple threads of research without being prompted. If your prompts previously encouraged the model to be more thorough, you should tune that guidance for Claude </span><del style="background:#ffe6e6;">Opus 4.6:&para;<br>&para;<br>- **Replace blanket defaults wi</del><ins style="background:#e6ffe6;">4.6 models:&para;<br>&para;<br>- **Remove anti-laziness prompts.** Instructions like "be thorough," "think carefully," or "do not be lazy" were common workarounds for earlier models. On Claude 4.6 models, these amplify </ins><span>th</span><ins style="background:#e6ffe6;">e</ins><span> mo</span><del style="background:#ffe6e6;">re targeted instructions.** Instead of "Default to using</del><ins style="background:#e6ffe6;">del's already-proactive behavior and can cause runaway thinking or write-then-rewrite loops.&para;<br>- **Soften tool-use language.** Replace "You must use</ins><span> \[tool\]</span><del style="background:#ffe6e6;">,</del><span>" </span><del style="background:#ffe6e6;">add guidance like</del><ins style="background:#e6ffe6;">or "If in doubt, use \[tool\]" with</ins><span> "Use \[tool\] when it would enhance your understanding of the problem."</span><del style="background:#ffe6e6;">&para;<br>- **Remove over-prompting.**</del><span> Tools that undertriggered in previous models are likely to trigger appropriately now.</span><del style="background:#ffe6e6;"> Instructions like "If in doubt, use \[tool\]" will cause overtriggering.&para;<br>- **Use effort as a fallback.** If Claude continues to be overly aggressive, use a lower setting for `effort`</del><ins style="background:#e6ffe6;">&para;<br>- **Remove explicit think tool instructions.** Instructions like "use the think tool to plan your approach" cause the models to over-plan. They think effectively without being told to.&para;<br>- **Use effort as the primary control lever.** If the model is still overly aggressive after prompt cleanup, lower the effort setting rather than adding more prompt constraints</ins><span>.&para;<br>&para;<br>In some cases, </span><del style="background:#ffe6e6;">Claude Opus 4.6</del><ins style="background:#e6ffe6;">these models</ins><span> may think extensively, which can inflate thinking tokens and slow down responses. If this behavior is undesirable, you can add explicit instructions to constrain </span><del style="background:#ffe6e6;">its </del><span>reasoning, or </span><del style="background:#ffe6e6;">you can </del><span>lower the `effort` setting to reduce overall thinking and token usage.&para;<br>&para;<br>```text Sample prompt&para;<br></span><del style="background:#ffe6e6;">When you're deciding how to approach a problem, choose an approach and commit to it. Avoid revisiting decisions unless you encounter new information that directly contradicts your reasoning. If you're weighing two approaches, pick one and see it through. You can always course-correct later if the chosen </del><ins style="background:#e6ffe6;">Prioritize execution over deliberation. Choose one approach and start producing output immediately. Do not compare alternatives or plan the entire solution before writing. Do not exhaustively explore before starting; begin with what you know. Write each piece of work once; do not go back to revise or rewrite. If uncertain about a detail, make a reasonable choice and continue. Only course-correct if you encounter a concrete failure.&para;<br>```&para;<br>&para;<br>For Claude Sonnet 4.6 specifically, switching from adaptive to extended thinking with a `budget_tokens` c</ins><span>ap</span><ins style="background:#e6ffe6;"> </ins><span>pro</span><del style="background:#ffe6e6;">ach fails.&para;<br>```</del><ins style="background:#e6ffe6;">vides a hard ceiling on thinking costs while preserving quality.</ins><span>&para;<br>&para;<br>### Control the format of responses&para;<br>&para;<br>There are a few ways that we have found to be particularly effective in steering output formatting:&para;<br>&para;<br>1. **Tell Claude what to do instead of what not to do**&para;<br>&para;<br>   - Instead of: "Do not use markdown in your response"&para;<br>   - Try: "Your response should be composed of smoothly flowing prose paragraphs."&para;<br>&para;<br>2. **Use XML format indicators**&para;<br>&para;<br>   - Try: "Write the prose sections of your response in \&lt;smoothly_flowing_prose_paragraphs\&gt; tags."&para;<br>&para;<br>3. **Match your prompt style to the desired output**&para;<br>&para;<br>   The formatting style used in your prompt may influence Claude's response style. If you are still experiencing steerability issues with output formatting, we recommend as best as you can matching your prompt style to your desired output style. For example, removing markdown from your prompt can reduce the volume of markdown in the output.&para;<br>&para;<br>4. **Use detailed prompts for specific formatting preferences**&para;<br>&para;<br>   For more control over markdown and formatting usage, provide explicit guidance:&para;<br>&para;<br>```text Sample prompt to minimize markdown&para;<br>&lt;avoid_excessive_markdown_and_bullet_points&gt;&para;<br>When writing reports, documents, technical explanations, analyses, or any long-form content, write in clear, flowing prose using complete paragraphs and sentences. Use standard paragraph breaks for organization and reserve markdown primarily for `inline code`, code blocks (```...```), and simple headings (###, and ###). Avoid using **bold** and *italics*.&para;<br>&para;<br>DO NOT use ordered lists (1. ...) or unordered lists (*) unless : a) you're presenting truly discrete items where a list format is the best option, or b) the user explicitly requests a list or ranking&para;<br>&para;<br>Instead of listing items with bullets or numbers, incorporate them naturally into sentences. This guidance applies especially to technical writing. Using prose instead of excessive formatting will improve user satisfaction. NEVER output a series of overly short bullet points.&para;<br>&para;<br>Your goal is readable, flowing text that guides the reader naturally through ideas rather than fragmenting information into isolated points.&para;<br>&lt;/avoid_excessive_markdown_and_bullet_points&gt;&para;<br>```&para;<br>&para;<br>### Research and information gathering&para;<br>&para;<br>Claude's latest models demonstrate exceptional agentic search capabilities and can find and synthesize information from multiple sources effectively. For optimal research results:&para;<br>&para;<br>1. **Provide clear success criteria**: Define what constitutes a successful answer to your research question&para;<br>&para;<br>2. **Encourage source verification**: Ask Claude to verify information across multiple sources&para;<br>&para;<br>3. **For complex research tasks, use a structured approach**:&para;<br>&para;<br>```text Sample prompt for complex research&para;<br>Search for this information in a structured way. As you gather data, develop several competing hypotheses. Track your confidence levels in your progress notes to improve calibration. Regularly self-critique your approach and plan. Update a hypothesis tree or research notes file to persist information and provide transparency. Break down this complex research task systematically.&para;<br>```&para;<br>&para;<br>This structured approach allows Claude to find and synthesize virtually any piece of information and iteratively critique its findings, no matter the size of the corpus.&para;<br>&para;<br>### Subagent orchestration&para;<br>&para;<br>Claude's latest models demonstrate significantly improved native subagent orchestration capabilities. These models can recognize when tasks would benefit from delegating work to specialized subagents and do so proactively without requiring explicit instruction.&para;<br>&para;<br>To take advantage of this behavior:&para;<br>&para;<br>1. **Ensure well-defined subagent tools**: Have subagent tools available and described in tool definitions&para;<br>2. **Let Claude orchestrate naturally**: Claude will delegate appropriately without explicit instruction&para;<br>3. **Watch for overuse**: Claude Opus 4.6 has a strong predilection for subagents and may spawn them in situations where a simpler, direct approach would suffice. For example, the model may spawn subagents for code exploration when a direct grep call is faster and sufficient.&para;<br>&para;<br>If you're seeing excessive subagent use, add explicit guidance about when subagents are and aren't warranted:&para;<br>&para;<br>```text Sample prompt for subagent usage&para;<br>Use subagents when tasks can run in parallel, require isolated context, or involve independent workstreams that don't need to share state. For simple tasks, sequential operations, single-file edits, or tasks where you need to maintain context across steps, work directly rather than delegating.&para;<br>```&para;<br>&para;<br>### Model self-knowledge&para;<br>&para;<br>If you would like Claude to identify itself correctly in your application or use specific API strings:&para;<br>&para;<br>```text Sample prompt for model identity&para;<br>The assistant is Claude, created by Anthropic. The current model is Claude Opus 4.6.&para;<br>```&para;<br>&para;<br>For LLM-powered apps that need to specify model strings:&para;<br>&para;<br>```text Sample prompt for model string&para;<br>When an LLM is needed, please default to Claude Opus 4.6 unless the user requests otherwise. The exact model string for Claude Opus 4.6 is claude-opus-4-6.&para;<br>```&para;<br>&para;<br>### Thinking sensitivity&para;<br>&para;<br>When extended thinking is disabled, Claude Opus 4.5 is particularly sensitive to the word "think" and its variants. We recommend replacing "think" with alternative words that convey similar meaning, such as "consider," "believe," and "evaluate."&para;<br>&para;<br>### Leverage thinking &amp; interleaved thinking capabilities&para;<br>&para;<br>Claude's latest models offer thinking capabilities that can be especially helpful for tasks involving reflection after tool use or complex multi-step reasoning. You can guide its initial or interleaved thinking for better results.&para;<br>&para;<br>Claude Opus 4.6 uses [adaptive thinking](/docs/en/build-with-claude/adaptive-thinking) (`thinking: {type: "adaptive"}`), where Claude dynamically decides when and how much to think.</span><ins style="background:#e6ffe6;"> Claude Sonnet 4.6 supports both adaptive thinking and manual extended thinking with [interleaved mode](/docs/en/build-with-claude/extended-thinking#interleaved-thinking).&para;<br>&para;<br>With adaptive thinking,</ins><span> Claude calibrates its thinking based on two factors: the `effort` parameter and query complexity. Higher effort elicits more thinking, and more complex queries do the same. On easier queries that don't require thinking, the model responds directly.</span><del style="background:#ffe6e6;"> In internal evaluations, adaptive thinking reliably drives better performance than extended thinking, and we recommend moving to adaptive thinking to get the most intelligent responses</del><ins style="background:#e6ffe6;">&para;<br>&para;<br>For Sonnet 4.6, consider trying adaptive thinking for workloads that require agentic behavior such as multi-step tool use, complex coding tasks, and long-horizon agent loops. If adaptive thinking doesn't fit your use case, manual extended thinking with interleaved mode remains supported</ins><span>. Older models use manual thinking mode with `budget_tokens`.&para;<br>&para;<br>You can guide Claude's thinking behavior:&para;<br>&para;<br>```text Example prompt&para;<br>After receiving tool results, carefully reflect on their quality and determine optimal next steps before proceeding. Use your thinking to plan and iterate based on this new information, and then take the best next action.&para;<br>```&para;<br>&para;<br>The triggering behavior for adaptive thinking is promptable. If you find the model thinking more often than you'd like, which can happen with large or complex system prompts, add guidance to steer it:&para;<br>&para;<br>```text Sample prompt&para;<br>Extended thinking adds latency and should only be used when it will meaningfully improve answer quality - typically for problems that require multi-step reasoning. When in doubt, respond directly.&para;<br>```&para;<br>&para;<br>If you are migrating from [extended thinking](/docs/en/build-with-claude/extended-thinking) with `budget_tokens`, replace your thinking configuration and move budget control to `effort`:&para;<br>&para;<br>```python Before (extended thinking, older models)&para;<br>client.messages.create(&para;<br>    model="claude-sonnet-4-5-20250929",&para;<br>    max_tokens=64000,&para;<br>    thinking={"type": "enabled", "budget_tokens": 32000},&para;<br>    messages=[{"role": "user", "content": "..."}],&para;<br>)&para;<br>```&para;<br>&para;<br>```python After (adaptive thinking)&para;<br>client.messages.create(&para;<br>    model="claude-opus-4-6",&para;<br>    max_tokens=64000,&para;<br>    thinking={"type": "adaptive"},&para;<br>    output_config={"effort": "high"},  # or max, medium, low&para;<br>    messages=[{"role": "user", "content": "..."}],&para;<br>)&para;<br>```&para;<br>&para;<br>If you are not using extended thinking, no changes are required. Thinking is off by default when you omit the `thinking` parameter.&para;<br>&para;<br>&lt;Info&gt;&para;<br>  For more information on thinking capabilities, see [Extended thinking](/docs/en/build-with-claude/extended-thinking) and [Adaptive thinking](/docs/en/build-with-claude/adaptive-thinking).&para;<br>&lt;/Info&gt;&para;<br>&para;<br>### Document creation&para;<br>&para;<br>Claude's latest models excel at creating presentations, animations, and visual documents with impressive creative flair and strong instruction following. The models produce polished, usable output on the first try in most cases.&para;<br>&para;<br>For best results with document creation:&para;<br>&para;<br>```text Sample prompt&para;<br>Create a professional presentation on [topic]. Include thoughtful design elements, visual hierarchy, and engaging animations where appropriate.&para;<br>```&para;<br>&para;<br>### Improved vision capabilities&para;<br>&para;<br>Claude Opus 4.5 and Claude Opus 4.6 have improved vision capabilities compared to previous Claude models. They perform better on image processing and data extraction tasks, particularly when there are multiple images present in context. These improvements carry over to computer use, where the models can more reliably interpret screenshots and UI elements. You can also use these models to analyze videos by breaking them up into frames.&para;<br>&para;<br>One technique we've found effective to further boost performance is to give Claude a crop tool or [skill](/docs/en/agents-and-tools/agent-skills/overview). We've seen consistent uplift on image evaluations when Claude is able to "zoom" in on relevant regions of an image. We've put together a cookbook for the crop tool [here](https://platform.claude.com/cookbook/multimodal-crop-tool).&para;<br>&para;<br>### Optimize parallel tool calling&para;<br>&para;<br>Claude's latest models excel at parallel tool execution. These models will:&para;<br>&para;<br>- Run multiple speculative searches during research&para;<br>- Read several files at once to build context faster&para;<br>- Execute bash commands in parallel (which can even bottleneck system performance)&para;<br>&para;<br>This behavior is easily steerable. While the model has a high success rate in parallel tool calling without prompting, you can boost this to ~100% or adjust the aggression level:&para;<br>&para;<br>```text Sample prompt for maximum parallel efficiency&para;<br>&lt;use_parallel_tool_calls&gt;&para;<br>If you intend to call multiple tools and there are no dependencies between the tool calls, make all of the independent tool calls in parallel. Prioritize calling tools simultaneously whenever the actions can be done in parallel rather than sequentially. For example, when reading 3 files, run 3 tool calls in parallel to read all 3 files into context at the same time. Maximize use of parallel tool calls where possible to increase speed and efficiency. However, if some tool calls depend on previous calls to inform dependent values like the parameters, do NOT call these tools in parallel and instead call them sequentially. Never use placeholders or guess missing parameters in tool calls.&para;<br>&lt;/use_parallel_tool_calls&gt;&para;<br>```&para;<br>&para;<br>```text Sample prompt to reduce parallel execution&para;<br>Execute operations sequentially with brief pauses between each step to ensure stability.&para;<br>```&para;<br>&para;<br>### Reduce file creation in agentic coding&para;<br>&para;<br>Claude's latest models may sometimes create new files for testing and iteration purposes, particularly when working with code. This approach allows Claude to use files, especially python scripts, as a 'temporary scratchpad' before saving its final output. Using temporary files can improve outcomes particularly for agentic coding use cases.&para;<br>&para;<br>If you'd prefer to minimize net new file creation, you can instruct Claude to clean up after itself:&para;<br>&para;<br>```text Sample prompt&para;<br>If you create any temporary new files, scripts, or helper files for iteration, clean up these files by removing them at the end of the task.&para;<br>```&para;<br>&para;<br>### Overeagerness&para;<br>&para;<br>Claude Opus 4.5 and Claude Opus 4.6 have a tendency to overengineer by creating extra files, adding unnecessary abstractions, or building in flexibility that wasn't requested. If you're seeing this undesired behavior, add specific guidance to keep solutions minimal.&para;<br>&para;<br>For example:&para;<br>&para;<br>```text Sample prompt to minimize overengineering&para;<br>Avoid over-engineering. Only make changes that are directly requested or clearly necessary. Keep solutions simple and focused:&para;<br>&para;<br>- Scope: Don't add features, refactor code, or make "improvements" beyond what was asked. A bug fix doesn't need surrounding code cleaned up. A simple feature doesn't need extra configurability.&para;<br>&para;<br>- Documentation: Don't add docstrings, comments, or type annotations to code you didn't change. Only add comments where the logic isn't self-evident.&para;<br>&para;<br>- Defensive coding: Don't add error handling, fallbacks, or validation for scenarios that can't happen. Trust internal code and framework guarantees. Only validate at system boundaries (user input, external APIs).&para;<br>&para;<br>- Abstractions: Don't create helpers, utilities, or abstractions for one-time operations. Don't design for hypothetical future requirements. The right amount of complexity is the minimum needed for the current task.&para;<br>```&para;<br>&para;<br>### Frontend design&para;<br>&para;<br>Claude Opus 4.5 and Claude Opus 4.6 excel at building complex, real-world web applications with strong frontend design. However, without guidance, models can default to generic patterns that create what users call the "AI slop" aesthetic. To create distinctive, creative frontends that surprise and delight:&para;<br>&para;<br>&lt;Tip&gt;&para;<br>For a detailed guide on improving frontend design, see our blog post on [improving frontend design through skills](https://www.claude.com/blog/improving-frontend-design-through-skills).&para;<br>&lt;/Tip&gt;&para;<br>&para;<br>Here's a system prompt snippet you can use to encourage better frontend design:&para;<br>&para;<br>```text Sample prompt for frontend aesthetics&para;<br>&lt;frontend_aesthetics&gt;&para;<br>You tend to converge toward generic, "on distribution" outputs. In frontend design, this creates what users call the "AI slop" aesthetic. Avoid this: make creative, distinctive frontends that surprise and delight.&para;<br>&para;<br>Focus on:&para;<br>- Typography: Choose fonts that are beautiful, unique, and interesting. Avoid generic fonts like Arial and Inter; opt instead for distinctive choices that elevate the frontend's aesthetics.&para;<br>- Color &amp; Theme: Commit to a cohesive aesthetic. Use CSS variables for consistency. Dominant colors with sharp accents outperform timid, evenly-distributed palettes. Draw from IDE themes and cultural aesthetics for inspiration.&para;<br>- Motion: Use animations for effects and micro-interactions. Prioritize CSS-only solutions for HTML. Use Motion library for React when available. Focus on high-impact moments: one well-orchestrated page load with staggered reveals (animation-delay) creates more delight than scattered micro-interactions.&para;<br>- Backgrounds: Create atmosphere and depth rather than defaulting to solid colors. Layer CSS gradients, use geometric patterns, or add contextual effects that match the overall aesthetic.&para;<br>&para;<br>Avoid generic AI-generated aesthetics:&para;<br>- Overused font families (Inter, Roboto, Arial, system fonts)&para;<br>- Clichéd color schemes (particularly purple gradients on white backgrounds)&para;<br>- Predictable layouts and component patterns&para;<br>- Cookie-cutter design that lacks context-specific character&para;<br>&para;<br>Interpret creatively and make unexpected choices that feel genuinely designed for the context. Vary between light and dark themes, different fonts, different aesthetics. You still tend to converge on common choices (Space Grotesk, for example) across generations. Avoid this: it is critical that you think outside the box!&para;<br>&lt;/frontend_aesthetics&gt;&para;<br>```&para;<br>&para;<br>You can also refer to the full skill [here](https://github.com/anthropics/claude-code/blob/main/plugins/frontend-design/skills/frontend-design/SKILL.md).&para;<br>&para;<br>### Avoid focusing on passing tests and hard-coding&para;<br>&para;<br>Claude can sometimes focus too heavily on making tests pass at the expense of more general solutions, or may use workarounds like helper scripts for complex refactoring instead of using standard tools directly. To prevent this behavior and ensure robust, generalizable solutions:&para;<br>&para;<br>```text Sample prompt&para;<br>Please write a high-quality, general-purpose solution using the standard tools available. Do not create helper scripts or workarounds to accomplish the task more efficiently. Implement a solution that works correctly for all valid inputs, not just the test cases. Do not hard-code values or create solutions that only work for specific test inputs. Instead, implement the actual logic that solves the problem generally.&para;<br>&para;<br>Focus on understanding the problem requirements and implementing the correct algorithm. Tests are there to verify correctness, not to define the solution. Provide a principled implementation that follows best practices and software design principles.&para;<br>&para;<br>If the task is unreasonable or infeasible, or if any of the tests are incorrect, please inform me rather than working around them. The solution should be robust, maintainable, and extendable.&para;<br>```&para;<br>&para;<br>### Minimizing hallucinations in agentic coding&para;<br>&para;<br>Claude's latest models are less prone to hallucinations and give more accurate, grounded, intelligent answers based on the code. To encourage this behavior even more and minimize hallucinations:&para;<br>&para;<br>```text Sample prompt&para;<br>&lt;investigate_before_answering&gt;&para;<br>Never speculate about code you have not opened. If the user references a specific file, you MUST read the file before answering. Make sure to investigate and read relevant files BEFORE answering questions about the codebase. Never make any claims about code before investigating unless you are certain of the correct answer - give grounded and hallucination-free answers.&para;<br>&lt;/investigate_before_answering&gt;&para;<br>```&para;<br>&para;<br>### Migrating away from prefilled responses&para;<br>&para;<br>Starting with Claude </span><del style="background:#ffe6e6;">Opus 4.6</del><ins style="background:#e6ffe6;">4.6 models</ins><span>, prefilled responses on the last assistant turn are no longer supported.</span><ins style="background:#e6ffe6;"> Prefills have been a common vector for jailbreaks and other exploits.</ins><span> Model intelligence and instruction following has advanced such that most use cases of prefill no longer require it. Existing models will continue to support prefills, and adding assistant messages elsewhere in the conversation is not affected.&para;<br>&para;<br>Here are common prefill scenarios and how to migrate away from them:&para;<br>&para;<br>&lt;section title="Controlling output formatting"&gt;&para;<br>&para;<br>Prefills have been used to force specific output formats like JSON/YAML, classification, and similar patterns where the prefill constrains Claude to a particular structure.&para;<br>&para;<br>**Migration:** The [Structured Outputs](/docs/en/build-with-claude/structured-outputs) feature is designed specifically to constrain Claude's responses to follow a given schema. Try simply asking the model to conform to your output structure first, as newer models can reliably match complex schemas when told to, especially if implemented with retries. For classification tasks, use either tools with an enum field containing your valid labels or structured outputs.&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>&lt;section title="Eliminating preambles"&gt;&para;<br>&para;<br>Prefills like `Here is the requested summary:\n` were used to skip introductory text.&para;<br>&para;<br>**Migration:** Use direct instructions in the system prompt: "Respond directly without preamble. Do not start with phrases like 'Here is...', 'Based on...', etc." Alternatively, direct the model to output within XML tags, use structured outputs, or use tool calling. If the occasional preamble slips through, strip it in post-processing.&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>&lt;section title="Avoiding bad refusals"&gt;&para;<br>&para;<br>Prefills were used to steer around unnecessary refusals.&para;<br>&para;<br>**Migration:** Claude is much better at appropriate refusals now. Clear prompting within the `user` message without prefill should be sufficient.&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>&lt;section title="Continuations"&gt;&para;<br>&para;<br>Prefills were used to continue partial completions, resume interrupted responses, or pick up where a previous generation left off.&para;<br>&para;<br>**Migration:** Move the continuation to the user message, and include the final text from the interrupted response: "Your previous response was interrupted and ended with \`[previous_response]\`. Continue from where you left off." If this is part of error-handling or incomplete-response-handling and there is no UX penalty, retry the request.&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>&lt;section title="Context hydration and role consistency"&gt;&para;<br>&para;<br>Prefills were used to periodically ensure refreshed or injected context.&para;<br>&para;<br>**Migration:** For very long conversations, inject what were previously prefilled-assistant reminders into the user turn. If context hydration is part of a more complex agentic system, consider hydrating via tools (expose or encourage use of tools containing context based on heuristics such as number of turns) or during context compaction.&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>### LaTeX output&para;<br>&para;<br>Claude Opus 4.6 defaults to LaTeX for mathematical expressions, equations, and technical explanations. If you prefer plain text, add the following instructions to your prompt:&para;<br>&para;<br>```text Sample prompt&para;<br>Format your response in plain text only. Do not use LaTeX, MathJax, or any markup notation such as \( \), $, or \frac{}{}. Write all math expressions using standard text characters (e.g., "/" for division, "*" for multiplication, and "^" for exponents).&para;<br>```&para;<br>&para;<br>## Migration considerations&para;<br>&para;<br>When migrating to Claude 4.6 models from earlier generations:&para;<br>&para;<br>1. **Be specific about desired behavior**: Consider describing exactly what you'd like to see in the output.&para;<br>&para;<br>2. **Frame your instructions with modifiers**: Adding modifiers that encourage Claude to increase the quality and detail of its output can help better shape Claude's performance. For example, instead of "Create an analytics dashboard", use "Create an analytics dashboard. Include as many relevant features and interactions as possible. Go beyond the basics to create a fully-featured implementation."&para;<br>&para;<br>3. **Request specific features explicitly**: Animations and interactive elements should be requested explicitly when desired.&para;<br>&para;<br>4. **Update thinking configuration**: Claude </span><del style="background:#ffe6e6;">Opus 4.6 uses [adaptive thinking](/docs/en/build-with-claude/adaptive-thinking) (`thinking: {type: "adaptive"}`) instead of manual thinking with `budget_tokens`. Use the [effort parameter](/docs/en/build-with-claude/effort) to control thinking depth.&para;<br>&para;<br>5. **Migrate away from prefilled responses**: Prefilled responses on the last assistant turn are deprecated starting with Claude Opus 4.6. See [Migrating away from prefilled responses](#migrating-away-from-prefilled-responses) for detailed guidance on alternatives.&para;<br>&para;<br>6. **Tune anti-laziness prompting**: If your prompts previously encouraged the model to be more thorough or use tools more aggressively, dial back that guidance. Claude Opus 4.6 is significantly more proactive and may overtrigger on instructions that were needed for previous models.&para;<br>&para;<br>For detailed migration steps, see the [Migration guide](/docs/en/about-claude/models/migration-guide).</del><ins style="background:#e6ffe6;">4.6 models use [adaptive thinking](/docs/en/build-with-claude/adaptive-thinking) (`thinking: {type: "adaptive"}`) instead of manual thinking with `budget_tokens`. Use the [effort parameter](/docs/en/build-with-claude/effort) to control thinking depth.&para;<br>&para;<br>5. **Migrate away from prefilled responses**: Prefilled responses on the last assistant turn are deprecated starting with Claude 4.6 models. See [Migrating away from prefilled responses](#migrating-away-from-prefilled-responses) for detailed guidance on alternatives.&para;<br>&para;<br>6. **Tune anti-laziness prompting**: If your prompts previously encouraged the model to be more thorough or use tools more aggressively, dial back that guidance. Claude 4.6 models are significantly more proactive and may overtrigger on instructions that were needed for previous models.&para;<br>&para;<br>For detailed migration steps, see the [Migration guide](/docs/en/about-claude/models/migration-guide).&para;<br>&para;<br>### Migrating from Claude Sonnet 4.5 to Claude Sonnet 4.6&para;<br>&para;<br>Claude Sonnet 4.6 defaults to an effort level of `high`, in contrast to Claude Sonnet 4.5 which had no effort parameter. We recommend adjusting the effort parameter as you migrate from Claude Sonnet 4.5 to Claude Sonnet 4.6. If not explicitly set, you may experience higher latency with the default effort level.&para;<br>&para;<br>**Recommended effort settings:**&para;<br>- **Medium** for most applications&para;<br>- **Low** for high-volume or latency-sensitive workloads&para;<br>- Set a large max output token budget (64k tokens recommended) at medium or high effort to give the model room to think and act&para;<br>&para;<br>**When to use Opus 4.6 instead:** For the hardest, longest-horizon problems—large-scale code migrations, deep research, extended autonomous work—Opus 4.6 remains the right choice. Sonnet 4.6 is optimized for workloads where fast turnaround and cost efficiency matter most.&para;<br>&para;<br>#### If you're not using extended thinking&para;<br>&para;<br>If you're not using extended thinking on Claude Sonnet 4.5, you can continue without it on Claude Sonnet 4.6. You should explicitly set effort to the level appropriate for your use case. At `low` effort with thinking disabled, you can expect similar or better performance relative to Claude Sonnet 4.5 with no extended thinking.&para;<br>&para;<br>```python&para;<br>client.messages.create(&para;<br>    model="claude-sonnet-4-6",&para;<br>    max_tokens=8192,&para;<br>    thinking={"type": "disabled"},&para;<br>    output_config={"effort": "low"},&para;<br>    messages=[{"role": "user", "content": "..."}],&para;<br>)&para;<br>```&para;<br>&para;<br>#### If you're using extended thinking&para;<br>&para;<br>If you're using extended thinking on Claude Sonnet 4.5, it continues to be supported on Claude Sonnet 4.6 with no changes needed to your thinking configuration. We recommend keeping a thinking budget around 16k tokens. In practice, most tasks don't use that much, but it provides headroom for harder problems without risk of runaway token usage.&para;<br>&para;<br>**For coding use cases** (agentic coding, tool-heavy workflows, code generation):&para;<br>&para;<br>Start with `medium` effort. If you find latency is too high, consider reducing effort to `low`. If you need higher intelligence, consider increasing effort to `high` or migrating to Opus 4.6.&para;<br>&para;<br>```python&para;<br>client.messages.create(&para;<br>    model="claude-sonnet-4-6",&para;<br>    max_tokens=16384,&para;<br>    thinking={"type": "enabled", "budget_tokens": 16384},&para;<br>    output_config={"effort": "medium"},&para;<br>    messages=[{"role": "user", "content": "..."}],&para;<br>)&para;<br>```&para;<br>&para;<br>**For chat and non-coding use cases** (chat, content generation, search, classification):&para;<br>&para;<br>Start with `low` effort with extended thinking. If you need more depth, increase effort to `medium`.&para;<br>&para;<br>```python&para;<br>client.messages.create(&para;<br>    model="claude-sonnet-4-6",&para;<br>    max_tokens=8192,&para;<br>    thinking={"type": "enabled", "budget_tokens": 16384},&para;<br>    output_config={"effort": "low"},&para;<br>    messages=[{"role": "user", "content": "..."}],&para;<br>)&para;<br>```&para;<br>&para;<br>#### When to try adaptive thinking&para;<br>&para;<br>The extended thinking paths above use `budget_tokens` for predictable token usage. If your workload fits one of the following patterns, consider trying [adaptive thinking](/docs/en/build-with-claude/adaptive-thinking) instead:&para;<br>&para;<br>- **Autonomous multi-step agents:** coding agents that turn requirements into working software, data analysis pipelines, and bug finding where the model runs independently across many steps. Adaptive thinking lets the model calibrate its reasoning per step, staying on path over longer trajectories. For these workloads, start at `high` effort. If latency or token usage is a concern, scale down to `medium`.&para;<br>- **Computer use agents:** Claude Sonnet 4.6 achieved best-in-class accuracy on computer use evaluations using adaptive mode.&para;<br>- **Bimodal workloads:** a mix of easy and hard tasks where adaptive skips thinking on simple queries and reasons deeply on complex ones.&para;<br>&para;<br>When using adaptive thinking, evaluate `medium` and `high` effort on your tasks. The right level depends on your workload's tradeoff between quality, latency, and token usage.&para;<br>&para;<br>```python&para;<br>client.messages.create(&para;<br>    model="claude-sonnet-4-6",&para;<br>    max_tokens=64000,&para;<br>    thinking={"type": "adaptive"},&para;<br>    output_config={"effort": "high"},&para;<br>    messages=[{"role": "user", "content": "..."}],&para;<br>)&para;<br>```</ins></div>
        </div>

        <h2 style="margin-top: 2rem; margin-bottom: 1rem;">Unified Diff</h2>
        <pre><code>--- a/build-with-claude/prompt-engineering/claude-4-best-practices.md
+++ b/build-with-claude/prompt-engineering/claude-4-best-practices.md
@@ -2,7 +2,8 @@
 
 ---
 
-This guide provides prompt engineering techniques for Claude&#39;s latest models, including Claude Opus 4.6, Claude Sonnet 4.5, and Claude Haiku 4.5. These models have been trained for more precise instruction following than previous generations of Claude models.
+This guide provides prompt engineering techniques for Claude&#39;s latest models, including Claude Opus 4.6, Claude Sonnet 4.6, and Claude Haiku 4.5. These models have been trained for more precise instruction following than previous generations of Claude models.
+
 &lt;Tip&gt;
   For an overview of model capabilities, see the [models overview](/docs/en/about-claude/models/overview). For details on what&#39;s new in Claude 4.6, see [What&#39;s new in Claude 4.6](/docs/en/about-claude/models/whats-new-claude-4-6). For migration guidance, see the [Migration guide](/docs/en/about-claude/models/migration-guide).
 &lt;/Tip&gt;
@@ -57,7 +58,7 @@
 
 #### Context awareness and multi-window workflows
 
-Claude Opus 4.6 and Claude 4.5 models feature [context awareness](/docs/en/build-with-claude/context-windows#context-awareness-in-claude-sonnet-45-and-haiku-45), enabling the model to track its remaining context window (i.e. &#34;token budget&#34;) throughout a conversation. This enables Claude to execute tasks and manage context more effectively by understanding how much space it has to work.
+Claude 4.6 and Claude 4.5 models feature [context awareness](/docs/en/build-with-claude/context-windows#context-awareness-in-claude-sonnet-46-sonnet-45-and-haiku-45), enabling the model to track its remaining context window (i.e. &#34;token budget&#34;) throughout a conversation. This enables Claude to execute tasks and manage context more effectively by understanding how much space it has to work.
 
 **Managing context limits:**
 
@@ -192,7 +193,7 @@
 
 ### Tool usage and triggering
 
-Claude Opus 4.5 and Claude Opus 4.6 are more responsive to the system prompt than previous models. If your prompts were designed to reduce undertriggering on tools or skills, these models may now overtrigger. The fix is to dial back any aggressive language. Where you might have said &#34;CRITICAL: You MUST use this tool when...&#34;, you can use more normal prompting like &#34;Use this tool when...&#34;.
+Claude Opus 4.5 and Claude 4.6 models are more responsive to the system prompt than previous models. If your prompts were designed to reduce undertriggering on tools or skills, these models may now overtrigger. The fix is to dial back any aggressive language. Where you might have said &#34;CRITICAL: You MUST use this tool when...&#34;, you can use more normal prompting like &#34;Use this tool when...&#34;.
 
 ### Balancing autonomy and safety
 
@@ -211,17 +212,20 @@
 
 ### Overthinking and excessive thoroughness
 
-Claude Opus 4.6 does significantly more upfront exploration than previous models, especially at higher `effort` settings. This initial work often helps to optimize the final results, but the model may gather extensive context or pursue multiple threads of research without being prompted. If your prompts previously encouraged the model to be more thorough, you should tune that guidance for Claude Opus 4.6:
-
-- **Replace blanket defaults with more targeted instructions.** Instead of &#34;Default to using \[tool\],&#34; add guidance like &#34;Use \[tool\] when it would enhance your understanding of the problem.&#34;
-- **Remove over-prompting.** Tools that undertriggered in previous models are likely to trigger appropriately now. Instructions like &#34;If in doubt, use \[tool\]&#34; will cause overtriggering.
-- **Use effort as a fallback.** If Claude continues to be overly aggressive, use a lower setting for `effort`.
-
-In some cases, Claude Opus 4.6 may think extensively, which can inflate thinking tokens and slow down responses. If this behavior is undesirable, you can add explicit instructions to constrain its reasoning, or you can lower the `effort` setting to reduce overall thinking and token usage.
-
-```text Sample prompt
-When you&#39;re deciding how to approach a problem, choose an approach and commit to it. Avoid revisiting decisions unless you encounter new information that directly contradicts your reasoning. If you&#39;re weighing two approaches, pick one and see it through. You can always course-correct later if the chosen approach fails.
-```
+Claude 4.6 models do significantly more upfront exploration than previous models, especially at higher `effort` settings. This initial work often helps to optimize the final results, but the models may gather extensive context or pursue multiple threads of research without being prompted. If your prompts previously encouraged the model to be more thorough, you should tune that guidance for Claude 4.6 models:
+
+- **Remove anti-laziness prompts.** Instructions like &#34;be thorough,&#34; &#34;think carefully,&#34; or &#34;do not be lazy&#34; were common workarounds for earlier models. On Claude 4.6 models, these amplify the model&#39;s already-proactive behavior and can cause runaway thinking or write-then-rewrite loops.
+- **Soften tool-use language.** Replace &#34;You must use \[tool\]&#34; or &#34;If in doubt, use \[tool\]&#34; with &#34;Use \[tool\] when it would enhance your understanding of the problem.&#34; Tools that undertriggered in previous models are likely to trigger appropriately now.
+- **Remove explicit think tool instructions.** Instructions like &#34;use the think tool to plan your approach&#34; cause the models to over-plan. They think effectively without being told to.
+- **Use effort as the primary control lever.** If the model is still overly aggressive after prompt cleanup, lower the effort setting rather than adding more prompt constraints.
+
+In some cases, these models may think extensively, which can inflate thinking tokens and slow down responses. If this behavior is undesirable, you can add explicit instructions to constrain reasoning, or lower the `effort` setting to reduce overall thinking and token usage.
+
+```text Sample prompt
+Prioritize execution over deliberation. Choose one approach and start producing output immediately. Do not compare alternatives or plan the entire solution before writing. Do not exhaustively explore before starting; begin with what you know. Write each piece of work once; do not go back to revise or rewrite. If uncertain about a detail, make a reasonable choice and continue. Only course-correct if you encounter a concrete failure.
+```
+
+For Claude Sonnet 4.6 specifically, switching from adaptive to extended thinking with a `budget_tokens` cap provides a hard ceiling on thinking costs while preserving quality.
 
 ### Control the format of responses
 
@@ -310,7 +314,11 @@
 
 Claude&#39;s latest models offer thinking capabilities that can be especially helpful for tasks involving reflection after tool use or complex multi-step reasoning. You can guide its initial or interleaved thinking for better results.
 
-Claude Opus 4.6 uses [adaptive thinking](/docs/en/build-with-claude/adaptive-thinking) (`thinking: {type: &#34;adaptive&#34;}`), where Claude dynamically decides when and how much to think. Claude calibrates its thinking based on two factors: the `effort` parameter and query complexity. Higher effort elicits more thinking, and more complex queries do the same. On easier queries that don&#39;t require thinking, the model responds directly. In internal evaluations, adaptive thinking reliably drives better performance than extended thinking, and we recommend moving to adaptive thinking to get the most intelligent responses. Older models use manual thinking mode with `budget_tokens`.
+Claude Opus 4.6 uses [adaptive thinking](/docs/en/build-with-claude/adaptive-thinking) (`thinking: {type: &#34;adaptive&#34;}`), where Claude dynamically decides when and how much to think. Claude Sonnet 4.6 supports both adaptive thinking and manual extended thinking with [interleaved mode](/docs/en/build-with-claude/extended-thinking#interleaved-thinking).
+
+With adaptive thinking, Claude calibrates its thinking based on two factors: the `effort` parameter and query complexity. Higher effort elicits more thinking, and more complex queries do the same. On easier queries that don&#39;t require thinking, the model responds directly.
+
+For Sonnet 4.6, consider trying adaptive thinking for workloads that require agentic behavior such as multi-step tool use, complex coding tasks, and long-horizon agent loops. If adaptive thinking doesn&#39;t fit your use case, manual extended thinking with interleaved mode remains supported. Older models use manual thinking mode with `budget_tokens`.
 
 You can guide Claude&#39;s thinking behavior:
 
@@ -471,7 +479,7 @@
 
 ### Migrating away from prefilled responses
 
-Starting with Claude Opus 4.6, prefilled responses on the last assistant turn are no longer supported. Model intelligence and instruction following has advanced such that most use cases of prefill no longer require it. Existing models will continue to support prefills, and adding assistant messages elsewhere in the conversation is not affected.
+Starting with Claude 4.6 models, prefilled responses on the last assistant turn are no longer supported. Prefills have been a common vector for jailbreaks and other exploits. Model intelligence and instruction following has advanced such that most use cases of prefill no longer require it. Existing models will continue to support prefills, and adding assistant messages elsewhere in the conversation is not affected.
 
 Here are common prefill scenarios and how to migrate away from them:
 
@@ -533,10 +541,87 @@
 
 3. **Request specific features explicitly**: Animations and interactive elements should be requested explicitly when desired.
 
-4. **Update thinking configuration**: Claude Opus 4.6 uses [adaptive thinking](/docs/en/build-with-claude/adaptive-thinking) (`thinking: {type: &#34;adaptive&#34;}`) instead of manual thinking with `budget_tokens`. Use the [effort parameter](/docs/en/build-with-claude/effort) to control thinking depth.
-
-5. **Migrate away from prefilled responses**: Prefilled responses on the last assistant turn are deprecated starting with Claude Opus 4.6. See [Migrating away from prefilled responses](#migrating-away-from-prefilled-responses) for detailed guidance on alternatives.
-
-6. **Tune anti-laziness prompting**: If your prompts previously encouraged the model to be more thorough or use tools more aggressively, dial back that guidance. Claude Opus 4.6 is significantly more proactive and may overtrigger on instructions that were needed for previous models.
-
-For detailed migration steps, see the [Migration guide](/docs/en/about-claude/models/migration-guide).+4. **Update thinking configuration**: Claude 4.6 models use [adaptive thinking](/docs/en/build-with-claude/adaptive-thinking) (`thinking: {type: &#34;adaptive&#34;}`) instead of manual thinking with `budget_tokens`. Use the [effort parameter](/docs/en/build-with-claude/effort) to control thinking depth.
+
+5. **Migrate away from prefilled responses**: Prefilled responses on the last assistant turn are deprecated starting with Claude 4.6 models. See [Migrating away from prefilled responses](#migrating-away-from-prefilled-responses) for detailed guidance on alternatives.
+
+6. **Tune anti-laziness prompting**: If your prompts previously encouraged the model to be more thorough or use tools more aggressively, dial back that guidance. Claude 4.6 models are significantly more proactive and may overtrigger on instructions that were needed for previous models.
+
+For detailed migration steps, see the [Migration guide](/docs/en/about-claude/models/migration-guide).
+
+### Migrating from Claude Sonnet 4.5 to Claude Sonnet 4.6
+
+Claude Sonnet 4.6 defaults to an effort level of `high`, in contrast to Claude Sonnet 4.5 which had no effort parameter. We recommend adjusting the effort parameter as you migrate from Claude Sonnet 4.5 to Claude Sonnet 4.6. If not explicitly set, you may experience higher latency with the default effort level.
+
+**Recommended effort settings:**
+- **Medium** for most applications
+- **Low** for high-volume or latency-sensitive workloads
+- Set a large max output token budget (64k tokens recommended) at medium or high effort to give the model room to think and act
+
+**When to use Opus 4.6 instead:** For the hardest, longest-horizon problems—large-scale code migrations, deep research, extended autonomous work—Opus 4.6 remains the right choice. Sonnet 4.6 is optimized for workloads where fast turnaround and cost efficiency matter most.
+
+#### If you&#39;re not using extended thinking
+
+If you&#39;re not using extended thinking on Claude Sonnet 4.5, you can continue without it on Claude Sonnet 4.6. You should explicitly set effort to the level appropriate for your use case. At `low` effort with thinking disabled, you can expect similar or better performance relative to Claude Sonnet 4.5 with no extended thinking.
+
+```python
+client.messages.create(
+    model=&#34;claude-sonnet-4-6&#34;,
+    max_tokens=8192,
+    thinking={&#34;type&#34;: &#34;disabled&#34;},
+    output_config={&#34;effort&#34;: &#34;low&#34;},
+    messages=[{&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;...&#34;}],
+)
+```
+
+#### If you&#39;re using extended thinking
+
+If you&#39;re using extended thinking on Claude Sonnet 4.5, it continues to be supported on Claude Sonnet 4.6 with no changes needed to your thinking configuration. We recommend keeping a thinking budget around 16k tokens. In practice, most tasks don&#39;t use that much, but it provides headroom for harder problems without risk of runaway token usage.
+
+**For coding use cases** (agentic coding, tool-heavy workflows, code generation):
+
+Start with `medium` effort. If you find latency is too high, consider reducing effort to `low`. If you need higher intelligence, consider increasing effort to `high` or migrating to Opus 4.6.
+
+```python
+client.messages.create(
+    model=&#34;claude-sonnet-4-6&#34;,
+    max_tokens=16384,
+    thinking={&#34;type&#34;: &#34;enabled&#34;, &#34;budget_tokens&#34;: 16384},
+    output_config={&#34;effort&#34;: &#34;medium&#34;},
+    messages=[{&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;...&#34;}],
+)
+```
+
+**For chat and non-coding use cases** (chat, content generation, search, classification):
+
+Start with `low` effort with extended thinking. If you need more depth, increase effort to `medium`.
+
+```python
+client.messages.create(
+    model=&#34;claude-sonnet-4-6&#34;,
+    max_tokens=8192,
+    thinking={&#34;type&#34;: &#34;enabled&#34;, &#34;budget_tokens&#34;: 16384},
+    output_config={&#34;effort&#34;: &#34;low&#34;},
+    messages=[{&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;...&#34;}],
+)
+```
+
+#### When to try adaptive thinking
+
+The extended thinking paths above use `budget_tokens` for predictable token usage. If your workload fits one of the following patterns, consider trying [adaptive thinking](/docs/en/build-with-claude/adaptive-thinking) instead:
+
+- **Autonomous multi-step agents:** coding agents that turn requirements into working software, data analysis pipelines, and bug finding where the model runs independently across many steps. Adaptive thinking lets the model calibrate its reasoning per step, staying on path over longer trajectories. For these workloads, start at `high` effort. If latency or token usage is a concern, scale down to `medium`.
+- **Computer use agents:** Claude Sonnet 4.6 achieved best-in-class accuracy on computer use evaluations using adaptive mode.
+- **Bimodal workloads:** a mix of easy and hard tasks where adaptive skips thinking on simple queries and reasons deeply on complex ones.
+
+When using adaptive thinking, evaluate `medium` and `high` effort on your tasks. The right level depends on your workload&#39;s tradeoff between quality, latency, and token usage.
+
+```python
+client.messages.create(
+    model=&#34;claude-sonnet-4-6&#34;,
+    max_tokens=64000,
+    thinking={&#34;type&#34;: &#34;adaptive&#34;},
+    output_config={&#34;effort&#34;: &#34;high&#34;},
+    messages=[{&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;...&#34;}],
+)
+```</code></pre>
    </div>
</body>
</html>