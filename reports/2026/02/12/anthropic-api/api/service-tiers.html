<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>api/service-tiers - Diff Report</title>
    <link rel="stylesheet" href="../../css/diff.css">
    <style>
        :root {
            --bg-color: #1a1a2e;
            --card-bg: #16213e;
            --text-color: #eee;
            --accent: #0f3460;
            --add-bg: #1a4d1a;
            --del-bg: #4d1a1a;
            --add-text: #4ade80;
            --del-text: #f87171;
        }
        @media (prefers-color-scheme: light) {
            :root {
                --bg-color: #f5f5f5;
                --card-bg: #fff;
                --text-color: #333;
                --accent: #e0e0e0;
                --add-bg: #d4edda;
                --del-bg: #f8d7da;
                --add-text: #155724;
                --del-text: #721c24;
            }
        }
        * { box-sizing: border-box; margin: 0; padding: 0; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: var(--bg-color);
            color: var(--text-color);
            line-height: 1.6;
            padding: 2rem;
        }
        .container { max-width: 1200px; margin: 0 auto; }
        header { margin-bottom: 2rem; }
        h1 { font-size: 1.5rem; margin-bottom: 0.5rem; }
        .meta { color: #888; font-size: 0.9rem; }
        .summary {
            background: var(--card-bg);
            padding: 1rem;
            border-radius: 8px;
            margin-bottom: 2rem;
            display: flex;
            gap: 2rem;
        }
        .stat { display: flex; align-items: center; gap: 0.5rem; }
        .stat.added { color: var(--add-text); }
        .stat.removed { color: var(--del-text); }
        .analysis {
            background: var(--card-bg);
            padding: 1.5rem;
            border-radius: 8px;
            margin-bottom: 2rem;
            border-left: 4px solid #8b5cf6;
        }
        .analysis-header {
            font-weight: 600;
            margin-bottom: 0.75rem;
            color: #8b5cf6;
        }
        .analysis-content {
            white-space: pre-wrap;
            font-size: 0.95rem;
            line-height: 1.7;
        }
        .diff-container {
            background: var(--card-bg);
            border-radius: 8px;
            overflow: hidden;
        }
        .diff-header {
            background: var(--accent);
            padding: 0.75rem 1rem;
            font-weight: 600;
        }
        .diff-content {
            padding: 1rem;
            overflow-x: auto;
        }
        .diff-content ins {
            background: var(--add-bg);
            color: var(--add-text);
            text-decoration: none;
            padding: 0.1em 0.2em;
            border-radius: 2px;
        }
        .diff-content del {
            background: var(--del-bg);
            color: var(--del-text);
            text-decoration: line-through;
            padding: 0.1em 0.2em;
            border-radius: 2px;
        }
        pre {
            background: var(--accent);
            padding: 1rem;
            border-radius: 8px;
            overflow-x: auto;
            font-size: 0.85rem;
            margin-top: 2rem;
        }
        a { color: #60a5fa; }
        .back-link { margin-bottom: 1rem; display: inline-block; }
    </style>
</head>
<body>
    <div class="container">
        <a href="../../index.html" class="back-link">&larr; Back to daily report</a>

        <header>
            <h1>api/service-tiers.md</h1>
            <p class="meta">Changed on 2026-02-12 23:17:05 EST</p>
        </header>

        <div class="summary">
            <div class="stat added">
                <span>+4</span> lines added
            </div>
            <div class="stat removed">
                <span>-3</span> lines removed
            </div>
        </div>

        

        <div class="diff-container">
            <div class="diff-header">Visual Diff</div>
            <div class="diff-content"><span># Service tiers&para;<br>&para;<br>Different tiers of service allow you to balance availability, performance, and predictable costs based on your application's needs.&para;<br>&para;<br>---&para;<br>&para;<br></span><del style="background:#ffe6e6;">We</del><ins style="background:#e6ffe6;">Anthropic</ins><span> offer</span><ins style="background:#e6ffe6;">s</ins><span> three service tiers:&para;<br>- **Priority Tier:** Best for workflows deployed in production where time, availability, and predictable pricing are important&para;<br>- **Standard:** Default tier for both piloting and scaling everyday use cases&para;<br>- **Batch:** Best for asynchronous workflows which can wait or benefit from being outside your normal capacity&para;<br>&para;<br>## Standard Tier&para;<br>&para;<br>The standard tier is the default service tier for all API requests. </span><del style="background:#ffe6e6;">Requests in this tier are prioritized</del><ins style="background:#e6ffe6;">The API prioritizes these requests</ins><span> alongside all other requests </span><del style="background:#ffe6e6;">and observe</del><ins style="background:#e6ffe6;">with</ins><span> best-effort availability.&para;<br>&para;<br>## Priority Tier&para;<br>&para;<br></span><del style="background:#ffe6e6;">R</del><ins style="background:#e6ffe6;">The API prioritizes r</ins><span>equests in this tier </span><del style="background:#ffe6e6;">are prioritized </del><span>over all other requests</span><del style="background:#ffe6e6;"> to Anthropic</del><span>. This prioritization helps minimize ["server overloaded" errors](/docs/en/api/errors#http-errors), even during peak times.&para;<br>&para;<br>For more information, see [Get started with Priority Tier](#get-started-with-priority-tier)&para;<br>&para;<br>## How requests get assigned tiers&para;<br>&para;<br>When handling a request, Anthropic decides to assign a request to Priority Tier in the following scenarios:&para;<br>- Your organization has sufficient priority tier capacity **input** tokens per minute&para;<br>- Your organization has sufficient priority tier capacity **output** tokens per minute&para;<br>&para;<br>Anthropic counts usage against Priority Tier capacity as follows:&para;<br>&para;<br>**Input Tokens**&para;<br>- Cache reads as 0.1 tokens per token read from the cache&para;<br>- Cache writes as 1.25 tokens per token written to the cache with a 5 minute TTL&para;<br>- Cache writes as 2.00 tokens per token written to the cache with a 1 hour TTL&para;<br>- For [long-context](/docs/en/build-with-claude/context-windows) (&gt;200k input tokens) requests, input tokens are 2 tokens per token&para;<br>- For [US-only inference](/docs/en/build-with-claude/data-residency) (`inference_geo: "us"`) requests, input tokens are 1.1 tokens per token&para;<br>- All other input tokens are 1 token per token&para;<br>&para;<br>**Output Tokens**&para;<br>- For [long-context](/docs/en/build-with-claude/context-windows) (&gt;200k input tokens) requests, output tokens are 1.5 tokens per token&para;<br>- For [US-only inference](/docs/en/build-with-claude/data-residency) (`inference_geo: "us"`) requests, output tokens are 1.1 tokens per token&para;<br>- All other output tokens are 1 token per token&para;<br>&para;<br>Otherwise, requests proceed at standard tier.&para;<br>&para;<br>&lt;Note&gt;&para;<br>These burndown rates reflect the relative pricing of each token type. For example, US-only inference is priced at 1.1x, so each token consumed with `inference_geo: "us"` draws down 1.1 tokens from your Priority Tier capacity. Multipliers stack — a long-context request with US-only inference draws down input tokens at 2.2 tokens per token (2 × 1.1).&para;<br>&lt;/Note&gt;&para;<br>&para;<br>&lt;Note&gt;&para;<br>Requests assigned Priority Tier pull from both the Priority Tier capacity and the regular rate limits.&para;<br>If servicing the request would exceed the rate limits, the request is declined.&para;<br>&lt;/Note&gt;&para;<br>&para;<br>## Using service tiers&para;<br>&para;<br>You can control which service tiers can be used for a request by setting the `service_tier` parameter:&para;<br>&para;<br>```python&para;<br>message = client.messages.create(&para;<br>    model="claude-opus-4-6",&para;<br>    max_tokens=1024,&para;<br>    messages=[{"role": "user", "content": "Hello, Claude!"}],&para;<br>    service_tier="auto",  # Automatically use Priority Tier when available, fallback to standard&para;<br>)&para;<br>```&para;<br>&para;<br>The `service_tier` parameter accepts the following values:&para;<br>&para;<br>- `"auto"` (default) - Uses the Priority Tier capacity if available, falling back to your other capacity if not&para;<br>- `"standard_only"` - Only use standard tier capacity, useful if you don't want to use your Priority Tier capacity&para;<br>&para;<br>The response `usage` object also includes the service tier assigned to the request:&para;<br>&para;<br>```json&para;<br>{&para;<br>  "usage": {&para;<br>    "input_tokens": 410,&para;<br>    "cache_creation_input_tokens": 0,&para;<br>    "cache_read_input_tokens": 0,&para;<br>    "output_tokens": 585,&para;<br>    "service_tier": "priority"&para;<br>  }&para;<br>}&para;<br>```&para;<br>This allows you to determine which service tier was assigned to the request.&para;<br>&para;<br>When requesting `service_tier="auto"` with a model with a Priority Tier commitment, these response headers provide insights:&para;<br>```</span><ins style="background:#e6ffe6;">text</ins><span>&para;<br>anthropic-priority-input-tokens-limit: 10000&para;<br>anthropic-priority-input-tokens-remaining: 9618&para;<br>anthropic-priority-input-tokens-reset: 2025-01-12T23:11:59Z&para;<br>anthropic-priority-output-tokens-limit: 10000&para;<br>anthropic-priority-output-tokens-remaining: 6000&para;<br>anthropic-priority-output-tokens-reset: 2025-01-12T23:12:21Z&para;<br>```&para;<br>You can use the presence of these headers to detect if your request was eligible for Priority Tier, even if it was over the limit.&para;<br>&para;<br>## Get started with Priority Tier&para;<br>&para;<br>You may want to commit to Priority Tier capacity if you are interested in:&para;<br>- **Higher availability**: Target 99.5% uptime with prioritized computational resources&para;<br>- **Cost Control**: Predictable spend and discounts for longer commitments&para;<br>- **Flexible overflow**: Automatically falls back to standard tier when you exceed your committed capacity&para;<br>&para;<br>Committing to Priority Tier will involve deciding:&para;<br>- A number of input tokens per minute&para;<br>- A number of output tokens per minute&para;<br>- A commitment duration (1, 3, 6, or 12 months)&para;<br>- A specific model version&para;<br>&para;<br>&lt;Note&gt;&para;<br>The ratio of input to output tokens you purchase matters. Sizing your Priority Tier capacity to align with your actual traffic patterns helps you maximize utilization of your purchased tokens.&para;<br>&lt;/Note&gt;&para;<br>&para;<br>### Supported models&para;<br>&para;<br>Priority Tier is supported by:&para;<br>&para;<br>- Claude Opus 4.6&para;<br>- Claude Opus 4.5&para;<br>- Claude Opus 4.1&para;<br>- Claude Opus 4&para;<br>- Claude Sonnet 4.5&para;<br>- Claude Sonnet 4&para;<br>- Claude Sonnet 3.7 ([deprecated](/docs/en/about-claude/model-deprecations))&para;<br>- Claude Haiku 4.5&para;<br>- Claude Haiku 3.5 ([deprecated](/docs/en/about-claude/model-deprecations))&para;<br>&para;<br>Check the [model overview page](/docs/en/about-claude/models/overview) for more details on our models.&para;<br>&para;<br>### How to access Priority Tier&para;<br>&para;<br>To begin using Priority Tier:&para;<br>&para;<br>1. [Contact sales](https://claude.com/contact-sales/priority-tier) to complete provisioning&para;<br>2. (Optional) Update your API requests to optionally set the `service_tier` parameter to `auto`&para;<br>3. Monitor your usage through response headers and the Claude Console</span></div>
        </div>

        <h2 style="margin-top: 2rem; margin-bottom: 1rem;">Unified Diff</h2>
        <pre><code>--- a/api/service-tiers.md
+++ b/api/service-tiers.md
@@ -4,18 +4,18 @@
 
 ---
 
-We offer three service tiers:
+Anthropic offers three service tiers:
 - **Priority Tier:** Best for workflows deployed in production where time, availability, and predictable pricing are important
 - **Standard:** Default tier for both piloting and scaling everyday use cases
 - **Batch:** Best for asynchronous workflows which can wait or benefit from being outside your normal capacity
 
 ## Standard Tier
 
-The standard tier is the default service tier for all API requests. Requests in this tier are prioritized alongside all other requests and observe best-effort availability.
+The standard tier is the default service tier for all API requests. The API prioritizes these requests alongside all other requests with best-effort availability.
 
 ## Priority Tier
 
-Requests in this tier are prioritized over all other requests to Anthropic. This prioritization helps minimize [&#34;server overloaded&#34; errors](/docs/en/api/errors#http-errors), even during peak times.
+The API prioritizes requests in this tier over all other requests. This prioritization helps minimize [&#34;server overloaded&#34; errors](/docs/en/api/errors#http-errors), even during peak times.
 
 For more information, see [Get started with Priority Tier](#get-started-with-priority-tier)
 
@@ -85,7 +85,7 @@
 This allows you to determine which service tier was assigned to the request.
 
 When requesting `service_tier=&#34;auto&#34;` with a model with a Priority Tier commitment, these response headers provide insights:
-```
+```text
 anthropic-priority-input-tokens-limit: 10000
 anthropic-priority-input-tokens-remaining: 9618
 anthropic-priority-input-tokens-reset: 2025-01-12T23:11:59Z
</code></pre>
    </div>
</body>
</html>