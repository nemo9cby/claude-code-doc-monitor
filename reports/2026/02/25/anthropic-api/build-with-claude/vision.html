<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>build-with-claude/vision - Diff Report</title>
    <link rel="stylesheet" href="../../css/diff.css">
    <style>
        :root {
            --bg-color: #1a1a2e;
            --card-bg: #16213e;
            --text-color: #eee;
            --accent: #0f3460;
            --add-bg: #1a4d1a;
            --del-bg: #4d1a1a;
            --add-text: #4ade80;
            --del-text: #f87171;
        }
        @media (prefers-color-scheme: light) {
            :root {
                --bg-color: #f5f5f5;
                --card-bg: #fff;
                --text-color: #333;
                --accent: #e0e0e0;
                --add-bg: #d4edda;
                --del-bg: #f8d7da;
                --add-text: #155724;
                --del-text: #721c24;
            }
        }
        * { box-sizing: border-box; margin: 0; padding: 0; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: var(--bg-color);
            color: var(--text-color);
            line-height: 1.6;
            padding: 2rem;
        }
        .container { max-width: 1200px; margin: 0 auto; }
        header { margin-bottom: 2rem; }
        h1 { font-size: 1.5rem; margin-bottom: 0.5rem; }
        .meta { color: #888; font-size: 0.9rem; }
        .summary {
            background: var(--card-bg);
            padding: 1rem;
            border-radius: 8px;
            margin-bottom: 2rem;
            display: flex;
            gap: 2rem;
        }
        .stat { display: flex; align-items: center; gap: 0.5rem; }
        .stat.added { color: var(--add-text); }
        .stat.removed { color: var(--del-text); }
        .analysis {
            background: var(--card-bg);
            padding: 1.5rem;
            border-radius: 8px;
            margin-bottom: 2rem;
            border-left: 4px solid #8b5cf6;
        }
        .analysis-header {
            font-weight: 600;
            margin-bottom: 0.75rem;
            color: #8b5cf6;
        }
        .analysis-content {
            white-space: pre-wrap;
            font-size: 0.95rem;
            line-height: 1.7;
        }
        .diff-container {
            background: var(--card-bg);
            border-radius: 8px;
            overflow: hidden;
        }
        .diff-header {
            background: var(--accent);
            padding: 0.75rem 1rem;
            font-weight: 600;
        }
        .diff-content {
            padding: 1rem;
            overflow-x: auto;
        }
        .diff-content ins {
            background: var(--add-bg);
            color: var(--add-text);
            text-decoration: none;
            padding: 0.1em 0.2em;
            border-radius: 2px;
        }
        .diff-content del {
            background: var(--del-bg);
            color: var(--del-text);
            text-decoration: line-through;
            padding: 0.1em 0.2em;
            border-radius: 2px;
        }
        pre {
            background: var(--accent);
            padding: 1rem;
            border-radius: 8px;
            overflow-x: auto;
            font-size: 0.85rem;
            margin-top: 2rem;
        }
        a { color: #60a5fa; }
        .back-link { margin-bottom: 1rem; display: inline-block; }
    </style>
</head>
<body>
    <div class="container">
        <a href="../../index.html" class="back-link">&larr; Back to daily report</a>

        <header>
            <h1>build-with-claude/vision.md</h1>
            <p class="meta">Changed on 2026-02-25 10:57:41 EST</p>
        </header>

        <div class="summary">
            <div class="stat added">
                <span>+8</span> lines added
            </div>
            <div class="stat removed">
                <span>-5</span> lines removed
            </div>
        </div>

        

        <div class="diff-container">
            <div class="diff-header">Visual Diff</div>
            <div class="diff-content"><span># Vision&para;<br>&para;<br>Claude's vision capabilities allow it to understand and analyze images, opening up exciting possibilities for multimodal interaction.&para;<br>&para;<br>---&para;<br>&para;<br>This guide describes how to work with images in Claude, including best practices, code examples, and limitations to keep in mind.&para;<br>&para;<br>---&para;<br>&para;<br>## How to use vision&para;<br>&para;<br>Use Claude’s vision capabilities via:&para;<br>&para;<br>- [claude.ai](https://claude.ai/). Upload an image like you would a file, or drag and drop an image directly into the chat window.&para;<br>- The [Console Workbench](/workbench/). A button to add images appears at the top right of every User message block.&para;<br>- **API request**. See the examples in this guide.&para;<br>&para;<br>---&para;<br>&para;<br>## Before you upload&para;<br>&para;<br>### Basics and Limits&para;<br>&para;<br>You can include multiple images in a single request (up to 20 for [claude.ai](https://claude.ai/) and 100 for API requests). Claude will analyze all provided images when formulating its response. This can be helpful for comparing or contrasting images.&para;<br>&para;<br>If you submit an image larger than 8000x8000 px, it will be rejected. If you submit more than 20 images in one API request, this limit is 2000x2000 px.&para;<br>&para;<br>&lt;Note&gt;&para;<br>While the API supports 100 images per request, there is a [32MB request size limit](/docs/en/api/overview#request-size-limits) for standard endpoints.&para;<br>&lt;/Note&gt;&para;<br>&para;<br>### Evaluate image size&para;<br>&para;<br>For optimal performance, resize images before uploading if they are too large. If your image’s long edge is more than 1568 pixels, or your image is more than ~1,600 tokens, it will first be scaled down, preserving aspect ratio, until it’s within the size limits.&para;<br>&para;<br>If your input image is too large and needs to be resized, it will increase latency of [time-to-first-token](/docs/en/about-claude/glossary), without giving you any additional model performance. Very small images under 200 pixels on any given edge may degrade performance.&para;<br>&para;<br>&lt;Tip&gt;&para;<br>  To improve [time-to-first-token](/docs/en/about-claude/glossary), consider&para;<br>  resizing images to no more than 1.15 megapixels (and within 1568 pixels in&para;<br>  both dimensions).&para;<br>&lt;/Tip&gt;&para;<br>&para;<br>Here is a table of maximum image sizes accepted by the API that will not be resized for common aspect ratios. With Claude Opus 4.6, these images use approximately 1,600 tokens and around $4.80/1K images.&para;<br>&para;<br>| Aspect ratio | Image size   |&para;<br>| ------------ | ------------ |&para;<br>| 1&amp;#58;1      | 1092x1092 px |&para;<br>| 3&amp;#58;4      | 951x1268 px  |&para;<br>| 2&amp;#58;3      | 896x1344 px  |&para;<br>| 9&amp;#58;16     | 819x1456 px  |&para;<br>| 1&amp;#58;2      | 784x1568 px  |&para;<br>&para;<br>### Calculate image costs&para;<br>&para;<br>Each image you include in a request to Claude counts towards your token usage. To calculate the approximate cost, multiply the approximate number of image tokens by the [per-token price of the model](https://claude.com/pricing) you’re using.&para;<br>&para;<br>If your image does not need to be resized, you can estimate the number of tokens used through this algorithm: `tokens = (width px * height px)/750`&para;<br>&para;<br>Here are examples of approximate tokenization and costs for different image sizes within the API's size constraints based on Claude Opus 4.6 per-token price of $3 per million input tokens:&para;<br>&para;<br>| Image size                    | \# of Tokens | Cost / image | Cost / 1K images |&para;<br>| ----------------------------- | ------------ | ------------ | ---------------- |&para;<br>| 200x200 px(0.04 megapixels)   | \~54         | \~$0.00016   | \~$0.16          |&para;<br>| 1000x1000 px(1 megapixel)     | \~1334       | \~$0.004     | \~$4.00          |&para;<br>| 1092x1092 px(1.19 megapixels) | \~1590       | \~$0.0048    | \~$4.80          |&para;<br>&para;<br>### Ensuring image quality&para;<br>&para;<br>When providing images to Claude, keep the following in mind for best results:&para;<br>&para;<br>- **Image format**: Use a supported image format: JPEG, PNG, GIF, or WebP.&para;<br>- **Image clarity**: Ensure images are clear and not too blurry or pixelated.&para;<br>- **Text**: If the image contains important text, make sure it’s legible and not too small. Avoid cropping out key visual context just to enlarge the text.&para;<br>&para;<br>---&para;<br>&para;<br>## Prompt examples&para;<br>&para;<br>Many of the [prompting techniques](/docs/en/build-with-claude/prompt-engineering/overview) that work well for text-based interactions with Claude can also be applied to image-based prompts.&para;<br>&para;<br>These examples demonstrate best practice prompt structures involving images.&para;<br>&para;<br>&lt;Tip&gt;&para;<br>  Just as with document-query placement, Claude works best when images come&para;<br>  before text. Images placed after text or interpolated with text will still&para;<br>  perform well, but if your use case allows it, prefer an image-then-text&para;<br>  structure.&para;<br>&lt;/Tip&gt;&para;<br>&para;<br>### About the prompt examples&para;<br>&para;<br>The following examples demonstrate how to use Claude's vision capabilities using various programming languages and approaches. You can provide images to Claude in three ways:&para;<br>&para;<br>1. As a base64-encoded image in `image` content blocks&para;<br>2. As a URL reference to an image hosted online&para;<br>3. Using the Files API (upload once, use multiple times)&para;<br>&para;<br>The base64 example prompts use these variables:&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>```bash Shell&para;<br>    # For URL-based images, you can use the URL directly in your JSON request&para;<br>&para;<br>    # For base64-encoded images, you need to first encode the image&para;<br>    # Example of how to encode an image to base64 in bash:&para;<br>    BASE64_IMAGE_DATA=$(curl -s "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg" | base64)&para;<br>&para;<br>    # The encoded data can now be used in your API calls&para;<br>```&para;<br>&para;<br>```python Python&para;<br>import base64&para;<br>import httpx&para;<br>&para;<br># For base64-encoded images&para;<br>image1_url = "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg"&para;<br>image1_media_type = "image/jpeg"&para;<br>image1_data = base64.standard_b64encode(httpx.get(image1_url).content).decode("utf-8")&para;<br>&para;<br>image2_url = "https://upload.wikimedia.org/wikipedia/commons/b/b5/Iridescent.green.sweat.bee1.jpg"&para;<br>image2_media_type = "image/jpeg"&para;<br>image2_data = base64.standard_b64encode(httpx.get(image2_url).content).decode("utf-8")&para;<br>&para;<br># For URL-based images, you can use the URLs directly in your requests&para;<br>```&para;<br>&para;<br>```typescript TypeScript&para;<br>import axios from "axios";&para;<br>&para;<br>// For base64-encoded images&para;<br>async function getBase64Image(url: string): Promise&lt;string&gt; {&para;<br>  const response = await axios.get(url, { responseType: "arraybuffer" });&para;<br>  return Buffer.from(response.data, "binary").toString("base64");&para;<br>}&para;<br>&para;<br>// Usage&para;<br>async function prepareImages() {&para;<br>  const imageData = await getBase64Image(</span><ins style="background:#e6ffe6;">&para;<br>    </ins><span>"https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg"</span><ins style="background:#e6ffe6;">&para;<br>  </ins><span>);&para;<br>  // Now you can use imageData in your API calls&para;<br>}&para;<br>&para;<br>// For URL-based images, you can use the URLs directly in your requests&para;<br>```&para;<br>&para;<br>```java Java&para;<br>import java.io.IOException;&para;<br>import java.io.InputStream;&para;<br>import java.net.URL;&para;<br>import java.util.Base64;&para;<br>&para;<br>public class ImageHandlingExample {&para;<br>&para;<br>  public static void main(String[] args) throws IOException, InterruptedException {&para;<br>    // For base64-encoded images&para;<br>    String image1Url =&para;<br>      "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg";&para;<br>    String image1MediaType = "image/jpeg";&para;<br>    String image1Data = downloadAndEncodeImage(image1Url);&para;<br>&para;<br>    String image2Url =&para;<br>      "https://upload.wikimedia.org/wikipedia/commons/b/b5/Iridescent.green.sweat.bee1.jpg";&para;<br>    String image2MediaType = "image/jpeg";&para;<br>    String image2Data = downloadAndEncodeImage(image2Url);&para;<br>&para;<br>    // For URL-based images, you can use the URLs directly in your requests&para;<br>  }&para;<br>&para;<br>  private static String downloadAndEncodeImage(String imageUrl) throws IOException {&para;<br>    try (InputStream inputStream = new URL(imageUrl).openStream()) {&para;<br>      return Base64.getEncoder().encodeToString(inputStream.readAllBytes());&para;<br>    }&para;<br>  }&para;<br>}&para;<br>```&para;<br>&para;<br>```go Go&para;<br>package main&para;<br>&para;<br>import (&para;<br>	"encoding/base64"&para;<br>	"io"&para;<br>	"net/http"&para;<br>)&para;<br>&para;<br>func downloadAndEncodeImage(url string) (string, error) {&para;<br>	resp, err := http.Get(url)&para;<br>	if err != nil {&para;<br>		return "", err&para;<br>	}&para;<br>	defer resp.Body.Close()&para;<br>&para;<br>	data, err := io.ReadAll(resp.Body)&para;<br>	if err != nil {&para;<br>		return "", err&para;<br>	}&para;<br>&para;<br>	return base64.StdEncoding.EncodeToString(data), nil&para;<br>}&para;<br>&para;<br>// Usage:&para;<br>// imageData, _ := downloadAndEncodeImage("https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg")&para;<br>// For URL-based images, you can use the URLs directly in your requests&para;<br>```&para;<br>&para;<br>```ruby Ruby&para;<br>require "base64"&para;<br>require "net/http"&para;<br>require "uri"&para;<br>&para;<br># For base64-encoded images&para;<br>def download_and_encode_image(url)&para;<br>  uri = URI.parse(url)&para;<br>  response = Net::HTTP.get_response(uri)&para;<br>  Base64.strict_encode64(response.body)&para;<br>end&para;<br>&para;<br>image1_url = "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg"&para;<br>image1_media_type = "image/jpeg"&para;<br>image1_data = download_and_encode_image(image1_url)&para;<br>&para;<br># For URL-based images, you can use the URLs directly in your requests&para;<br>```&para;<br>&para;<br>```csharp C#&para;<br>using System;&para;<br>using System.Net.Http;&para;<br>using System.Threading.Tasks;&para;<br>&para;<br>// For base64-encoded images&para;<br>async Task&lt;string&gt; DownloadAndEncodeImageAsync(string url)&para;<br>{&para;<br>    using var client = new HttpClient();&para;<br>    var bytes = await client.GetByteArrayAsync(url);&para;<br>    return Convert.ToBase64String(bytes);&para;<br>}&para;<br>&para;<br>// Usage:&para;<br>// var imageData = await DownloadAndEncodeImageAsync("https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg");&para;<br>// For URL-based images, you can use the URLs directly in your requests&para;<br>```&para;<br>&para;<br>```php PHP&para;<br>&lt;?php&para;<br>// For base64-encoded images&para;<br>function downloadAndEncodeImage($url) {&para;<br>    $imageData = file_get_contents($url);&para;<br>    return base64_encode($imageData);&para;<br>}&para;<br>&para;<br>$image1Url = "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg";&para;<br>$image1MediaType = "image/jpeg";&para;<br>$image1Data = downloadAndEncodeImage($image1Url);&para;<br>&para;<br>// For URL-based images, you can use the URLs directly in your requests&para;<br>```&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>Below are examples of how to include images in a Messages API request using base64-encoded images and URL references:&para;<br>&para;<br>### Base64-encoded image example&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>    ```bash Shell&para;<br>    curl https://api.anthropic.com/v1/messages \&para;<br>      -H "x-api-key: $ANTHROPIC_API_KEY" \&para;<br>      -H "anthropic-version: 2023-06-01" \&para;<br>      -H "content-type: application/json" \&para;<br>      -d '{&para;<br>        "model": "claude-opus-4-6",&para;<br>        "max_tokens": 1024,&para;<br>        "messages": [&para;<br>          {&para;<br>            "role": "user",&para;<br>            "content": [&para;<br>              {&para;<br>                "type": "image",&para;<br>                "source": {&para;<br>                  "type": "base64",&para;<br>                  "media_type": "image/jpeg",&para;<br>                  "data": "'"$BASE64_IMAGE_DATA"'"&para;<br>                }&para;<br>              },&para;<br>              {&para;<br>                "type": "text",&para;<br>                "text": "Describe this image."&para;<br>              }&para;<br>            ]&para;<br>          }&para;<br>        ]&para;<br>      }'&para;<br>    ```&para;<br>    ```python Python&para;<br>    import anthropic&para;<br>&para;<br>    client = anthropic.Anthropic()&para;<br>    message = client.messages.create(&para;<br>        model="claude-opus-4-6",&para;<br>        max_tokens=1024,&para;<br>        messages=[&para;<br>            {&para;<br>                "role": "user",&para;<br>                "content": [&para;<br>                    {&para;<br>                        "type": "image",&para;<br>                        "source": {&para;<br>                            "type": "base64",&para;<br>                            "media_type": image1_media_type,&para;<br>                            "data": image1_data,&para;<br>                        },&para;<br>                    },&para;<br>                    {"type": "text", "text": "Describe this image."},&para;<br>                ],&para;<br>            }&para;<br>        ],&para;<br>    )&para;<br>    print(message)&para;<br>    ```&para;<br>    ```typescript TypeScript&para;<br>    import Anthropic from "@anthropic-ai/sdk";&para;<br>&para;<br>    const anthropic = new Anthropic({&para;<br>      apiKey: process.env.ANTHROPIC_API_KEY&para;<br>    });&para;<br>&para;<br>    async function main() {&para;<br>      const message = await anthropic.messages.create({&para;<br>        model: "claude-opus-4-6",&para;<br>        max_tokens: 1024,&para;<br>        messages: [&para;<br>          {&para;<br>            role: "user",&para;<br>            content: [&para;<br>              {&para;<br>                type: "image",&para;<br>                source: {&para;<br>                  type: "base64",&para;<br>                  media_type: "image/jpeg",&para;<br>                  data: imageData // Base64-encoded image data as string&para;<br>                }&para;<br>              },&para;<br>              {&para;<br>                type: "text",&para;<br>                text: "Describe this image."&para;<br>              }&para;<br>            ]&para;<br>          }&para;<br>        ]&para;<br>      });&para;<br>&para;<br>      console.log(message);&para;<br>    }&para;<br>&para;<br>    main();&para;<br>    ```&para;<br>&para;<br>    ```java Java&para;<br>    import com.anthropic.client.AnthropicClient;&para;<br>    import com.anthropic.client.okhttp.AnthropicOkHttpClient;&para;<br>    import com.anthropic.models.messages.*;&para;<br>    import java.io.IOException;&para;<br>    import java.util.List;&para;<br>&para;<br>    public class VisionExample {&para;<br>&para;<br>      public static void main(String[] args) throws IOException, InterruptedException {&para;<br>        AnthropicClient client = AnthropicOkHttpClient.fromEnv();&para;<br>        String imageData = ""; // // Base64-encoded image data as string&para;<br>&para;<br>        List&lt;ContentBlockParam&gt; contentBlockParams = List.of(&para;<br>          ContentBlockParam.ofImage(&para;<br>            ImageBlockParam.builder()&para;<br>              .source(Base64ImageSource.builder().data(imageData).build())&para;<br>              .build()&para;<br>          ),&para;<br>          ContentBlockParam.ofText(TextBlockParam.builder().text("Describe this image.").build())&para;<br>        );&para;<br>        Message message = client&para;<br>          .messages()&para;<br>          .create(&para;<br>            MessageCreateParams.builder()&para;<br>              .model(Model.CLAUDE_OPUS_4_6)&para;<br>              .maxTokens(1024)&para;<br>              .addUserMessageOfBlockParams(contentBlockParams)&para;<br>              .build()&para;<br>          );&para;<br>&para;<br>        System.out.println(message);&para;<br>      }&para;<br>    }&para;<br>    ```&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>### URL-based image example&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>    ```bash Shell&para;<br>    curl https://api.anthropic.com/v1/messages \&para;<br>      -H "x-api-key: $ANTHROPIC_API_KEY" \&para;<br>      -H "anthropic-version: 2023-06-01" \&para;<br>      -H "content-type: application/json" \&para;<br>      -d '{&para;<br>        "model": "claude-opus-4-6",&para;<br>        "max_tokens": 1024,&para;<br>        "messages": [&para;<br>          {&para;<br>            "role": "user",&para;<br>            "content": [&para;<br>              {&para;<br>                "type": "image",&para;<br>                "source": {&para;<br>                  "type": "url",&para;<br>                  "url": "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg"&para;<br>                }&para;<br>              },&para;<br>              {&para;<br>                "type": "text",&para;<br>                "text": "Describe this image."&para;<br>              }&para;<br>            ]&para;<br>          }&para;<br>        ]&para;<br>      }'&para;<br>    ```&para;<br>    ```python Python&para;<br>    import anthropic&para;<br>&para;<br>    client = anthropic.Anthropic()&para;<br>    message = client.messages.create(&para;<br>        model="claude-opus-4-6",&para;<br>        max_tokens=1024,&para;<br>        messages=[&para;<br>            {&para;<br>                "role": "user",&para;<br>                "content": [&para;<br>                    {&para;<br>                        "type": "image",&para;<br>                        "source": {&para;<br>                            "type": "url",&para;<br>                            "url": "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg",&para;<br>                        },&para;<br>                    },&para;<br>                    {"type": "text", "text": "Describe this image."},&para;<br>                ],&para;<br>            }&para;<br>        ],&para;<br>    )&para;<br>    print(message)&para;<br>    ```&para;<br>    ```typescript TypeScript&para;<br>    import Anthropic from "@anthropic-ai/sdk";&para;<br>&para;<br>    const anthropic = new Anthropic({&para;<br>      apiKey: process.env.ANTHROPIC_API_KEY&para;<br>    });&para;<br>&para;<br>    async function main() {&para;<br>      const message = await anthropic.messages.create({&para;<br>        model: "claude-opus-4-6",&para;<br>        max_tokens: 1024,&para;<br>        messages: [&para;<br>          {&para;<br>            role: "user",&para;<br>            content: [&para;<br>              {&para;<br>                type: "image",&para;<br>                source: {&para;<br>                  type: "url",&para;<br>                  url: "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg"&para;<br>                }&para;<br>              },&para;<br>              {&para;<br>                type: "text",&para;<br>                text: "Describe this image."&para;<br>              }&para;<br>            ]&para;<br>          }&para;<br>        ]&para;<br>      });&para;<br>&para;<br>      console.log(message);&para;<br>    }&para;<br>&para;<br>    main();&para;<br>    ```&para;<br>    ```java Java&para;<br>    import com.anthropic.client.AnthropicClient;&para;<br>    import com.anthropic.client.okhttp.AnthropicOkHttpClient;&para;<br>    import com.anthropic.models.messages.*;&para;<br>    import java.io.IOException;&para;<br>    import java.util.List;&para;<br>&para;<br>    public class VisionExample {&para;<br>&para;<br>      public static void main(String[] args) throws IOException, InterruptedException {&para;<br>        AnthropicClient client = AnthropicOkHttpClient.fromEnv();&para;<br>&para;<br>        List&lt;ContentBlockParam&gt; contentBlockParams = List.of(&para;<br>          ContentBlockParam.ofImage(&para;<br>            ImageBlockParam.builder()&para;<br>              .source(&para;<br>                UrlImageSource.builder()&para;<br>                  .url(&para;<br>                    "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg"&para;<br>                  )&para;<br>                  .build()&para;<br>              )&para;<br>              .build()&para;<br>          ),&para;<br>          ContentBlockParam.ofText(TextBlockParam.builder().text("Describe this image.").build())&para;<br>        );&para;<br>        Message message = client&para;<br>          .messages()&para;<br>          .create(&para;<br>            MessageCreateParams.builder()&para;<br>              .model(Model.CLAUDE_OPUS_4_6)&para;<br>              .maxTokens(1024)&para;<br>              .addUserMessageOfBlockParams(contentBlockParams)&para;<br>              .build()&para;<br>          );&para;<br>        System.out.println(message);&para;<br>      }&para;<br>    }&para;<br>    ```&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>### Files API image example&para;<br>&para;<br>For images you'll use repeatedly or when you want to avoid encoding overhead, use the [Files API](/docs/en/build-with-claude/files):&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>```bash Shell&para;<br># First, upload your image to the Files API&para;<br>curl -X POST https://api.anthropic.com/v1/files \&para;<br>  -H "x-api-key: $ANTHROPIC_API_KEY" \&para;<br>  -H "anthropic-version: 2023-06-01" \&para;<br>  -H "anthropic-beta: files-api-2025-04-14" \&para;<br>  -F "file=@image.jpg"&para;<br>&para;<br># Then use the returned file_id in your message&para;<br>curl https://api.anthropic.com/v1/messages \&para;<br>  -H "x-api-key: $ANTHROPIC_API_KEY" \&para;<br>  -H "anthropic-version: 2023-06-01" \&para;<br>  -H "anthropic-beta: files-api-2025-04-14" \&para;<br>  -H "content-type: application/json" \&para;<br>  -d '{&para;<br>    "model": "claude-opus-4-6",&para;<br>    "max_tokens": 1024,&para;<br>    "messages": [&para;<br>      {&para;<br>        "role": "user",&para;<br>        "content": [&para;<br>          {&para;<br>            "type": "image",&para;<br>            "source": {&para;<br>              "type": "file",&para;<br>              "file_id": "file_abc123"&para;<br>            }&para;<br>          },&para;<br>          {&para;<br>            "type": "text",&para;<br>            "text": "Describe this image."&para;<br>          }&para;<br>        ]&para;<br>      }&para;<br>    ]&para;<br>  }'&para;<br>```&para;<br>&para;<br>```python Python&para;<br>import anthropic&para;<br>&para;<br>client = anthropic.Anthropic()&para;<br>&para;<br># Upload the image file&para;<br>with open("image.jpg", "rb") as f:&para;<br>    file_upload = client.beta.files.upload(file=("image.jpg", f, "image/jpeg"))&para;<br>&para;<br># Use the uploaded file in a message&para;<br>message = client.beta.messages.create(&para;<br>    model="claude-opus-4-6",&para;<br>    max_tokens=1024,&para;<br>    betas=["files-api-2025-04-14"],&para;<br>    messages=[&para;<br>        {&para;<br>            "role": "user",&para;<br>            "content": [&para;<br>                {&para;<br>                    "type": "image",&para;<br>                    "source": {"type": "file", "file_id": file_upload.id},&para;<br>                },&para;<br>                {"type": "text", "text": "Describe this image."},&para;<br>            ],&para;<br>        }&para;<br>    ],&para;<br>)&para;<br>&para;<br>print(message.content)&para;<br>```&para;<br>&para;<br>```typescript TypeScript&para;<br>import { Anthropic, toFile } from "@anthropic-ai/sdk";&para;<br>import fs from "fs";&para;<br>&para;<br>const anthropic = new Anthropic();&para;<br>&para;<br>async function main() {&para;<br>  // Upload the image file&para;<br>  const fileUpload = await anthropic.beta.files.upload(</span><del style="background:#ffe6e6;">{</del><span>&para;<br></span><ins style="background:#e6ffe6;">    {&para;<br>  </ins><span>    file: toFile(fs.createReadStream("image.jpg"), undefined, { type: "image/jpeg" })&para;<br>  </span><ins style="background:#e6ffe6;">  </ins><span>},</span><del style="background:#ffe6e6;"> {</del><span>&para;<br>   </span><ins style="background:#e6ffe6;"> {</ins><span> betas: ["files-api-2025-04-14"]</span><ins style="background:#e6ffe6;"> }</ins><span>&para;<br>  </span><del style="background:#ffe6e6;">}</del><span>);&para;<br>&para;<br>  // Use the uploaded file in a message&para;<br>  const response = await anthropic.beta.messages.create({&para;<br>    model: "claude-opus-4-6",&para;<br>    max_tokens: 1024,&para;<br>    betas: ["files-api-2025-04-14"],&para;<br>    messages: [&para;<br>      {&para;<br>        role: "user",&para;<br>        content: [&para;<br>          {&para;<br>            type: "image",&para;<br>            source: {&para;<br>              type: "file",&para;<br>              file_id: fileUpload.id&para;<br>            }&para;<br>          },&para;<br>          {&para;<br>            type: "text",&para;<br>            text: "Describe this image."&para;<br>          }&para;<br>        ]&para;<br>      }&para;<br>    ]&para;<br>  });&para;<br>&para;<br>  console.log(response);&para;<br>}&para;<br>&para;<br>main();&para;<br>```&para;<br>&para;<br>```java Java&para;<br>import com.anthropic.client.AnthropicClient;&para;<br>import com.anthropic.client.okhttp.AnthropicOkHttpClient;&para;<br>import com.anthropic.models.File;&para;<br>import com.anthropic.models.files.FileUploadParams;&para;<br>import com.anthropic.models.messages.*;&para;<br>import java.io.IOException;&para;<br>import java.nio.file.Files;&para;<br>import java.nio.file.Path;&para;<br>import java.util.List;&para;<br>&para;<br>public class ImageFilesExample {&para;<br>&para;<br>  public static void main(String[] args) throws IOException {&para;<br>    AnthropicClient client = AnthropicOkHttpClient.fromEnv();&para;<br>&para;<br>    // Upload the image file&para;<br>    File file = client&para;<br>      .beta()&para;<br>      .files()&para;<br>      .upload(&para;<br>        FileUploadParams.builder().file(Files.newInputStream(Path.of("image.jpg"))).build()&para;<br>      );&para;<br>&para;<br>    // Use the uploaded file in a message&para;<br>    ImageBlockParam imageParam = ImageBlockParam.builder().fileSource(file.id()).build();&para;<br>&para;<br>    MessageCreateParams params = MessageCreateParams.builder()&para;<br>      .model(Model.CLAUDE_OPUS_4_6)&para;<br>      .maxTokens(1024)&para;<br>      .addUserMessageOfBlockParams(&para;<br>        List.of(&para;<br>          ContentBlockParam.ofImage(imageParam),&para;<br>          ContentBlockParam.ofText(&para;<br>            TextBlockParam.builder().text("Describe this image.").build()&para;<br>          )&para;<br>        )&para;<br>      )&para;<br>      .build();&para;<br>&para;<br>    Message message = client.messages().create(params);&para;<br>    System.out.println(message.content());&para;<br>  }&para;<br>}&para;<br>```&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>See [Messages API examples](/docs/en/api/messages) for more example code and parameter details.&para;<br>&para;<br>&lt;section title="Example: One image"&gt;&para;<br>&para;<br>It’s best to place images earlier in the prompt than questions about them or instructions for tasks that use them.&para;<br>&para;<br>Ask Claude to describe one image.&para;<br>&para;<br>| Role | Content                        |&para;<br>| ---- | ------------------------------ |&para;<br>| User | \[Image\] Describe this image. |&para;<br>&para;<br>&lt;Tabs&gt;&para;<br>  &lt;Tab title="Using Base64"&gt;&para;<br>    ```python Python&para;<br>    message = client.messages.create(&para;<br>        model="claude-opus-4-6",&para;<br>        max_tokens=1024,&para;<br>        messages=[&para;<br>            {&para;<br>                "role": "user",&para;<br>                "content": [&para;<br>                    {&para;<br>                        "type": "image",&para;<br>                        "source": {&para;<br>                            "type": "base64",&para;<br>                            "media_type": image1_media_type,&para;<br>                            "data": image1_data,&para;<br>                        },&para;<br>                    },&para;<br>                    {"type": "text", "text": "Describe this image."},&para;<br>                ],&para;<br>            }&para;<br>        ],&para;<br>    )&para;<br>    ```&para;<br>  &lt;/Tab&gt;&para;<br>  &lt;Tab title="Using URL"&gt;&para;<br>    ```python Python&para;<br>    message = client.messages.create(&para;<br>        model="claude-opus-4-6",&para;<br>        max_tokens=1024,&para;<br>        messages=[&para;<br>            {&para;<br>                "role": "user",&para;<br>                "content": [&para;<br>                    {&para;<br>                        "type": "image",&para;<br>                        "source": {&para;<br>                            "type": "url",&para;<br>                            "url": "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg",&para;<br>                        },&para;<br>                    },&para;<br>                    {"type": "text", "text": "Describe this image."},&para;<br>                ],&para;<br>            }&para;<br>        ],&para;<br>    )&para;<br>    ```&para;<br>  &lt;/Tab&gt;&para;<br>&lt;/Tabs&gt;&para;<br>&para;<br>&lt;/section&gt;&para;<br>&lt;section title="Example: Multiple images"&gt;&para;<br>&para;<br>In situations where there are multiple images, introduce each image with `Image 1:` and `Image 2:` and so on. You don’t need newlines between images or between images and the prompt.&para;<br>&para;<br>Ask Claude to describe the differences between multiple images.&para;<br>| Role | Content |&para;<br>| ---- | ------------------------------------------------------------------------- |&para;<br>| User | Image 1: \[Image 1\] Image 2: \[Image 2\] How are these images different? |&para;<br>&para;<br>&lt;Tabs&gt;&para;<br>  &lt;Tab title="Using Base64"&gt;&para;<br>    ```python Python&para;<br>    message = client.messages.create(&para;<br>        model="claude-opus-4-6",&para;<br>        max_tokens=1024,&para;<br>        messages=[&para;<br>            {&para;<br>                "role": "user",&para;<br>                "content": [&para;<br>                    {"type": "text", "text": "Image 1:"},&para;<br>                    {&para;<br>                        "type": "image",&para;<br>                        "source": {&para;<br>                            "type": "base64",&para;<br>                            "media_type": image1_media_type,&para;<br>                            "data": image1_data,&para;<br>                        },&para;<br>                    },&para;<br>                    {"type": "text", "text": "Image 2:"},&para;<br>                    {&para;<br>                        "type": "image",&para;<br>                        "source": {&para;<br>                            "type": "base64",&para;<br>                            "media_type": image2_media_type,&para;<br>                            "data": image2_data,&para;<br>                        },&para;<br>                    },&para;<br>                    {"type": "text", "text": "How are these images different?"},&para;<br>                ],&para;<br>            }&para;<br>        ],&para;<br>    )&para;<br>    ```&para;<br>  &lt;/Tab&gt;&para;<br>  &lt;Tab title="Using URL"&gt;&para;<br>    ```python Python&para;<br>    message = client.messages.create(&para;<br>        model="claude-opus-4-6",&para;<br>        max_tokens=1024,&para;<br>        messages=[&para;<br>            {&para;<br>                "role": "user",&para;<br>                "content": [&para;<br>                    {"type": "text", "text": "Image 1:"},&para;<br>                    {&para;<br>                        "type": "image",&para;<br>                        "source": {&para;<br>                            "type": "url",&para;<br>                            "url": "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg",&para;<br>                        },&para;<br>                    },&para;<br>                    {"type": "text", "text": "Image 2:"},&para;<br>                    {&para;<br>                        "type": "image",&para;<br>                        "source": {&para;<br>                            "type": "url",&para;<br>                            "url": "https://upload.wikimedia.org/wikipedia/commons/b/b5/Iridescent.green.sweat.bee1.jpg",&para;<br>                        },&para;<br>                    },&para;<br>                    {"type": "text", "text": "How are these images different?"},&para;<br>                ],&para;<br>            }&para;<br>        ],&para;<br>    )&para;<br>    ```&para;<br>  &lt;/Tab&gt;&para;<br>&lt;/Tabs&gt;&para;<br>&para;<br>&lt;/section&gt;&para;<br>&lt;section title="Example: Multiple images with a system prompt"&gt;&para;<br>&para;<br>Ask Claude to describe the differences between multiple images, while giving it a system prompt for how to respond.&para;<br>&para;<br>| Content |                                                                           |&para;<br>| ------- | ------------------------------------------------------------------------- |&para;<br>| System  | Respond only in Spanish.                                                  |&para;<br>| User    | Image 1: \[Image 1\] Image 2: \[Image 2\] How are these images different? |&para;<br>&para;<br>&lt;Tabs&gt;&para;<br>  &lt;Tab title="Using Base64"&gt;&para;<br>    ```python Python&para;<br>    message = client.messages.create(&para;<br>        model="claude-opus-4-6",&para;<br>        max_tokens=1024,&para;<br>        system="Respond only in Spanish.",&para;<br>        messages=[&para;<br>            {&para;<br>                "role": "user",&para;<br>                "content": [&para;<br>                    {"type": "text", "text": "Image 1:"},&para;<br>                    {&para;<br>                        "type": "image",&para;<br>                        "source": {&para;<br>                            "type": "base64",&para;<br>                            "media_type": image1_media_type,&para;<br>                            "data": image1_data,&para;<br>                        },&para;<br>                    },&para;<br>                    {"type": "text", "text": "Image 2:"},&para;<br>                    {&para;<br>                        "type": "image",&para;<br>                        "source": {&para;<br>                            "type": "base64",&para;<br>                            "media_type": image2_media_type,&para;<br>                            "data": image2_data,&para;<br>                        },&para;<br>                    },&para;<br>                    {"type": "text", "text": "How are these images different?"},&para;<br>                ],&para;<br>            }&para;<br>        ],&para;<br>    )&para;<br>    ```&para;<br>  &lt;/Tab&gt;&para;<br>  &lt;Tab title="Using URL"&gt;&para;<br>    ```python Python&para;<br>    message = client.messages.create(&para;<br>        model="claude-opus-4-6",&para;<br>        max_tokens=1024,&para;<br>        system="Respond only in Spanish.",&para;<br>        messages=[&para;<br>            {&para;<br>                "role": "user",&para;<br>                "content": [&para;<br>                    {"type": "text", "text": "Image 1:"},&para;<br>                    {&para;<br>                        "type": "image",&para;<br>                        "source": {&para;<br>                            "type": "url",&para;<br>                            "url": "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg",&para;<br>                        },&para;<br>                    },&para;<br>                    {"type": "text", "text": "Image 2:"},&para;<br>                    {&para;<br>                        "type": "image",&para;<br>                        "source": {&para;<br>                            "type": "url",&para;<br>                            "url": "https://upload.wikimedia.org/wikipedia/commons/b/b5/Iridescent.green.sweat.bee1.jpg",&para;<br>                        },&para;<br>                    },&para;<br>                    {"type": "text", "text": "How are these images different?"},&para;<br>                ],&para;<br>            }&para;<br>        ],&para;<br>    )&para;<br>    ```&para;<br>  &lt;/Tab&gt;&para;<br>&lt;/Tabs&gt;&para;<br>&para;<br>&lt;/section&gt;&para;<br>&lt;section title="Example: Four images across two conversation turns"&gt;&para;<br>&para;<br>Claude’s vision capabilities shine in multimodal conversations that mix images and text. You can have extended back-and-forth exchanges with Claude, adding new images or follow-up questions at any point. This enables powerful workflows for iterative image analysis, comparison, or combining visuals with other knowledge.&para;<br>&para;<br>Ask Claude to contrast two images, then ask a follow-up question comparing the first images to two new images.&para;<br>| Role | Content |&para;<br>| --------- | ------------------------------------------------------------------------------------ |&para;<br>| User | Image 1: \[Image 1\] Image 2: \[Image 2\] How are these images different? |&para;<br>| Assistant | \[Claude's response\] |&para;<br>| User | Image 1: \[Image 3\] Image 2: \[Image 4\] Are these images similar to the first two? |&para;<br>| Assistant | \[Claude's response\] |&para;<br>&para;<br>When using the API, simply insert new images into the array of Messages in the `user` role as part of any standard [multiturn conversation](/docs/en/api/messages) structure.&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>---&para;<br>&para;<br>## Limitations&para;<br>&para;<br>While Claude's image understanding capabilities are cutting-edge, there are some limitations to be aware of:&para;<br>&para;<br>- **People identification**: Claude [cannot be used](https://www.anthropic.com/legal/aup) to identify (i.e., name) people in images and will refuse to do so.&para;<br>- **Accuracy**: Claude may hallucinate or make mistakes when interpreting low-quality, rotated, or very small images under 200 pixels.&para;<br>- **Spatial reasoning**: Claude's spatial reasoning abilities are limited. It may struggle with tasks requiring precise localization or layouts, like reading an analog clock face or describing exact positions of chess pieces.&para;<br>- **Counting**: Claude can give approximate counts of objects in an image but may not always be precisely accurate, especially with large numbers of small objects.&para;<br>- **AI generated images**: Claude does not know if an image is AI-generated and may be incorrect if asked. Do not rely on it to detect fake or synthetic images.&para;<br>- **Inappropriate content**: Claude will not process inappropriate or explicit images that violate the [Acceptable Use Policy](https://www.anthropic.com/legal/aup).&para;<br>- **Healthcare applications**: While Claude can analyze general medical images, it is not designed to interpret complex diagnostic scans such as CTs or MRIs. Claude's outputs should not be considered a substitute for professional medical advice or diagnosis.&para;<br>&para;<br>Always carefully review and verify Claude's image interpretations, especially for high-stakes use cases. Do not use Claude for tasks requiring perfect precision or sensitive image analysis without human oversight.&para;<br>&para;<br>---&para;<br>&para;<br>## FAQ&para;<br>&para;<br>  &lt;section title="What image file types does Claude support?"&gt;&para;<br>&para;<br>    Claude currently supports JPEG, PNG, GIF, and WebP image formats, specifically:&para;<br>    - `image/jpeg`&para;<br>    - `image/png`&para;<br>    - `image/gif`&para;<br>    - `image/webp`&para;<br>  &para;<br>&lt;/section&gt;&para;<br>&para;<br>{" "}&para;<br>&para;<br>&lt;section title="Can Claude read image URLs?"&gt;&para;<br>&para;<br>  Yes, Claude can process images from URLs with URL image source blocks in the API.&para;<br>  Simply use the "url" source type instead of "base64" in your API requests.&para;<br>  Example:&para;<br>  ```json&para;<br>  {&para;<br>    "type": "image",&para;<br>    "source": {&para;<br>      "type": "url",&para;<br>      "url": "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg"&para;<br>    }&para;<br>  }&para;<br>  ```&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>  &lt;section title="Is there a limit to the image file size I can upload?"&gt;&para;<br>&para;<br>    Yes, there are limits:&para;<br>    - API: Maximum 5MB per image&para;<br>    - claude.ai: Maximum 10MB per image&para;<br>&para;<br>    Images larger than these limits will be rejected and return an error when using the API.&para;<br>&para;<br>  &para;<br>&lt;/section&gt;&para;<br>&para;<br>  &lt;section title="How many images can I include in one request?"&gt;&para;<br>&para;<br>    The image limits are:&para;<br>    - Messages API: Up to 100 images per request&para;<br>    - claude.ai: Up to 20 images per turn&para;<br>&para;<br>    Requests exceeding these limits will be rejected and return an error.&para;<br>&para;<br>  &para;<br>&lt;/section&gt;&para;<br>&para;<br>{" "}&para;<br>&para;<br>&lt;section title="Does Claude read image metadata?"&gt;&para;<br>&para;<br>  No, Claude does not parse or receive any metadata from images passed to it.&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>{" "}&para;<br>&para;<br>&lt;section title="Can I delete images I've uploaded?"&gt;&para;<br>&para;<br>  No. Image uploads are ephemeral and not stored beyond the duration of the API&para;<br>  request. Uploaded images are automatically deleted after they have been&para;<br>  processed.&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>{" "}&para;<br>&para;<br>&lt;section title="Where can I find details on data privacy for image uploads?"&gt;&para;<br>&para;<br>  Refer to the Anthropic privacy policy page for information on how uploaded&para;<br>  images and other data are handled. Anthropic does not use uploaded images to&para;<br>  train models.&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>  &lt;section title="What if Claude's image interpretation seems wrong?"&gt;&para;<br>&para;<br>    If Claude's image interpretation seems incorrect:&para;<br>    1. Ensure the image is clear, high-quality, and correctly oriented.&para;<br>    2. Try prompt engineering techniques to improve results.&para;<br>    3. If the issue persists, flag the output in claude.ai (thumbs up/down) or contact the [support team](https://support.claude.com/).&para;<br>&para;<br>    Your feedback helps improve Claude!&para;<br>&para;<br>  &para;<br>&lt;/section&gt;&para;<br>&para;<br>  &lt;section title="Can Claude generate or edit images?"&gt;&para;<br>&para;<br>    No, Claude is an image understanding model only. It can interpret and analyze images, but it cannot generate, produce, edit, manipulate, or create images.&para;<br>  &para;<br>&lt;/section&gt;&para;<br>&para;<br>---&para;<br>&para;<br>## Dive deeper into vision&para;<br>&para;<br>Ready to start building with images using Claude? Here are a few helpful resources:&para;<br>&para;<br>- [Multimodal cookbook](https://platform.claude.com/cookbook/multimodal-getting-started-with-vision): This cookbook has tips on [getting started with images](https://platform.claude.com/cookbook/multimodal-getting-started-with-vision) and [best practice techniques](https://platform.claude.com/cookbook/multimodal-best-practices-for-vision) to ensure the highest quality performance with images. See how you can effectively prompt Claude with images to carry out tasks such as [interpreting and analyzing charts](https://platform.claude.com/cookbook/multimodal-reading-charts-graphs-powerpoints) or [extracting content from forms](https://platform.claude.com/cookbook/multimodal-how-to-transcribe-text).&para;<br>- [API reference](/docs/en/api/messages): Documentation for the Messages API, including example [API calls involving images](/docs/en/build-with-claude/working-with-messages#vision).&para;<br>&para;<br>If you have any other questions, reach out to the [support team](https://support.claude.com/). You can also join the [developer community](https://www.anthropic.com/discord) to connect with other creators and get help from Anthropic experts.</span></div>
        </div>

        <h2 style="margin-top: 2rem; margin-bottom: 1rem;">Unified Diff</h2>
        <pre><code>--- a/build-with-claude/vision.md
+++ b/build-with-claude/vision.md
@@ -137,7 +137,9 @@
 
 // Usage
 async function prepareImages() {
-  const imageData = await getBase64Image(&#34;https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg&#34;);
+  const imageData = await getBase64Image(
+    &#34;https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg&#34;
+  );
   // Now you can use imageData in your API calls
 }
 
@@ -607,11 +609,12 @@
 
 async function main() {
   // Upload the image file
-  const fileUpload = await anthropic.beta.files.upload({
-    file: toFile(fs.createReadStream(&#34;image.jpg&#34;), undefined, { type: &#34;image/jpeg&#34; })
-  }, {
-    betas: [&#34;files-api-2025-04-14&#34;]
-  });
+  const fileUpload = await anthropic.beta.files.upload(
+    {
+      file: toFile(fs.createReadStream(&#34;image.jpg&#34;), undefined, { type: &#34;image/jpeg&#34; })
+    },
+    { betas: [&#34;files-api-2025-04-14&#34;] }
+  );
 
   // Use the uploaded file in a message
   const response = await anthropic.beta.messages.create({
</code></pre>
    </div>
</body>
</html>