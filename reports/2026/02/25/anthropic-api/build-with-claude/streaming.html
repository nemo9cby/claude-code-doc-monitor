<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>build-with-claude/streaming - Diff Report</title>
    <link rel="stylesheet" href="../../css/diff.css">
    <style>
        :root {
            --bg-color: #1a1a2e;
            --card-bg: #16213e;
            --text-color: #eee;
            --accent: #0f3460;
            --add-bg: #1a4d1a;
            --del-bg: #4d1a1a;
            --add-text: #4ade80;
            --del-text: #f87171;
        }
        @media (prefers-color-scheme: light) {
            :root {
                --bg-color: #f5f5f5;
                --card-bg: #fff;
                --text-color: #333;
                --accent: #e0e0e0;
                --add-bg: #d4edda;
                --del-bg: #f8d7da;
                --add-text: #155724;
                --del-text: #721c24;
            }
        }
        * { box-sizing: border-box; margin: 0; padding: 0; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: var(--bg-color);
            color: var(--text-color);
            line-height: 1.6;
            padding: 2rem;
        }
        .container { max-width: 1200px; margin: 0 auto; }
        header { margin-bottom: 2rem; }
        h1 { font-size: 1.5rem; margin-bottom: 0.5rem; }
        .meta { color: #888; font-size: 0.9rem; }
        .summary {
            background: var(--card-bg);
            padding: 1rem;
            border-radius: 8px;
            margin-bottom: 2rem;
            display: flex;
            gap: 2rem;
        }
        .stat { display: flex; align-items: center; gap: 0.5rem; }
        .stat.added { color: var(--add-text); }
        .stat.removed { color: var(--del-text); }
        .analysis {
            background: var(--card-bg);
            padding: 1.5rem;
            border-radius: 8px;
            margin-bottom: 2rem;
            border-left: 4px solid #8b5cf6;
        }
        .analysis-header {
            font-weight: 600;
            margin-bottom: 0.75rem;
            color: #8b5cf6;
        }
        .analysis-content {
            white-space: pre-wrap;
            font-size: 0.95rem;
            line-height: 1.7;
        }
        .diff-container {
            background: var(--card-bg);
            border-radius: 8px;
            overflow: hidden;
        }
        .diff-header {
            background: var(--accent);
            padding: 0.75rem 1rem;
            font-weight: 600;
        }
        .diff-content {
            padding: 1rem;
            overflow-x: auto;
        }
        .diff-content ins {
            background: var(--add-bg);
            color: var(--add-text);
            text-decoration: none;
            padding: 0.1em 0.2em;
            border-radius: 2px;
        }
        .diff-content del {
            background: var(--del-bg);
            color: var(--del-text);
            text-decoration: line-through;
            padding: 0.1em 0.2em;
            border-radius: 2px;
        }
        pre {
            background: var(--accent);
            padding: 1rem;
            border-radius: 8px;
            overflow-x: auto;
            font-size: 0.85rem;
            margin-top: 2rem;
        }
        a { color: #60a5fa; }
        .back-link { margin-bottom: 1rem; display: inline-block; }
    </style>
</head>
<body>
    <div class="container">
        <a href="../../index.html" class="back-link">&larr; Back to daily report</a>

        <header>
            <h1>build-with-claude/streaming.md</h1>
            <p class="meta">Changed on 2026-02-25 10:57:41 EST</p>
        </header>

        <div class="summary">
            <div class="stat added">
                <span>+92</span> lines added
            </div>
            <div class="stat removed">
                <span>-12</span> lines removed
            </div>
        </div>

        

        <div class="diff-container">
            <div class="diff-header">Visual Diff</div>
            <div class="diff-content"><span># Streaming Messages&para;<br>&para;<br>---&para;<br>&para;<br>When creating a Message, you can set `"stream": true` to incrementally stream the response using [server-sent events](https://developer.mozilla.org/en-US/Web/API/Server-sent%5Fevents/Using%5Fserver-sent%5Fevents) (SSE).&para;<br>&para;<br>## Streaming with SDKs&para;<br>&para;<br>The [Python](https://github.com/anthropics/anthropic-sdk-python) and [TypeScript](https://github.com/anthropics/anthropic-sdk-typescript) SDKs offer multiple ways of streaming. The Python SDK allows both sync and async streams. See the documentation in each SDK for details.&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>    ```python Python&para;<br>    import anthropic&para;<br>&para;<br>    client = anthropic.Anthropic()&para;<br>&para;<br>    with client.messages.stream(&para;<br>        max_tokens=1024,&para;<br>        messages=[{"role": "user", "content": "Hello"}],&para;<br>        model="claude-opus-4-6",&para;<br>    ) as stream:&para;<br>        for text in stream.text_stream:&para;<br>            print(text, end="", flush=True)&para;<br>    ```&para;<br>&para;<br>    ```typescript TypeScript&para;<br>    import Anthropic from "@anthropic-ai/sdk";&para;<br>&para;<br>    const client = new Anthropic();&para;<br>&para;<br>    await client.messages</span><ins style="background:#e6ffe6;">&para;<br>      </ins><span>.stream({&para;<br></span><ins style="background:#e6ffe6;">  </ins><span>      messages: [{ role: "user", content: "Hello" }],&para;<br>      </span><ins style="background:#e6ffe6;">  </ins><span>model: "claude-opus-4-6",&para;<br></span><ins style="background:#e6ffe6;">  </ins><span>      max_tokens: 1024&para;<br>    </span><del style="background:#ffe6e6;">})</del><ins style="background:#e6ffe6;">  })&para;<br>      </ins><span>.on("text", (text) =&gt; {&para;<br>      </span><ins style="background:#e6ffe6;">  </ins><span>console.log(text);&para;<br></span><ins style="background:#e6ffe6;">  </ins><span>    });&para;<br>    ```&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>## Get the final message without handling events&para;<br>&para;<br>If you don't need to process text as it arrives, the SDKs provide a way to use streaming under the hood while returning the complete `Message` object, identical to what `.create()` returns. This is especially useful for requests with large `max_tokens` values, where the SDKs require streaming to avoid HTTP timeouts.&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>    ```python Python&para;<br>    import anthropic&para;<br>&para;<br>    client = anthropic.Anthropic()&para;<br>&para;<br>    with client.messages.stream(&para;<br>        max_tokens=128000,&para;<br>        messages=[{"role": "user", "content": "Write a detailed analysis..."}],&para;<br>        model="claude-opus-4-6",&para;<br>    ) as stream:&para;<br>        message = stream.get_final_message()&para;<br>&para;<br>    print(message.content[0].text)&para;<br>    ```&para;<br>&para;<br>    ```typescript TypeScript&para;<br>    import Anthropic from "@anthropic-ai/sdk";&para;<br>&para;<br>    const client = new Anthropic();&para;<br>&para;<br>    const stream = client.messages.stream({&para;<br>      max_tokens: 128000,&para;<br>      messages: [{ role: "user", content: "Write a detailed analysis..." }],&para;<br>      model: "claude-opus-4-6"&para;<br>    });&para;<br>&para;<br>    const message = await stream.finalMessage();&para;<br>    console.log(message.content[0].text);&para;<br>    ```&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>The `.stream()` call keeps the HTTP connection alive with server-sent events, then `.get_final_message()` (Python) or `.finalMessage()` (TypeScript) accumulates all events and returns the complete `Message` object. No event handling code is needed.&para;<br>&para;<br>## Event types&para;<br>&para;<br>Each server-sent event includes a named event type and associated JSON data. Each event will use an SSE event name (e.g. `event: message_stop`), and include the matching event `type` in its data.&para;<br>&para;<br>Each stream uses the following event flow:&para;<br>&para;<br>1. `message_start`: contains a `Message` object with empty `content`.&para;<br>2. A series of content blocks, each of which have a `content_block_start`, one or more `content_block_delta` events, and a `content_block_stop` event. Each content block will have an `index` that corresponds to its index in the final Message `content` array.&para;<br>3. One or more `message_delta` events, indicating top-level changes to the final `Message` object.&para;<br>4. A final `message_stop` event.&para;<br>&para;<br>  &lt;Warning&gt;&para;<br>  The token counts shown in the `usage` field of the `message_delta` event are *cumulative*.&para;<br>  &lt;/Warning&gt;&para;<br>&para;<br>### Ping events&para;<br>&para;<br>Event streams may also include any number of `ping` events.&para;<br>&para;<br>### Error events&para;<br>&para;<br>The API may occasionally send [errors](/docs/en/api/errors) in the event stream. For example, during periods of high usage, you may receive an `overloaded_error`, which would normally correspond to an HTTP 529 in a non-streaming context:&para;<br>&para;<br>```</span><del style="background:#ffe6e6;">json</del><ins style="background:#e6ffe6;">sse</ins><span> Example error&para;<br>event: error&para;<br>data: {"type": "error", "error": {"type": "overloaded_error", "message": "Overloaded"}}&para;<br>```&para;<br>&para;<br>### Other events&para;<br>&para;<br>In accordance with the [versioning policy](/docs/en/api/versioning), new event types may be added, and your code should handle unknown event types gracefully.&para;<br>&para;<br>## Content block delta types&para;<br>&para;<br>Each `content_block_delta` event contains a `delta` of a type that updates the `content` block at a given `index`.&para;<br>&para;<br>### Text delta&para;<br>&para;<br>A `text` content block delta looks like:&para;<br>```</span><del style="background:#ffe6e6;">json</del><ins style="background:#e6ffe6;">sse</ins><span> Text delta&para;<br>event: content_block_delta&para;<br>data: {"type": "content_block_delta","index": 0,"delta": {"type": "text_delta", "text": "ello frien"}}&para;<br>```&para;<br>&para;<br>### Input JSON delta&para;<br>&para;<br>The deltas for `tool_use` content blocks correspond to updates for the `input` field of the block. To support maximum granularity, the deltas are _partial JSON strings_, whereas the final `tool_use.input` is always an _object_.&para;<br>&para;<br>You can accumulate the string deltas and parse the JSON once you receive a `content_block_stop` event, by using a library like [Pydantic](https://docs.pydantic.dev/latest/concepts/json/#partial-json-parsing) to do partial JSON parsing, or by using the [SDKs](/docs/en/api/client-sdks), which provide helpers to access parsed incremental values.&para;<br>&para;<br>A `tool_use` content block delta looks like:&para;<br>```</span><del style="background:#ffe6e6;">json</del><ins style="background:#e6ffe6;">sse</ins><span> Input JSON delta&para;<br>event: content_block_delta&para;<br>data: {"type": "content_block_delta","index": 1,"delta": {"type": "input_json_delta","partial_json": "{\"location\": \"San Fra"}}}&para;<br>```&para;<br>Note: Current models only support emitting one complete key and value property from `input` at a time. As such, when using tools, there may be delays between streaming events while the model is working. Once an `input` key and value are accumulated, they are emitted as multiple `content_block_delta` events with chunked partial json so that the format can automatically support finer granularity in future models.&para;<br>&para;<br>### Thinking delta&para;<br>&para;<br>When using [extended thinking](/docs/en/build-with-claude/extended-thinking#streaming-thinking) with streaming enabled, you'll receive thinking content via `thinking_delta` events. These deltas correspond to the `thinking` field of the `thinking` content blocks.&para;<br>&para;<br>For thinking content, a special `signature_delta` event is sent just before the `content_block_stop` event. This signature is used to verify the integrity of the thinking block.&para;<br>&para;<br>A typical thinking delta looks like:&para;<br>```</span><del style="background:#ffe6e6;">json</del><ins style="background:#e6ffe6;">sse</ins><span> Thinking delta&para;<br>event: content_block_delta&para;<br>data: {"type": "content_block_delta", "index": 0, "delta": {"type": "thinking_delta", "thinking": "I need to find the GCD of 1071 and 462 using the Euclidean algorithm.\n\n1071 = 2 × 462 + 147"}}&para;<br>```&para;<br>&para;<br>The signature delta looks like:&para;<br>```</span><del style="background:#ffe6e6;">json</del><ins style="background:#e6ffe6;">sse</ins><span> Signature delta&para;<br>event: content_block_delta&para;<br>data: {"type": "content_block_delta", "index": 0, "delta": {"type": "signature_delta", "signature": "EqQBCgIYAhIM1gbcDa9GJwZA2b3hGgxBdjrkzLoky3dl1pkiMOYds..."}}&para;<br>```&para;<br>&para;<br>## Full HTTP Stream response&para;<br>&para;<br>Use the [client SDKs](/docs/en/api/client-sdks) when using streaming mode. However, if you are building a direct API integration, you will need to handle these events yourself.&para;<br>&para;<br>A stream response is comprised of:&para;<br>1. A `message_start` event&para;<br>2. Potentially multiple content blocks, each of which contains:&para;<br>    - A `content_block_start` event&para;<br>    - Potentially multiple `content_block_delta` events&para;<br>    - A `content_block_stop` event&para;<br>3. A `message_delta` event&para;<br>4. A `message_stop` event&para;<br>&para;<br>There may be `ping` events dispersed throughout the response as well. See [Event types](#event-types) for more details on the format.&para;<br>&para;<br>### Basic streaming request&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>```bash Shell&para;<br>curl https://api.anthropic.com/v1/messages \&para;<br>     --header "anthropic-version: 2023-06-01" \&para;<br>     --header "content-type: application/json" \&para;<br>     --header "x-api-key: $ANTHROPIC_API_KEY" \&para;<br>     --data \&para;<br>'{&para;<br>  "model": "claude-opus-4-6",&para;<br>  "messages": [{"role": "user", "content": "Hello"}],&para;<br>  "max_tokens": 256,&para;<br>  "stream": true&para;<br>}'&para;<br>```&para;<br>&para;<br>```python Python&para;<br>import anthropic&para;<br>&para;<br>client = anthropic.Anthropic()&para;<br>&para;<br>with client.messages.stream(&para;<br>    model="claude-opus-4-6",&para;<br>    messages=[{"role": "user", "content": "Hello"}],&para;<br>    max_tokens=256,&para;<br>) as stream:&para;<br>    for text in stream.text_stream:&para;<br>        print(text, end="", flush=True)&para;<br>```&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>```</span><del style="background:#ffe6e6;">json</del><ins style="background:#e6ffe6;">sse</ins><span> Response&para;<br>event: message_start&para;<br>data: {"type": "message_start", "message": {"id": "msg_1nZdL29xx5MUA1yADyHTEsnR8uuvGzszyY", "type": "message", "role": "assistant", "content": [], "model": "claude-opus-4-6", "stop_reason": null, "stop_sequence": null, "usage": {"input_tokens": 25, "output_tokens": 1}}}&para;<br>&para;<br>event: content_block_start&para;<br>data: {"type": "content_block_start", "index": 0, "content_block": {"type": "text", "text": ""}}&para;<br>&para;<br>event: ping&para;<br>data: {"type": "ping"}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type": "content_block_delta", "index": 0, "delta": {"type": "text_delta", "text": "Hello"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type": "content_block_delta", "index": 0, "delta": {"type": "text_delta", "text": "!"}}&para;<br>&para;<br>event: content_block_stop&para;<br>data: {"type": "content_block_stop", "index": 0}&para;<br>&para;<br>event: message_delta&para;<br>data: {"type": "message_delta", "delta": {"stop_reason": "end_turn", "stop_sequence":null}, "usage": {"output_tokens": 15}}&para;<br>&para;<br>event: message_stop&para;<br>data: {"type": "message_stop"}&para;<br>&para;<br>```&para;<br>&para;<br>### Streaming request with tool use&para;<br>&para;<br>&lt;Tip&gt;&para;<br>Tool use supports [fine-grained streaming](/docs/en/agents-and-tools/tool-use/fine-grained-tool-streaming) for parameter values. Enable it per tool with `eager_input_streaming`.&para;<br>&lt;/Tip&gt;&para;<br>&para;<br>This request asks Claude to use a tool to report the weather.&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>```bash Shell&para;<br>  curl https://api.anthropic.com/v1/messages \&para;<br>    -H "content-type: application/json" \&para;<br>    -H "x-api-key: $ANTHROPIC_API_KEY" \&para;<br>    -H "anthropic-version: 2023-06-01" \&para;<br>    -d '{&para;<br>      "model": "claude-opus-4-6",&para;<br>      "max_tokens": 1024,&para;<br>      "tools": [&para;<br>        {&para;<br>          "name": "get_weather",&para;<br>          "description": "Get the current weather in a given location",&para;<br>          "input_schema": {&para;<br>            "type": "object",&para;<br>            "properties": {&para;<br>              "location": {&para;<br>                "type": "string",&para;<br>                "description": "The city and state, e.g. San Francisco, CA"&para;<br>              }&para;<br>            },&para;<br>            "required": ["location"]&para;<br>          }&para;<br>        }&para;<br>      ],&para;<br>      "tool_choice": {"type": "any"},&para;<br>      "messages": [&para;<br>        {&para;<br>          "role": "user",&para;<br>          "content": "What is the weather like in San Francisco?"&para;<br>        }&para;<br>      ],&para;<br>      "stream": true&para;<br>    }'&para;<br>```&para;<br>&para;<br>```python Python&para;<br>import anthropic&para;<br>&para;<br>client = anthropic.Anthropic()&para;<br>&para;<br>tools = [&para;<br>    {&para;<br>        "name": "get_weather",&para;<br>        "description": "Get the current weather in a given location",&para;<br>        "input_schema": {&para;<br>            "type": "object",&para;<br>            "properties": {&para;<br>                "location": {&para;<br>                    "type": "string",&para;<br>                    "description": "The city and state, e.g. San Francisco, CA",&para;<br>                }&para;<br>            },&para;<br>            "required": ["location"],&para;<br>        },&para;<br>    }&para;<br>]&para;<br>&para;<br>with client.messages.stream(&para;<br>    model="claude-opus-4-6",&para;<br>    max_tokens=1024,&para;<br>    tools=tools,&para;<br>    tool_choice={"type": "any"},&para;<br>    messages=[&para;<br>        {"role": "user", "content": "What is the weather like in San Francisco?"}&para;<br>    ],&para;<br>) as stream:&para;<br>    for text in stream.text_stream:&para;<br>        print(text, end="", flush=True)&para;<br>```&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>```</span><del style="background:#ffe6e6;">json</del><ins style="background:#e6ffe6;">sse</ins><span> Response&para;<br>event: message_start&para;<br>data: {"type":"message_start","message":{"id":"msg_014p7gG3wDgGV9EUtLvnow3U","type":"message","role":"assistant","model":"claude-opus-4-6","stop_sequence":null,"usage":{"input_tokens":472,"output_tokens":2},"content":[],"stop_reason":null}}&para;<br>&para;<br>event: content_block_start&para;<br>data: {"type":"content_block_start","index":0,"content_block":{"type":"text","text":""}}&para;<br>&para;<br>event: ping&para;<br>data: {"type": "ping"}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":"Okay"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":","}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":" let"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":"'s"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":" check"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":" the"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":" weather"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":" for"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":" San"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":" Francisco"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":","}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":" CA"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":":"}}&para;<br>&para;<br>event: content_block_stop&para;<br>data: {"type":"content_block_stop","index":0}&para;<br>&para;<br>event: content_block_start&para;<br>data: {"type":"content_block_start","index":1,"content_block":{"type":"tool_use","id":"toolu_01T1x1fJ34qAmk2tNTrN7Up6","name":"get_weather","input":{}}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":""}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":"{\"location\":"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":" \"San"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":" Francisc"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":"o,"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":" CA\""}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":", "}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":"\"unit\": \"fah"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":"renheit\"}"}}&para;<br>&para;<br>event: content_block_stop&para;<br>data: {"type":"content_block_stop","index":1}&para;<br>&para;<br>event: message_delta&para;<br>data: {"type":"message_delta","delta":{"stop_reason":"tool_use","stop_sequence":null},"usage":{"output_tokens":89}}&para;<br>&para;<br>event: message_stop&para;<br>data: {"type":"message_stop"}&para;<br>```&para;<br>&para;<br>### Streaming request with extended thinking&para;<br>&para;<br>This request enables extended thinking with streaming to see Claude's step-by-step reasoning.&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>```bash Shell&para;<br>curl https://api.anthropic.com/v1/messages \&para;<br>     --header "x-api-key: $ANTHROPIC_API_KEY" \&para;<br>     --header "anthropic-version: 2023-06-01" \&para;<br>     --header "content-type: application/json" \&para;<br>     --data \&para;<br>'{&para;<br>    "model": "claude-opus-4-6",&para;<br>    "max_tokens": 20000,&para;<br>    "stream": true,&para;<br>    "thinking": {&para;<br>        "type": "enabled",&para;<br>        "budget_tokens": 16000&para;<br>    },&para;<br>    "messages": [&para;<br>        {&para;<br>            "role": "user",&para;<br>            "content": "What is the greatest common divisor of 1071 and 462?"&para;<br>        }&para;<br>    ]&para;<br>}'&para;<br>```&para;<br>&para;<br>```python Python&para;<br>import anthropic&para;<br>&para;<br>client = anthropic.Anthropic()&para;<br>&para;<br>with client.messages.stream(&para;<br>    model="claude-opus-4-6",&para;<br>    max_tokens=20000,&para;<br>    thinking={"type": "enabled", "budget_tokens": 16000},&para;<br>    messages=[&para;<br>        {&para;<br>            "role": "user",&para;<br>            "content": "What is the greatest common divisor of 1071 and 462?",&para;<br>        }&para;<br>    ],&para;<br>) as stream:&para;<br>    for event in stream:&para;<br>        if event.type == "content_block_delta":&para;<br>            if event.delta.type == "thinking_delta":&para;<br>                print(event.delta.thinking, end="", flush=True)&para;<br>            elif event.delta.type == "text_delta":&para;<br>                print(event.delta.text, end="", flush=True)&para;<br>```&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>```</span><del style="background:#ffe6e6;">json</del><ins style="background:#e6ffe6;">sse</ins><span> Response&para;<br>event: message_start&para;<br>data: {"type": "message_start", "message": {"id": "msg_01...", "type": "message", "role": "assistant", "content": [], "model": "claude-opus-4-6", "stop_reason": null, "stop_sequence": null}}&para;<br>&para;<br>event: content_block_start&para;<br>data: {"type": "content_block_start", "index": 0, "content_block": {"type": "thinking", "thinking": ""}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type": "content_block_delta", "index": 0, "delta": {"type": "thinking_delta", "thinking": "I need to find the GCD of 1071 and 462 using the Euclidean algorithm.\n\n1071 = 2 × 462 + 147"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type": "content_block_delta", "index": 0, "delta": {"type": "thinking_delta", "thinking": "\n462 = 3 × 147 + 21"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type": "content_block_delta", "index": 0, "delta": {"type": "thinking_delta", "thinking": "\n147 = 7 × 21 + 0"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type": "content_block_delta", "index": 0, "delta": {"type": "thinking_delta", "thinking": "\nThe remainder is 0, so GCD(1071, 462) = 21."}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type": "content_block_delta", "index": 0, "delta": {"type": "signature_delta", "signature": "EqQBCgIYAhIM1gbcDa9GJwZA2b3hGgxBdjrkzLoky3dl1pkiMOYds..."}}&para;<br>&para;<br>event: content_block_stop&para;<br>data: {"type": "content_block_stop", "index": 0}&para;<br>&para;<br>event: content_block_start&para;<br>data: {"type": "content_block_start", "index": 1, "content_block": {"type": "text", "text": ""}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type": "content_block_delta", "index": 1, "delta": {"type": "text_delta", "text": "The greatest common divisor of 1071 and 462 is **21**."}}&para;<br>&para;<br>event: content_block_stop&para;<br>data: {"type": "content_block_stop", "index": 1}&para;<br>&para;<br>event: message_delta&para;<br>data: {"type": "message_delta", "delta": {"stop_reason": "end_turn", "stop_sequence": null}}&para;<br>&para;<br>event: message_stop&para;<br>data: {"type": "message_stop"}&para;<br>```&para;<br>&para;<br>### Streaming request with web search tool use&para;<br>&para;<br>This request asks Claude to search the web for current weather information.&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>```bash Shell&para;<br>curl https://api.anthropic.com/v1/messages \&para;<br>     --header "x-api-key: $ANTHROPIC_API_KEY" \&para;<br>     --header "anthropic-version: 2023-06-01" \&para;<br>     --header "content-type: application/json" \&para;<br>     --data \&para;<br>'{&para;<br>    "model": "claude-opus-4-6",&para;<br>    "max_tokens": 1024,&para;<br>    "stream": true,&para;<br>    "tools": [&para;<br>        {&para;<br>            "type": "web_search_20250305",&para;<br>            "name": "web_search",&para;<br>            "max_uses": 5&para;<br>        }&para;<br>    ],&para;<br>    "messages": [&para;<br>        {&para;<br>            "role": "user",&para;<br>            "content": "What is the weather like in New York City today?"&para;<br>        }&para;<br>    ]&para;<br>}'&para;<br>```&para;<br>&para;<br>```python Python&para;<br>import anthropic&para;<br>&para;<br>client = anthropic.Anthropic()&para;<br>&para;<br>with client.messages.stream(&para;<br>    model="claude-opus-4-6",&para;<br>    max_tokens=1024,&para;<br>    tools=[{"type": "web_search_20250305", "name": "web_search", "max_uses": 5}],&para;<br>    messages=[&para;<br>        {"role": "user", "content": "What is the weather like in New York City today?"}&para;<br>    ],&para;<br>) as stream:&para;<br>    for text in stream.text_stream:&para;<br>        print(text, end="", flush=True)&para;<br>```</span><ins style="background:#e6ffe6;">&para;<br>&para;<br>```java Java&para;<br>import com.anthropic.client.AnthropicClient;&para;<br>import com.anthropic.client.okhttp.AnthropicOkHttpClient;&para;<br>import com.anthropic.models.messages.MessageCreateParams;&para;<br>import com.anthropic.models.messages.Model;&para;<br>import com.anthropic.models.messages.WebSearchTool20250305;&para;<br>&para;<br>public class WebSearchStreaming {&para;<br>    public static void main(String[] args) {&para;<br>        AnthropicClient client = AnthropicOkHttpClient.fromEnv();&para;<br>&para;<br>        MessageCreateParams params = MessageCreateParams.builder()&para;<br>            .model(Model.CLAUDE_OPUS_4_6)&para;<br>            .maxTokens(1024L)&para;<br>            .addTool(WebSearchTool20250305.builder()&para;<br>                .maxUses(5L)&para;<br>                .build())&para;<br>            .addUserMessage("What is the weather like in New York City today?")&para;<br>            .build();&para;<br>&para;<br>        try (var streamResponse = client.messages().createStreaming(params)) {&para;<br>            streamResponse.stream().forEach(event -&gt; {&para;<br>                event.contentBlockDelta().ifPresent(deltaEvent -&gt;&para;<br>                    deltaEvent.delta().text().ifPresent(td -&gt;&para;<br>                        System.out.print(td.text())&para;<br>                    )&para;<br>                );&para;<br>            });&para;<br>        }&para;<br>    }&para;<br>}&para;<br>```&para;<br>&para;<br>```go Go&para;<br>package main&para;<br>&para;<br>import (&para;<br>	"context"&para;<br>	"fmt"&para;<br>	"log"&para;<br>&para;<br>	"github.com/anthropics/anthropic-sdk-go"&para;<br>)&para;<br>&para;<br>func main() {&para;<br>	client := anthropic.NewClient()&para;<br>&para;<br>	stream := client.Messages.NewStreaming(context.TODO(), anthropic.MessageNewParams{&para;<br>		Model:     anthropic.ModelClaudeOpus4_6,&para;<br>		MaxTokens: 1024,&para;<br>		Tools: []anthropic.ToolParam{&para;<br>			anthropic.NewWebSearchTool(anthropic.WebSearchToolParam{&para;<br>				Type:    anthropic.F(anthropic.ToolTypeWebSearch20250305),&para;<br>				Name:    anthropic.F("web_search"),&para;<br>				MaxUses: anthropic.Int(5),&para;<br>			}),&para;<br>		},&para;<br>		Messages: []anthropic.MessageParam{&para;<br>			anthropic.NewUserMessage(anthropic.NewTextBlock("What is the weather like in New York City today?")),&para;<br>		},&para;<br>	})&para;<br>&para;<br>	for stream.Next() {&para;<br>		event := stream.Current()&para;<br>		switch eventVariant := event.AsAny().(type) {&para;<br>		case anthropic.ContentBlockDeltaEvent:&para;<br>			switch deltaVariant := eventVariant.Delta.AsAny().(type) {&para;<br>			case anthropic.TextDelta:&para;<br>				fmt.Print(deltaVariant.Text)&para;<br>			}&para;<br>		}&para;<br>	}&para;<br>	if err := stream.Err(); err != nil {&para;<br>		log.Fatal(err)&para;<br>	}&para;<br>}&para;<br>```&para;<br>&para;<br>```ruby Ruby&para;<br>require "anthropic"&para;<br>&para;<br>client = Anthropic::Client.new&para;<br>&para;<br>stream = client.messages.stream(&para;<br>  model: :"claude-opus-4-6",&para;<br>  max_tokens: 1024,&para;<br>  tools: [&para;<br>    {&para;<br>      type: "web_search_20250305",&para;<br>      name: "web_search",&para;<br>      max_uses: 5&para;<br>    }&para;<br>  ],&para;<br>  messages: [&para;<br>    {&para;<br>      role: "user",&para;<br>      content: "What is the weather like in New York City today?"&para;<br>    }&para;<br>  ]&para;<br>)&para;<br>&para;<br>stream.text.each { |text| print(text) }&para;<br>```</ins><span>&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>```</span><del style="background:#ffe6e6;">json</del><ins style="background:#e6ffe6;">sse</ins><span> Response&para;<br>event: message_start&para;<br>data: {"type":"message_start","message":{"id":"msg_01G...","type":"message","role":"assistant","model":"claude-opus-4-6","content":[],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2679,"cache_creation_input_tokens":0,"cache_read_input_tokens":0,"output_tokens":3}}}&para;<br>&para;<br>event: content_block_start&para;<br>data: {"type":"content_block_start","index":0,"content_block":{"type":"text","text":""}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":"I'll check"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":" the current weather in New York City for you"}}&para;<br>&para;<br>event: ping&para;<br>data: {"type": "ping"}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":"."}}&para;<br>&para;<br>event: content_block_stop&para;<br>data: {"type":"content_block_stop","index":0}&para;<br>&para;<br>event: content_block_start&para;<br>data: {"type":"content_block_start","index":1,"content_block":{"type":"server_tool_use","id":"srvtoolu_014hJH82Qum7Td6UV8gDXThB","name":"web_search","input":{}}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":""}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":"{\"query"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":"\":"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":" \"weather"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":" NY"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":"C to"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":"day\"}"}}&para;<br>&para;<br>event: content_block_stop&para;<br>data: {"type":"content_block_stop","index":1 }&para;<br>&para;<br>event: content_block_start&para;<br>data: {"type":"content_block_start","index":2,"content_block":{"type":"web_search_tool_result","tool_use_id":"srvtoolu_014hJH82Qum7Td6UV8gDXThB","content":[{"type":"web_search_result","title":"Weather in New York City in May 2025 (New York) - detailed Weather Forecast for a month","url":"https://world-weather.info/forecast/usa/new_york/may-2025/","encrypted_content":"Ev0DCioIAxgCIiQ3NmU4ZmI4OC1k...","page_age":null},...]}}&para;<br>&para;<br>event: content_block_stop&para;<br>data: {"type":"content_block_stop","index":2}&para;<br>&para;<br>event: content_block_start&para;<br>data: {"type":"content_block_start","index":3,"content_block":{"type":"text","text":""}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":3,"delta":{"type":"text_delta","text":"Here's the current weather information for New York"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":3,"delta":{"type":"text_delta","text":" City:\n\n# Weather"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":3,"delta":{"type":"text_delta","text":" in New York City"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":3,"delta":{"type":"text_delta","text":"\n\n"}}&para;<br>&para;<br>...&para;<br>&para;<br>event: content_block_stop&para;<br>data: {"type":"content_block_stop","index":17}&para;<br>&para;<br>event: message_delta&para;<br>data: {"type":"message_delta","delta":{"stop_reason":"end_turn","stop_sequence":null},"usage":{"input_tokens":10682,"cache_creation_input_tokens":0,"cache_read_input_tokens":0,"output_tokens":510,"server_tool_use":{"web_search_requests":1}}}&para;<br>&para;<br>event: message_stop&para;<br>data: {"type":"message_stop"}&para;<br>```&para;<br>&para;<br>## Error recovery&para;<br>&para;<br>### Claude 4.5 and earlier&para;<br>&para;<br>For Claude 4.5 models and earlier, you can recover a streaming request that was interrupted due to network issues, timeouts, or other errors by resuming from where the stream was interrupted. This approach saves you from re-processing the entire response.&para;<br>&para;<br>The basic recovery strategy involves:&para;<br>&para;<br>1. **Capture the partial response**: Save all content that was successfully received before the error occurred&para;<br>2. **Construct a continuation request**: Create a new API request that includes the partial assistant response as the beginning of a new assistant message&para;<br>3. **Resume streaming**: Continue receiving the rest of the response from where it was interrupted&para;<br>&para;<br>### Claude 4.6&para;<br>&para;<br>For Claude 4.6 models, you should add a user message that instructs the model to continue from where it left off. For example:&para;<br></span><ins style="background:#e6ffe6;">&para;<br></ins><span>```text Sample prompt&para;<br>Your previous response was interrupted and ended with [previous_response]. Continue from where you left off.&para;<br>```&para;<br>&para;<br>### Error recovery best practices&para;<br>&para;<br>1. **Use SDK features**: Leverage the SDK's built-in message accumulation and error handling capabilities&para;<br>2. **Handle content types**: Be aware that messages can contain multiple content blocks (`text`, `tool_use`, `thinking`). Tool use and extended thinking blocks cannot be partially recovered. You can resume streaming from the most recent text block.</span></div>
        </div>

        <h2 style="margin-top: 2rem; margin-bottom: 1rem;">Unified Diff</h2>
        <pre><code>--- a/build-with-claude/streaming.md
+++ b/build-with-claude/streaming.md
@@ -28,13 +28,15 @@
 
     const client = new Anthropic();
 
-    await client.messages.stream({
-      messages: [{ role: &#34;user&#34;, content: &#34;Hello&#34; }],
-      model: &#34;claude-opus-4-6&#34;,
-      max_tokens: 1024
-    }).on(&#34;text&#34;, (text) =&gt; {
-      console.log(text);
-    });
+    await client.messages
+      .stream({
+        messages: [{ role: &#34;user&#34;, content: &#34;Hello&#34; }],
+        model: &#34;claude-opus-4-6&#34;,
+        max_tokens: 1024
+      })
+      .on(&#34;text&#34;, (text) =&gt; {
+        console.log(text);
+      });
     ```
 &lt;/CodeGroup&gt;
 
@@ -99,7 +101,7 @@
 
 The API may occasionally send [errors](/docs/en/api/errors) in the event stream. For example, during periods of high usage, you may receive an `overloaded_error`, which would normally correspond to an HTTP 529 in a non-streaming context:
 
-```json Example error
+```sse Example error
 event: error
 data: {&#34;type&#34;: &#34;error&#34;, &#34;error&#34;: {&#34;type&#34;: &#34;overloaded_error&#34;, &#34;message&#34;: &#34;Overloaded&#34;}}
 ```
@@ -115,7 +117,7 @@
 ### Text delta
 
 A `text` content block delta looks like:
-```json Text delta
+```sse Text delta
 event: content_block_delta
 data: {&#34;type&#34;: &#34;content_block_delta&#34;,&#34;index&#34;: 0,&#34;delta&#34;: {&#34;type&#34;: &#34;text_delta&#34;, &#34;text&#34;: &#34;ello frien&#34;}}
 ```
@@ -127,7 +129,7 @@
 You can accumulate the string deltas and parse the JSON once you receive a `content_block_stop` event, by using a library like [Pydantic](https://docs.pydantic.dev/latest/concepts/json/#partial-json-parsing) to do partial JSON parsing, or by using the [SDKs](/docs/en/api/client-sdks), which provide helpers to access parsed incremental values.
 
 A `tool_use` content block delta looks like:
-```json Input JSON delta
+```sse Input JSON delta
 event: content_block_delta
 data: {&#34;type&#34;: &#34;content_block_delta&#34;,&#34;index&#34;: 1,&#34;delta&#34;: {&#34;type&#34;: &#34;input_json_delta&#34;,&#34;partial_json&#34;: &#34;{\&#34;location\&#34;: \&#34;San Fra&#34;}}}
 ```
@@ -140,13 +142,13 @@
 For thinking content, a special `signature_delta` event is sent just before the `content_block_stop` event. This signature is used to verify the integrity of the thinking block.
 
 A typical thinking delta looks like:
-```json Thinking delta
+```sse Thinking delta
 event: content_block_delta
 data: {&#34;type&#34;: &#34;content_block_delta&#34;, &#34;index&#34;: 0, &#34;delta&#34;: {&#34;type&#34;: &#34;thinking_delta&#34;, &#34;thinking&#34;: &#34;I need to find the GCD of 1071 and 462 using the Euclidean algorithm.\n\n1071 = 2 × 462 + 147&#34;}}
 ```
 
 The signature delta looks like:
-```json Signature delta
+```sse Signature delta
 event: content_block_delta
 data: {&#34;type&#34;: &#34;content_block_delta&#34;, &#34;index&#34;: 0, &#34;delta&#34;: {&#34;type&#34;: &#34;signature_delta&#34;, &#34;signature&#34;: &#34;EqQBCgIYAhIM1gbcDa9GJwZA2b3hGgxBdjrkzLoky3dl1pkiMOYds...&#34;}}
 ```
@@ -198,7 +200,7 @@
 ```
 &lt;/CodeGroup&gt;
 
-```json Response
+```sse Response
 event: message_start
 data: {&#34;type&#34;: &#34;message_start&#34;, &#34;message&#34;: {&#34;id&#34;: &#34;msg_1nZdL29xx5MUA1yADyHTEsnR8uuvGzszyY&#34;, &#34;type&#34;: &#34;message&#34;, &#34;role&#34;: &#34;assistant&#34;, &#34;content&#34;: [], &#34;model&#34;: &#34;claude-opus-4-6&#34;, &#34;stop_reason&#34;: null, &#34;stop_sequence&#34;: null, &#34;usage&#34;: {&#34;input_tokens&#34;: 25, &#34;output_tokens&#34;: 1}}}
 
@@ -305,7 +307,7 @@
 ```
 &lt;/CodeGroup&gt;
 
-```json Response
+```sse Response
 event: message_start
 data: {&#34;type&#34;:&#34;message_start&#34;,&#34;message&#34;:{&#34;id&#34;:&#34;msg_014p7gG3wDgGV9EUtLvnow3U&#34;,&#34;type&#34;:&#34;message&#34;,&#34;role&#34;:&#34;assistant&#34;,&#34;model&#34;:&#34;claude-opus-4-6&#34;,&#34;stop_sequence&#34;:null,&#34;usage&#34;:{&#34;input_tokens&#34;:472,&#34;output_tokens&#34;:2},&#34;content&#34;:[],&#34;stop_reason&#34;:null}}
 
@@ -450,7 +452,7 @@
 ```
 &lt;/CodeGroup&gt;
 
-```json Response
+```sse Response
 event: message_start
 data: {&#34;type&#34;: &#34;message_start&#34;, &#34;message&#34;: {&#34;id&#34;: &#34;msg_01...&#34;, &#34;type&#34;: &#34;message&#34;, &#34;role&#34;: &#34;assistant&#34;, &#34;content&#34;: [], &#34;model&#34;: &#34;claude-opus-4-6&#34;, &#34;stop_reason&#34;: null, &#34;stop_sequence&#34;: null}}
 
@@ -538,9 +540,113 @@
     for text in stream.text_stream:
         print(text, end=&#34;&#34;, flush=True)
 ```
+
+```java Java
+import com.anthropic.client.AnthropicClient;
+import com.anthropic.client.okhttp.AnthropicOkHttpClient;
+import com.anthropic.models.messages.MessageCreateParams;
+import com.anthropic.models.messages.Model;
+import com.anthropic.models.messages.WebSearchTool20250305;
+
+public class WebSearchStreaming {
+    public static void main(String[] args) {
+        AnthropicClient client = AnthropicOkHttpClient.fromEnv();
+
+        MessageCreateParams params = MessageCreateParams.builder()
+            .model(Model.CLAUDE_OPUS_4_6)
+            .maxTokens(1024L)
+            .addTool(WebSearchTool20250305.builder()
+                .maxUses(5L)
+                .build())
+            .addUserMessage(&#34;What is the weather like in New York City today?&#34;)
+            .build();
+
+        try (var streamResponse = client.messages().createStreaming(params)) {
+            streamResponse.stream().forEach(event -&gt; {
+                event.contentBlockDelta().ifPresent(deltaEvent -&gt;
+                    deltaEvent.delta().text().ifPresent(td -&gt;
+                        System.out.print(td.text())
+                    )
+                );
+            });
+        }
+    }
+}
+```
+
+```go Go
+package main
+
+import (
+	&#34;context&#34;
+	&#34;fmt&#34;
+	&#34;log&#34;
+
+	&#34;github.com/anthropics/anthropic-sdk-go&#34;
+)
+
+func main() {
+	client := anthropic.NewClient()
+
+	stream := client.Messages.NewStreaming(context.TODO(), anthropic.MessageNewParams{
+		Model:     anthropic.ModelClaudeOpus4_6,
+		MaxTokens: 1024,
+		Tools: []anthropic.ToolParam{
+			anthropic.NewWebSearchTool(anthropic.WebSearchToolParam{
+				Type:    anthropic.F(anthropic.ToolTypeWebSearch20250305),
+				Name:    anthropic.F(&#34;web_search&#34;),
+				MaxUses: anthropic.Int(5),
+			}),
+		},
+		Messages: []anthropic.MessageParam{
+			anthropic.NewUserMessage(anthropic.NewTextBlock(&#34;What is the weather like in New York City today?&#34;)),
+		},
+	})
+
+	for stream.Next() {
+		event := stream.Current()
+		switch eventVariant := event.AsAny().(type) {
+		case anthropic.ContentBlockDeltaEvent:
+			switch deltaVariant := eventVariant.Delta.AsAny().(type) {
+			case anthropic.TextDelta:
+				fmt.Print(deltaVariant.Text)
+			}
+		}
+	}
+	if err := stream.Err(); err != nil {
+		log.Fatal(err)
+	}
+}
+```
+
+```ruby Ruby
+require &#34;anthropic&#34;
+
+client = Anthropic::Client.new
+
+stream = client.messages.stream(
+  model: :&#34;claude-opus-4-6&#34;,
+  max_tokens: 1024,
+  tools: [
+    {
+      type: &#34;web_search_20250305&#34;,
+      name: &#34;web_search&#34;,
+      max_uses: 5
+    }
+  ],
+  messages: [
+    {
+      role: &#34;user&#34;,
+      content: &#34;What is the weather like in New York City today?&#34;
+    }
+  ]
+)
+
+stream.text.each { |text| print(text) }
+```
 &lt;/CodeGroup&gt;
 
-```json Response
+```sse Response
 event: message_start
 data: {&#34;type&#34;:&#34;message_start&#34;,&#34;message&#34;:{&#34;id&#34;:&#34;msg_01G...&#34;,&#34;type&#34;:&#34;message&#34;,&#34;role&#34;:&#34;assistant&#34;,&#34;model&#34;:&#34;claude-opus-4-6&#34;,&#34;content&#34;:[],&#34;stop_reason&#34;:null,&#34;stop_sequence&#34;:null,&#34;usage&#34;:{&#34;input_tokens&#34;:2679,&#34;cache_creation_input_tokens&#34;:0,&#34;cache_read_input_tokens&#34;:0,&#34;output_tokens&#34;:3}}}
 
@@ -637,6 +743,7 @@
 ### Claude 4.6
 
 For Claude 4.6 models, you should add a user message that instructs the model to continue from where it left off. For example:
+
 ```text Sample prompt
 Your previous response was interrupted and ended with [previous_response]. Continue from where you left off.
 ```
</code></pre>
    </div>
</body>
</html>