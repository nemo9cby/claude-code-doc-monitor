<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>build-with-claude/streaming - Diff Report</title>
    <link rel="stylesheet" href="../../css/diff.css">
    <style>
        :root {
            --bg-color: #1a1a2e;
            --card-bg: #16213e;
            --text-color: #eee;
            --accent: #0f3460;
            --add-bg: #1a4d1a;
            --del-bg: #4d1a1a;
            --add-text: #4ade80;
            --del-text: #f87171;
        }
        @media (prefers-color-scheme: light) {
            :root {
                --bg-color: #f5f5f5;
                --card-bg: #fff;
                --text-color: #333;
                --accent: #e0e0e0;
                --add-bg: #d4edda;
                --del-bg: #f8d7da;
                --add-text: #155724;
                --del-text: #721c24;
            }
        }
        * { box-sizing: border-box; margin: 0; padding: 0; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: var(--bg-color);
            color: var(--text-color);
            line-height: 1.6;
            padding: 2rem;
        }
        .container { max-width: 1200px; margin: 0 auto; }
        header { margin-bottom: 2rem; }
        h1 { font-size: 1.5rem; margin-bottom: 0.5rem; }
        .meta { color: #888; font-size: 0.9rem; }
        .summary {
            background: var(--card-bg);
            padding: 1rem;
            border-radius: 8px;
            margin-bottom: 2rem;
            display: flex;
            gap: 2rem;
        }
        .stat { display: flex; align-items: center; gap: 0.5rem; }
        .stat.added { color: var(--add-text); }
        .stat.removed { color: var(--del-text); }
        .analysis {
            background: var(--card-bg);
            padding: 1.5rem;
            border-radius: 8px;
            margin-bottom: 2rem;
            border-left: 4px solid #8b5cf6;
        }
        .analysis-header {
            font-weight: 600;
            margin-bottom: 0.75rem;
            color: #8b5cf6;
        }
        .analysis-content {
            white-space: pre-wrap;
            font-size: 0.95rem;
            line-height: 1.7;
        }
        .diff-container {
            background: var(--card-bg);
            border-radius: 8px;
            overflow: hidden;
        }
        .diff-header {
            background: var(--accent);
            padding: 0.75rem 1rem;
            font-weight: 600;
        }
        .diff-content {
            padding: 1rem;
            overflow-x: auto;
        }
        .diff-content ins {
            background: var(--add-bg);
            color: var(--add-text);
            text-decoration: none;
            padding: 0.1em 0.2em;
            border-radius: 2px;
        }
        .diff-content del {
            background: var(--del-bg);
            color: var(--del-text);
            text-decoration: line-through;
            padding: 0.1em 0.2em;
            border-radius: 2px;
        }
        pre {
            background: var(--accent);
            padding: 1rem;
            border-radius: 8px;
            overflow-x: auto;
            font-size: 0.85rem;
            margin-top: 2rem;
        }
        a { color: #60a5fa; }
        .back-link { margin-bottom: 1rem; display: inline-block; }
    </style>
</head>
<body>
    <div class="container">
        <a href="../../index.html" class="back-link">&larr; Back to daily report</a>

        <header>
            <h1>build-with-claude/streaming.md</h1>
            <p class="meta">Changed on 2026-02-18 20:48:24 EST</p>
        </header>

        <div class="summary">
            <div class="stat added">
                <span>+10</span> lines added
            </div>
            <div class="stat removed">
                <span>-10</span> lines removed
            </div>
        </div>

        

        <div class="diff-container">
            <div class="diff-header">Visual Diff</div>
            <div class="diff-content"><span># Streaming Messages&para;<br>&para;<br>---&para;<br>&para;<br>When creating a Message, you can set `"stream": true` to incrementally stream the response using [server-sent events](https://developer.mozilla.org/en-US/Web/API/Server-sent%5Fevents/Using%5Fserver-sent%5Fevents) (SSE).&para;<br>&para;<br>## Streaming with SDKs&para;<br>&para;<br></span><del style="background:#ffe6e6;">Our</del><ins style="background:#e6ffe6;">The</ins><span> [Python](https://github.com/anthropics/anthropic-sdk-python) and [TypeScript](https://github.com/anthropics/anthropic-sdk-typescript) SDKs offer multiple ways of streaming. The Python SDK allows both sync and async streams. See the documentation in each SDK for details.&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>    ```python Python&para;<br>    import anthropic&para;<br>&para;<br>    client = anthropic.Anthropic()&para;<br>&para;<br>    with client.messages.stream(&para;<br>        max_tokens=1024,&para;<br>        messages=[{"role": "user", "content": "Hello"}],&para;<br>        model="claude-opus-4-6",&para;<br>    ) as stream:&para;<br>        for text in stream.text_stream:&para;<br>            print(text, end="", flush=True)&para;<br>    ```&para;<br>&para;<br>    ```typescript TypeScript&para;<br>    import Anthropic from "@anthropic-ai/sdk";&para;<br>&para;<br>    const client = new Anthropic();&para;<br>&para;<br>    await client.messages.stream({&para;<br>      messages: [{ role: "user", content: "Hello" }],&para;<br>      model: "claude-opus-4-6",&para;<br>      max_tokens: 1024&para;<br>    }).on("text", (text) =&gt; {&para;<br>      console.log(text);&para;<br>    });&para;<br>    ```&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>## Get the final message without handling events&para;<br>&para;<br>If you don't need to process text as it arrives, the SDKs provide a way to use streaming under the hood while returning the complete `Message` object</span><del style="background:#ffe6e6;"> —</del><ins style="background:#e6ffe6;">,</ins><span> identical to what `.create()` returns. This is especially useful for requests with large `max_tokens` values, where the SDKs require streaming to avoid HTTP timeouts.&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>    ```python Python&para;<br>    import anthropic&para;<br>&para;<br>    client = anthropic.Anthropic()&para;<br>&para;<br>    with client.messages.stream(&para;<br>        max_tokens=128000,&para;<br>        messages=[{"role": "user", "content": "Write a detailed analysis..."}],&para;<br>        model="claude-opus-4-6",&para;<br>    ) as stream:&para;<br>        message = stream.get_final_message()&para;<br>&para;<br>    print(message.content[0].text)&para;<br>    ```&para;<br>&para;<br>    ```typescript TypeScript&para;<br>    import Anthropic from "@anthropic-ai/sdk";&para;<br>&para;<br>    const client = new Anthropic();&para;<br>&para;<br>    const stream = client.messages.stream({&para;<br>      max_tokens: 128000,&para;<br>      messages: [{ role: "user", content: "Write a detailed analysis..." }],&para;<br>      model: "claude-opus-4-6"&para;<br>    });&para;<br>&para;<br>    const message = await stream.finalMessage();&para;<br>    console.log(message.content[0].text);&para;<br>    ```&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>The `.stream()` call keeps the HTTP connection alive with server-sent events, then `.get_final_message()` (Python) or `.finalMessage()` (TypeScript) accumulates all events and returns the complete `Message` object. No event handling code is needed.&para;<br>&para;<br>## Event types&para;<br>&para;<br>Each server-sent event includes a named event type and associated JSON data. Each event will use an SSE event name (e.g. `event: message_stop`), and include the matching event `type` in its data.&para;<br>&para;<br>Each stream uses the following event flow:&para;<br>&para;<br>1. `message_start`: contains a `Message` object with empty `content`.&para;<br>2. A series of content blocks, each of which have a `content_block_start`, one or more `content_block_delta` events, and a `content_block_stop` event. Each content block will have an `index` that corresponds to its index in the final Message `content` array.&para;<br>3. One or more `message_delta` events, indicating top-level changes to the final `Message` object.&para;<br>4. A final `message_stop` event.&para;<br>&para;<br>  &lt;Warning&gt;&para;<br>  The token counts shown in the `usage` field of the `message_delta` event are *cumulative*.&para;<br>  &lt;/Warning&gt;&para;<br>&para;<br>### Ping events&para;<br>&para;<br>Event streams may also include any number of `ping` events.&para;<br>&para;<br>### Error events&para;<br>&para;<br></span><del style="background:#ffe6e6;">We</del><ins style="background:#e6ffe6;">The API</ins><span> may occasionally send [errors](/docs/en/api/errors) in the event stream. For example, during periods of high usage, you may receive an `overloaded_error`, which would normally correspond to an HTTP 529 in a non-streaming context:&para;<br>&para;<br>```json Example error&para;<br>event: error&para;<br>data: {"type": "error", "error": {"type": "overloaded_error", "message": "Overloaded"}}&para;<br>```&para;<br>&para;<br>### Other events&para;<br>&para;<br>In accordance with </span><del style="background:#ffe6e6;">our</del><ins style="background:#e6ffe6;">the</ins><span> [versioning policy](/docs/en/api/versioning),</span><del style="background:#ffe6e6;"> we may add</del><span> new event types</span><ins style="background:#e6ffe6;"> may be added</ins><span>, and your code should handle unknown event types gracefully.&para;<br>&para;<br>## Content block delta types&para;<br>&para;<br>Each `content_block_delta` event contains a `delta` of a type that updates the `content` block at a given `index`.&para;<br>&para;<br>### Text delta&para;<br>&para;<br>A `text` content block delta looks like:&para;<br>```json Text delta&para;<br>event: content_block_delta&para;<br>data: {"type": "content_block_delta","index": 0,"delta": {"type": "text_delta", "text": "ello frien"}}&para;<br>```&para;<br>&para;<br>### Input JSON delta&para;<br>&para;<br>The deltas for `tool_use` content blocks correspond to updates for the `input` field of the block. To support maximum granularity, the deltas are _partial JSON strings_, whereas the final `tool_use.input` is always an _object_.&para;<br>&para;<br>You can accumulate the string deltas and parse the JSON once you receive a `content_block_stop` event, by using a library like [Pydantic](https://docs.pydantic.dev/latest/concepts/json/#partial-json-parsing) to do partial JSON parsing, or by using </span><del style="background:#ffe6e6;">our</del><ins style="background:#e6ffe6;">the</ins><span> [SDKs](/docs/en/api/client-sdks), which provide helpers to access parsed incremental values.&para;<br>&para;<br>A `tool_use` content block delta looks like:&para;<br>```json Input JSON delta&para;<br>event: content_block_delta&para;<br>data: {"type": "content_block_delta","index": 1,"delta": {"type": "input_json_delta","partial_json": "{\"location\": \"San Fra"}}}&para;<br>```&para;<br>Note: </span><del style="background:#ffe6e6;">Our c</del><ins style="background:#e6ffe6;">C</ins><span>urrent models only support emitting one complete key and value property from `input` at a time. As such, when using tools, there may be delays between streaming events while the model is working. Once an `input` key and value are accumulated, </span><del style="background:#ffe6e6;">w</del><ins style="background:#e6ffe6;">they ar</ins><span>e emit</span><del style="background:#ffe6e6;"> them</del><ins style="background:#e6ffe6;">ted</ins><span> as multiple `content_block_delta` events with chunked partial json so that the format can automatically support finer granularity in future models.&para;<br>&para;<br>### Thinking delta&para;<br>&para;<br>When using [extended thinking](/docs/en/build-with-claude/extended-thinking#streaming-thinking) with streaming enabled, you'll receive thinking content via `thinking_delta` events. These deltas correspond to the `thinking` field of the `thinking` content blocks.&para;<br>&para;<br>For thinking content, a special `signature_delta` event is sent just before the `content_block_stop` event. This signature is used to verify the integrity of the thinking block.&para;<br>&para;<br>A typical thinking delta looks like:&para;<br>```json Thinking delta&para;<br>event: content_block_delta&para;<br>data: {"type": "content_block_delta", "index": 0, "delta": {"type": "thinking_delta", "thinking": "I need to find the GCD of 1071 and 462 using the Euclidean algorithm.\n\n1071 = 2 × 462 + 147"}}&para;<br>```&para;<br>&para;<br>The signature delta looks like:&para;<br>```json Signature delta&para;<br>event: content_block_delta&para;<br>data: {"type": "content_block_delta", "index": 0, "delta": {"type": "signature_delta", "signature": "EqQBCgIYAhIM1gbcDa9GJwZA2b3hGgxBdjrkzLoky3dl1pkiMOYds..."}}&para;<br>```&para;<br>&para;<br>## Full HTTP Stream response&para;<br>&para;<br></span><del style="background:#ffe6e6;">We strongly recommend that you use our</del><ins style="background:#e6ffe6;">Use the</ins><span> [client SDKs](/docs/en/api/client-sdks) when using streaming mode. However, if you are building a direct API integration, you will need to handle these events yourself.&para;<br>&para;<br>A stream response is comprised of:&para;<br>1. A `message_start` event&para;<br>2. Potentially multiple content blocks, each of which contains:&para;<br>    - A `content_block_start` event&para;<br>    - Potentially multiple `content_block_delta` events&para;<br>    - A `content_block_stop` event&para;<br>3. A `message_delta` event&para;<br>4. A `message_stop` event&para;<br>&para;<br>There may be `ping` events dispersed throughout the response as well. See [Event types](#event-types) for more details on the format.&para;<br>&para;<br>### Basic streaming request&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>```bash Shell&para;<br>curl https://api.anthropic.com/v1/messages \&para;<br>     --header "anthropic-version: 2023-06-01" \&para;<br>     --header "content-type: application/json" \&para;<br>     --header "x-api-key: $ANTHROPIC_API_KEY" \&para;<br>     --data \&para;<br>'{&para;<br>  "model": "claude-opus-4-6",&para;<br>  "messages": [{"role": "user", "content": "Hello"}],&para;<br>  "max_tokens": 256,&para;<br>  "stream": true&para;<br>}'&para;<br>```&para;<br>&para;<br>```python Python&para;<br>import anthropic&para;<br>&para;<br>client = anthropic.Anthropic()&para;<br>&para;<br>with client.messages.stream(&para;<br>    model="claude-opus-4-6",&para;<br>    messages=[{"role": "user", "content": "Hello"}],&para;<br>    max_tokens=256,&para;<br>) as stream:&para;<br>    for text in stream.text_stream:&para;<br>        print(text, end="", flush=True)&para;<br>```&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>```json Response&para;<br>event: message_start&para;<br>data: {"type": "message_start", "message": {"id": "msg_1nZdL29xx5MUA1yADyHTEsnR8uuvGzszyY", "type": "message", "role": "assistant", "content": [], "model": "claude-opus-4-6", "stop_reason": null, "stop_sequence": null, "usage": {"input_tokens": 25, "output_tokens": 1}}}&para;<br>&para;<br>event: content_block_start&para;<br>data: {"type": "content_block_start", "index": 0, "content_block": {"type": "text", "text": ""}}&para;<br>&para;<br>event: ping&para;<br>data: {"type": "ping"}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type": "content_block_delta", "index": 0, "delta": {"type": "text_delta", "text": "Hello"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type": "content_block_delta", "index": 0, "delta": {"type": "text_delta", "text": "!"}}&para;<br>&para;<br>event: content_block_stop&para;<br>data: {"type": "content_block_stop", "index": 0}&para;<br>&para;<br>event: message_delta&para;<br>data: {"type": "message_delta", "delta": {"stop_reason": "end_turn", "stop_sequence":null}, "usage": {"output_tokens": 15}}&para;<br>&para;<br>event: message_stop&para;<br>data: {"type": "message_stop"}&para;<br>&para;<br>```&para;<br>&para;<br>### Streaming request with tool use&para;<br>&para;<br>&lt;Tip&gt;&para;<br>Tool use supports [fine-grained streaming](/docs/en/agents-and-tools/tool-use/fine-grained-tool-streaming) for parameter values. Enable it per tool with `eager_input_streaming`.&para;<br>&lt;/Tip&gt;&para;<br>&para;<br></span><del style="background:#ffe6e6;">In t</del><ins style="background:#e6ffe6;">T</ins><span>his request</span><del style="background:#ffe6e6;">, we</del><span> ask</span><ins style="background:#e6ffe6;">s</ins><span> Claude to use a tool to </span><del style="background:#ffe6e6;">tell us</del><ins style="background:#e6ffe6;">report</ins><span> the weather.&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>```bash Shell&para;<br>  curl https://api.anthropic.com/v1/messages \&para;<br>    -H "content-type: application/json" \&para;<br>    -H "x-api-key: $ANTHROPIC_API_KEY" \&para;<br>    -H "anthropic-version: 2023-06-01" \&para;<br>    -d '{&para;<br>      "model": "claude-opus-4-6",&para;<br>      "max_tokens": 1024,&para;<br>      "tools": [&para;<br>        {&para;<br>          "name": "get_weather",&para;<br>          "description": "Get the current weather in a given location",&para;<br>          "input_schema": {&para;<br>            "type": "object",&para;<br>            "properties": {&para;<br>              "location": {&para;<br>                "type": "string",&para;<br>                "description": "The city and state, e.g. San Francisco, CA"&para;<br>              }&para;<br>            },&para;<br>            "required": ["location"]&para;<br>          }&para;<br>        }&para;<br>      ],&para;<br>      "tool_choice": {"type": "any"},&para;<br>      "messages": [&para;<br>        {&para;<br>          "role": "user",&para;<br>          "content": "What is the weather like in San Francisco?"&para;<br>        }&para;<br>      ],&para;<br>      "stream": true&para;<br>    }'&para;<br>```&para;<br>&para;<br>```python Python&para;<br>import anthropic&para;<br>&para;<br>client = anthropic.Anthropic()&para;<br>&para;<br>tools = [&para;<br>    {&para;<br>        "name": "get_weather",&para;<br>        "description": "Get the current weather in a given location",&para;<br>        "input_schema": {&para;<br>            "type": "object",&para;<br>            "properties": {&para;<br>                "location": {&para;<br>                    "type": "string",&para;<br>                    "description": "The city and state, e.g. San Francisco, CA",&para;<br>                }&para;<br>            },&para;<br>            "required": ["location"],&para;<br>        },&para;<br>    }&para;<br>]&para;<br>&para;<br>with client.messages.stream(&para;<br>    model="claude-opus-4-6",&para;<br>    max_tokens=1024,&para;<br>    tools=tools,&para;<br>    tool_choice={"type": "any"},&para;<br>    messages=[&para;<br>        {"role": "user", "content": "What is the weather like in San Francisco?"}&para;<br>    ],&para;<br>) as stream:&para;<br>    for text in stream.text_stream:&para;<br>        print(text, end="", flush=True)&para;<br>```&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>```json Response&para;<br>event: message_start&para;<br>data: {"type":"message_start","message":{"id":"msg_014p7gG3wDgGV9EUtLvnow3U","type":"message","role":"assistant","model":"claude-opus-4-6","stop_sequence":null,"usage":{"input_tokens":472,"output_tokens":2},"content":[],"stop_reason":null}}&para;<br>&para;<br>event: content_block_start&para;<br>data: {"type":"content_block_start","index":0,"content_block":{"type":"text","text":""}}&para;<br>&para;<br>event: ping&para;<br>data: {"type": "ping"}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":"Okay"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":","}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":" let"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":"'s"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":" check"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":" the"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":" weather"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":" for"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":" San"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":" Francisco"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":","}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":" CA"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":":"}}&para;<br>&para;<br>event: content_block_stop&para;<br>data: {"type":"content_block_stop","index":0}&para;<br>&para;<br>event: content_block_start&para;<br>data: {"type":"content_block_start","index":1,"content_block":{"type":"tool_use","id":"toolu_01T1x1fJ34qAmk2tNTrN7Up6","name":"get_weather","input":{}}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":""}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":"{\"location\":"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":" \"San"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":" Francisc"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":"o,"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":" CA\""}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":", "}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":"\"unit\": \"fah"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":"renheit\"}"}}&para;<br>&para;<br>event: content_block_stop&para;<br>data: {"type":"content_block_stop","index":1}&para;<br>&para;<br>event: message_delta&para;<br>data: {"type":"message_delta","delta":{"stop_reason":"tool_use","stop_sequence":null},"usage":{"output_tokens":89}}&para;<br>&para;<br>event: message_stop&para;<br>data: {"type":"message_stop"}&para;<br>```&para;<br>&para;<br>### Streaming request with extended thinking&para;<br>&para;<br></span><del style="background:#ffe6e6;">In t</del><ins style="background:#e6ffe6;">T</ins><span>his request</span><del style="background:#ffe6e6;">, we</del><span> enable</span><ins style="background:#e6ffe6;">s</ins><span> extended thinking with streaming to see Claude's step-by-step reasoning.&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>```bash Shell&para;<br>curl https://api.anthropic.com/v1/messages \&para;<br>     --header "x-api-key: $ANTHROPIC_API_KEY" \&para;<br>     --header "anthropic-version: 2023-06-01" \&para;<br>     --header "content-type: application/json" \&para;<br>     --data \&para;<br>'{&para;<br>    "model": "claude-opus-4-6",&para;<br>    "max_tokens": 20000,&para;<br>    "stream": true,&para;<br>    "thinking": {&para;<br>        "type": "enabled",&para;<br>        "budget_tokens": 16000&para;<br>    },&para;<br>    "messages": [&para;<br>        {&para;<br>            "role": "user",&para;<br>            "content": "What is the greatest common divisor of 1071 and 462?"&para;<br>        }&para;<br>    ]&para;<br>}'&para;<br>```&para;<br>&para;<br>```python Python&para;<br>import anthropic&para;<br>&para;<br>client = anthropic.Anthropic()&para;<br>&para;<br>with client.messages.stream(&para;<br>    model="claude-opus-4-6",&para;<br>    max_tokens=20000,&para;<br>    thinking={"type": "enabled", "budget_tokens": 16000},&para;<br>    messages=[&para;<br>        {&para;<br>            "role": "user",&para;<br>            "content": "What is the greatest common divisor of 1071 and 462?",&para;<br>        }&para;<br>    ],&para;<br>) as stream:&para;<br>    for event in stream:&para;<br>        if event.type == "content_block_delta":&para;<br>            if event.delta.type == "thinking_delta":&para;<br>                print(event.delta.thinking, end="", flush=True)&para;<br>            elif event.delta.type == "text_delta":&para;<br>                print(event.delta.text, end="", flush=True)&para;<br>```&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>```json Response&para;<br>event: message_start&para;<br>data: {"type": "message_start", "message": {"id": "msg_01...", "type": "message", "role": "assistant", "content": [], "model": "claude-opus-4-6", "stop_reason": null, "stop_sequence": null}}&para;<br>&para;<br>event: content_block_start&para;<br>data: {"type": "content_block_start", "index": 0, "content_block": {"type": "thinking", "thinking": ""}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type": "content_block_delta", "index": 0, "delta": {"type": "thinking_delta", "thinking": "I need to find the GCD of 1071 and 462 using the Euclidean algorithm.\n\n1071 = 2 × 462 + 147"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type": "content_block_delta", "index": 0, "delta": {"type": "thinking_delta", "thinking": "\n462 = 3 × 147 + 21"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type": "content_block_delta", "index": 0, "delta": {"type": "thinking_delta", "thinking": "\n147 = 7 × 21 + 0"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type": "content_block_delta", "index": 0, "delta": {"type": "thinking_delta", "thinking": "\nThe remainder is 0, so GCD(1071, 462) = 21."}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type": "content_block_delta", "index": 0, "delta": {"type": "signature_delta", "signature": "EqQBCgIYAhIM1gbcDa9GJwZA2b3hGgxBdjrkzLoky3dl1pkiMOYds..."}}&para;<br>&para;<br>event: content_block_stop&para;<br>data: {"type": "content_block_stop", "index": 0}&para;<br>&para;<br>event: content_block_start&para;<br>data: {"type": "content_block_start", "index": 1, "content_block": {"type": "text", "text": ""}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type": "content_block_delta", "index": 1, "delta": {"type": "text_delta", "text": "The greatest common divisor of 1071 and 462 is **21**."}}&para;<br>&para;<br>event: content_block_stop&para;<br>data: {"type": "content_block_stop", "index": 1}&para;<br>&para;<br>event: message_delta&para;<br>data: {"type": "message_delta", "delta": {"stop_reason": "end_turn", "stop_sequence": null}}&para;<br>&para;<br>event: message_stop&para;<br>data: {"type": "message_stop"}&para;<br>```&para;<br>&para;<br>### Streaming request with web search tool use&para;<br>&para;<br></span><del style="background:#ffe6e6;">In t</del><ins style="background:#e6ffe6;">T</ins><span>his request</span><del style="background:#ffe6e6;">, we</del><span> ask</span><ins style="background:#e6ffe6;">s</ins><span> Claude to search the web for current weather information.&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>```bash Shell&para;<br>curl https://api.anthropic.com/v1/messages \&para;<br>     --header "x-api-key: $ANTHROPIC_API_KEY" \&para;<br>     --header "anthropic-version: 2023-06-01" \&para;<br>     --header "content-type: application/json" \&para;<br>     --data \&para;<br>'{&para;<br>    "model": "claude-opus-4-6",&para;<br>    "max_tokens": 1024,&para;<br>    "stream": true,&para;<br>    "tools": [&para;<br>        {&para;<br>            "type": "web_search_20250305",&para;<br>            "name": "web_search",&para;<br>            "max_uses": 5&para;<br>        }&para;<br>    ],&para;<br>    "messages": [&para;<br>        {&para;<br>            "role": "user",&para;<br>            "content": "What is the weather like in New York City today?"&para;<br>        }&para;<br>    ]&para;<br>}'&para;<br>```&para;<br>&para;<br>```python Python&para;<br>import anthropic&para;<br>&para;<br>client = anthropic.Anthropic()&para;<br>&para;<br>with client.messages.stream(&para;<br>    model="claude-opus-4-6",&para;<br>    max_tokens=1024,&para;<br>    tools=[{"type": "web_search_20250305", "name": "web_search", "max_uses": 5}],&para;<br>    messages=[&para;<br>        {"role": "user", "content": "What is the weather like in New York City today?"}&para;<br>    ],&para;<br>) as stream:&para;<br>    for text in stream.text_stream:&para;<br>        print(text, end="", flush=True)&para;<br>```&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>```json Response&para;<br>event: message_start&para;<br>data: {"type":"message_start","message":{"id":"msg_01G...","type":"message","role":"assistant","model":"claude-opus-4-6","content":[],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2679,"cache_creation_input_tokens":0,"cache_read_input_tokens":0,"output_tokens":3}}}&para;<br>&para;<br>event: content_block_start&para;<br>data: {"type":"content_block_start","index":0,"content_block":{"type":"text","text":""}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":"I'll check"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":" the current weather in New York City for you"}}&para;<br>&para;<br>event: ping&para;<br>data: {"type": "ping"}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":0,"delta":{"type":"text_delta","text":"."}}&para;<br>&para;<br>event: content_block_stop&para;<br>data: {"type":"content_block_stop","index":0}&para;<br>&para;<br>event: content_block_start&para;<br>data: {"type":"content_block_start","index":1,"content_block":{"type":"server_tool_use","id":"srvtoolu_014hJH82Qum7Td6UV8gDXThB","name":"web_search","input":{}}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":""}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":"{\"query"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":"\":"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":" \"weather"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":" NY"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":"C to"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":1,"delta":{"type":"input_json_delta","partial_json":"day\"}"}}&para;<br>&para;<br>event: content_block_stop&para;<br>data: {"type":"content_block_stop","index":1 }&para;<br>&para;<br>event: content_block_start&para;<br>data: {"type":"content_block_start","index":2,"content_block":{"type":"web_search_tool_result","tool_use_id":"srvtoolu_014hJH82Qum7Td6UV8gDXThB","content":[{"type":"web_search_result","title":"Weather in New York City in May 2025 (New York) - detailed Weather Forecast for a month","url":"https://world-weather.info/forecast/usa/new_york/may-2025/","encrypted_content":"Ev0DCioIAxgCIiQ3NmU4ZmI4OC1k...","page_age":null},...]}}&para;<br>&para;<br>event: content_block_stop&para;<br>data: {"type":"content_block_stop","index":2}&para;<br>&para;<br>event: content_block_start&para;<br>data: {"type":"content_block_start","index":3,"content_block":{"type":"text","text":""}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":3,"delta":{"type":"text_delta","text":"Here's the current weather information for New York"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":3,"delta":{"type":"text_delta","text":" City:\n\n# Weather"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":3,"delta":{"type":"text_delta","text":" in New York City"}}&para;<br>&para;<br>event: content_block_delta&para;<br>data: {"type":"content_block_delta","index":3,"delta":{"type":"text_delta","text":"\n\n"}}&para;<br>&para;<br>...&para;<br>&para;<br>event: content_block_stop&para;<br>data: {"type":"content_block_stop","index":17}&para;<br>&para;<br>event: message_delta&para;<br>data: {"type":"message_delta","delta":{"stop_reason":"end_turn","stop_sequence":null},"usage":{"input_tokens":10682,"cache_creation_input_tokens":0,"cache_read_input_tokens":0,"output_tokens":510,"server_tool_use":{"web_search_requests":1}}}&para;<br>&para;<br>event: message_stop&para;<br>data: {"type":"message_stop"}&para;<br>```&para;<br>&para;<br>## Error recovery&para;<br>&para;<br>### Claude 4.5 and earlier&para;<br>&para;<br>For Claude 4.5 models and earlier, you can recover a streaming request that was interrupted due to network issues, timeouts, or other errors by resuming from where the stream was interrupted. This approach saves you from re-processing the entire response.&para;<br>&para;<br>The basic recovery strategy involves:&para;<br>&para;<br>1. **Capture the partial response**: Save all content that was successfully received before the error occurred&para;<br>2. **Construct a continuation request**: Create a new API request that includes the partial assistant response as the beginning of a new assistant message&para;<br>3. **Resume streaming**: Continue receiving the rest of the response from where it was interrupted&para;<br>&para;<br>### Claude 4.6&para;<br>&para;<br>For Claude 4.6 models, you should add a user message that instructs the model to continue from where it left off. For example:&para;<br>```text Sample prompt&para;<br>Your previous response was interrupted and ended with [previous_response]. Continue from where you left off.&para;<br>```&para;<br>&para;<br>### Error recovery best practices&para;<br>&para;<br>1. **Use SDK features**: Leverage the SDK's built-in message accumulation and error handling capabilities&para;<br>2. **Handle content types**: Be aware that messages can contain multiple content blocks (`text`, `tool_use`, `thinking`). Tool use and extended thinking blocks cannot be partially recovered. You can resume streaming from the most recent text block.</span></div>
        </div>

        <h2 style="margin-top: 2rem; margin-bottom: 1rem;">Unified Diff</h2>
        <pre><code>--- a/build-with-claude/streaming.md
+++ b/build-with-claude/streaming.md
@@ -6,7 +6,7 @@
 
 ## Streaming with SDKs
 
-Our [Python](https://github.com/anthropics/anthropic-sdk-python) and [TypeScript](https://github.com/anthropics/anthropic-sdk-typescript) SDKs offer multiple ways of streaming. The Python SDK allows both sync and async streams. See the documentation in each SDK for details.
+The [Python](https://github.com/anthropics/anthropic-sdk-python) and [TypeScript](https://github.com/anthropics/anthropic-sdk-typescript) SDKs offer multiple ways of streaming. The Python SDK allows both sync and async streams. See the documentation in each SDK for details.
 
 &lt;CodeGroup&gt;
     ```python Python
@@ -40,7 +40,7 @@
 
 ## Get the final message without handling events
 
-If you don&#39;t need to process text as it arrives, the SDKs provide a way to use streaming under the hood while returning the complete `Message` object — identical to what `.create()` returns. This is especially useful for requests with large `max_tokens` values, where the SDKs require streaming to avoid HTTP timeouts.
+If you don&#39;t need to process text as it arrives, the SDKs provide a way to use streaming under the hood while returning the complete `Message` object, identical to what `.create()` returns. This is especially useful for requests with large `max_tokens` values, where the SDKs require streaming to avoid HTTP timeouts.
 
 &lt;CodeGroup&gt;
     ```python Python
@@ -97,7 +97,7 @@
 
 ### Error events
 
-We may occasionally send [errors](/docs/en/api/errors) in the event stream. For example, during periods of high usage, you may receive an `overloaded_error`, which would normally correspond to an HTTP 529 in a non-streaming context:
+The API may occasionally send [errors](/docs/en/api/errors) in the event stream. For example, during periods of high usage, you may receive an `overloaded_error`, which would normally correspond to an HTTP 529 in a non-streaming context:
 
 ```json Example error
 event: error
@@ -106,7 +106,7 @@
 
 ### Other events
 
-In accordance with our [versioning policy](/docs/en/api/versioning), we may add new event types, and your code should handle unknown event types gracefully.
+In accordance with the [versioning policy](/docs/en/api/versioning), new event types may be added, and your code should handle unknown event types gracefully.
 
 ## Content block delta types
 
@@ -124,14 +124,14 @@
 
 The deltas for `tool_use` content blocks correspond to updates for the `input` field of the block. To support maximum granularity, the deltas are _partial JSON strings_, whereas the final `tool_use.input` is always an _object_.
 
-You can accumulate the string deltas and parse the JSON once you receive a `content_block_stop` event, by using a library like [Pydantic](https://docs.pydantic.dev/latest/concepts/json/#partial-json-parsing) to do partial JSON parsing, or by using our [SDKs](/docs/en/api/client-sdks), which provide helpers to access parsed incremental values.
+You can accumulate the string deltas and parse the JSON once you receive a `content_block_stop` event, by using a library like [Pydantic](https://docs.pydantic.dev/latest/concepts/json/#partial-json-parsing) to do partial JSON parsing, or by using the [SDKs](/docs/en/api/client-sdks), which provide helpers to access parsed incremental values.
 
 A `tool_use` content block delta looks like:
 ```json Input JSON delta
 event: content_block_delta
 data: {&#34;type&#34;: &#34;content_block_delta&#34;,&#34;index&#34;: 1,&#34;delta&#34;: {&#34;type&#34;: &#34;input_json_delta&#34;,&#34;partial_json&#34;: &#34;{\&#34;location\&#34;: \&#34;San Fra&#34;}}}
 ```
-Note: Our current models only support emitting one complete key and value property from `input` at a time. As such, when using tools, there may be delays between streaming events while the model is working. Once an `input` key and value are accumulated, we emit them as multiple `content_block_delta` events with chunked partial json so that the format can automatically support finer granularity in future models.
+Note: Current models only support emitting one complete key and value property from `input` at a time. As such, when using tools, there may be delays between streaming events while the model is working. Once an `input` key and value are accumulated, they are emitted as multiple `content_block_delta` events with chunked partial json so that the format can automatically support finer granularity in future models.
 
 ### Thinking delta
 
@@ -153,7 +153,7 @@
 
 ## Full HTTP Stream response
 
-We strongly recommend that you use our [client SDKs](/docs/en/api/client-sdks) when using streaming mode. However, if you are building a direct API integration, you will need to handle these events yourself.
+Use the [client SDKs](/docs/en/api/client-sdks) when using streaming mode. However, if you are building a direct API integration, you will need to handle these events yourself.
 
 A stream response is comprised of:
 1. A `message_start` event
@@ -231,7 +231,7 @@
 Tool use supports [fine-grained streaming](/docs/en/agents-and-tools/tool-use/fine-grained-tool-streaming) for parameter values. Enable it per tool with `eager_input_streaming`.
 &lt;/Tip&gt;
 
-In this request, we ask Claude to use a tool to tell us the weather.
+This request asks Claude to use a tool to report the weather.
 
 &lt;CodeGroup&gt;
 ```bash Shell
@@ -399,7 +399,7 @@
 
 ### Streaming request with extended thinking
 
-In this request, we enable extended thinking with streaming to see Claude&#39;s step-by-step reasoning.
+This request enables extended thinking with streaming to see Claude&#39;s step-by-step reasoning.
 
 &lt;CodeGroup&gt;
 ```bash Shell
@@ -493,7 +493,7 @@
 
 ### Streaming request with web search tool use
 
-In this request, we ask Claude to search the web for current weather information.
+This request asks Claude to search the web for current weather information.
 
 &lt;CodeGroup&gt;
 ```bash Shell
</code></pre>
    </div>
</body>
</html>