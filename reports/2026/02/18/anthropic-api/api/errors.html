<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>api/errors - Diff Report</title>
    <link rel="stylesheet" href="../../css/diff.css">
    <style>
        :root {
            --bg-color: #1a1a2e;
            --card-bg: #16213e;
            --text-color: #eee;
            --accent: #0f3460;
            --add-bg: #1a4d1a;
            --del-bg: #4d1a1a;
            --add-text: #4ade80;
            --del-text: #f87171;
        }
        @media (prefers-color-scheme: light) {
            :root {
                --bg-color: #f5f5f5;
                --card-bg: #fff;
                --text-color: #333;
                --accent: #e0e0e0;
                --add-bg: #d4edda;
                --del-bg: #f8d7da;
                --add-text: #155724;
                --del-text: #721c24;
            }
        }
        * { box-sizing: border-box; margin: 0; padding: 0; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: var(--bg-color);
            color: var(--text-color);
            line-height: 1.6;
            padding: 2rem;
        }
        .container { max-width: 1200px; margin: 0 auto; }
        header { margin-bottom: 2rem; }
        h1 { font-size: 1.5rem; margin-bottom: 0.5rem; }
        .meta { color: #888; font-size: 0.9rem; }
        .summary {
            background: var(--card-bg);
            padding: 1rem;
            border-radius: 8px;
            margin-bottom: 2rem;
            display: flex;
            gap: 2rem;
        }
        .stat { display: flex; align-items: center; gap: 0.5rem; }
        .stat.added { color: var(--add-text); }
        .stat.removed { color: var(--del-text); }
        .analysis {
            background: var(--card-bg);
            padding: 1.5rem;
            border-radius: 8px;
            margin-bottom: 2rem;
            border-left: 4px solid #8b5cf6;
        }
        .analysis-header {
            font-weight: 600;
            margin-bottom: 0.75rem;
            color: #8b5cf6;
        }
        .analysis-content {
            white-space: pre-wrap;
            font-size: 0.95rem;
            line-height: 1.7;
        }
        .diff-container {
            background: var(--card-bg);
            border-radius: 8px;
            overflow: hidden;
        }
        .diff-header {
            background: var(--accent);
            padding: 0.75rem 1rem;
            font-weight: 600;
        }
        .diff-content {
            padding: 1rem;
            overflow-x: auto;
        }
        .diff-content ins {
            background: var(--add-bg);
            color: var(--add-text);
            text-decoration: none;
            padding: 0.1em 0.2em;
            border-radius: 2px;
        }
        .diff-content del {
            background: var(--del-bg);
            color: var(--del-text);
            text-decoration: line-through;
            padding: 0.1em 0.2em;
            border-radius: 2px;
        }
        pre {
            background: var(--accent);
            padding: 1rem;
            border-radius: 8px;
            overflow-x: auto;
            font-size: 0.85rem;
            margin-top: 2rem;
        }
        a { color: #60a5fa; }
        .back-link { margin-bottom: 1rem; display: inline-block; }
    </style>
</head>
<body>
    <div class="container">
        <a href="../../index.html" class="back-link">&larr; Back to daily report</a>

        <header>
            <h1>api/errors.md</h1>
            <p class="meta">Changed on 2026-02-18 20:48:24 EST</p>
        </header>

        <div class="summary">
            <div class="stat added">
                <span>+10</span> lines added
            </div>
            <div class="stat removed">
                <span>-10</span> lines removed
            </div>
        </div>

        

        <div class="diff-container">
            <div class="diff-header">Visual Diff</div>
            <div class="diff-content"><span># Errors&para;<br>&para;<br>---&para;<br>&para;<br>## HTTP errors&para;<br>&para;<br></span><del style="background:#ffe6e6;">Our</del><ins style="background:#e6ffe6;">The</ins><span> API follows a predictable HTTP error code format:&para;<br>&para;<br>* 400 - `invalid_request_error`: There was an issue with the format or content of your request. </span><del style="background:#ffe6e6;">We may also use this error type</del><ins style="background:#e6ffe6;">This error type may also be used</ins><span> for other 4XX status codes not listed below.&para;<br>* 401 - `authentication_error`: There's an issue with your API key.&para;<br>* 403 - `permission_error`: Your API key does not have permission to use the specified resource.&para;<br>* 404 - `not_found_error`: The requested resource was not found.&para;<br>* 413 - `request_too_large`: Request exceeds the maximum allowed number of bytes. The maximum request size is 32 MB for standard API endpoints.&para;<br>* 429 - `rate_limit_error`: Your account has hit a rate limit.&para;<br>* 500 - `api_error`: An unexpected error has occurred internal to Anthropic's systems.&para;<br>* 529 - `overloaded_error`: The API is temporarily overloaded.&para;<br>&para;<br>  &lt;Warning&gt;&para;<br>  529 errors can occur when APIs experience high traffic across all users.&para;<br>&para;<br>  In rare cases, if your organization has a sharp increase in usage, you might see 429 errors due to acceleration limits on the API. To avoid hitting acceleration limits, ramp up your traffic gradually and maintain consistent usage patterns.&para;<br>  &lt;/Warning&gt;&para;<br>&para;<br>When receiving a [streaming](/docs/en/build-with-claude/streaming) response via SSE, it's possible that an error can occur after returning a 200 response, in which case error handling wouldn't follow these standard mechanisms.&para;<br>&para;<br>## Request size limits&para;<br>&para;<br>The API enforces request size limits to ensure optimal performance:&para;<br>&para;<br>| Endpoint Type | Maximum Request Size |&para;<br>|:---|:---|&para;<br>| Messages API | 32 MB |&para;<br>| Token Counting API | 32 MB |&para;<br>| [Batch API](/docs/en/build-with-claude/batch-processing) | 256 MB |&para;<br>| [Files API](/docs/en/build-with-claude/files) | 500 MB |&para;<br>&para;<br>If you exceed these limits, you'll receive a 413 `request_too_large` error. The error is returned from Cloudflare before the request reaches </span><del style="background:#ffe6e6;">our</del><ins style="background:#e6ffe6;">the</ins><span> API servers.&para;<br>&para;<br>## Error shapes&para;<br>&para;<br>Errors are always returned as JSON, with a top-level `error` object that always includes a `type` and `message` value. The response also includes a `request_id` field for easier tracking and debugging. For example:&para;<br>&para;<br>```json JSON&para;<br>{&para;<br>  "type": "error",&para;<br>  "error": {&para;<br>    "type": "not_found_error",&para;<br>    "message": "The requested resource could not be found."&para;<br>  },&para;<br>  "request_id": "req_011CSHoEeqs5C35K2UUqR7Fy"&para;<br>}&para;<br>```&para;<br>&para;<br>In accordance with </span><del style="background:#ffe6e6;">our</del><ins style="background:#e6ffe6;">the</ins><span> [versioning](/docs/en/api/versioning) policy,</span><del style="background:#ffe6e6;"> we may expand</del><span> the values within these objects</span><ins style="background:#e6ffe6;"> may expand</ins><span>, and it is possible that the `type` values will grow over time.&para;<br>&para;<br>## Request id&para;<br>&para;<br>Every API response includes a unique `request-id` header. This header contains a value such as `req_018EeWyXxfu5pfWkrYcMdjWG`. When contacting support about a specific request, please include this ID to help </span><del style="background:#ffe6e6;">us </del><span>quickly resolve your issue.&para;<br>&para;<br></span><del style="background:#ffe6e6;">Our</del><ins style="background:#e6ffe6;">The</ins><span> official SDKs provide this value as a property on top-level response objects, containing the value of the `request-id` header:&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>  ```python Python&para;<br>  import anthropic&para;<br>&para;<br>  client = anthropic.Anthropic()&para;<br>&para;<br>  message = client.messages.create(&para;<br>      model="claude-opus-4-6",&para;<br>      max_tokens=1024,&para;<br>      messages=[{"role": "user", "content": "Hello, Claude"}],&para;<br>  )&para;<br>  print(f"Request ID: {message._request_id}")&para;<br>  ```&para;<br>&para;<br>  ```typescript TypeScript&para;<br>  import Anthropic from "@anthropic-ai/sdk";&para;<br>&para;<br>  const client = new Anthropic();&para;<br>&para;<br>  const message = await client.messages.create({&para;<br>    model: "claude-opus-4-6",&para;<br>    max_tokens: 1024,&para;<br>    messages: [&para;<br>      { role: "user", content: "Hello, Claude" }&para;<br>    ]&para;<br>  });&para;<br>  console.log("Request ID:", message._request_id);&para;<br>  ```&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>## Long requests&para;<br>&para;<br>&lt;Warning&gt;&para;<br> </span><del style="background:#ffe6e6;">We highly encourage</del><ins style="background:#e6ffe6;">Consider</ins><span> using the [streaming Messages API](/docs/en/build-with-claude/streaming) or [Message Batches API](/docs/en/api/creating-message-batches) for long running requests, especially those over 10 minutes.&para;<br>&lt;/Warning&gt;&para;<br>&para;<br></span><del style="background:#ffe6e6;">We do not recommen</del><ins style="background:#e6ffe6;">Avoi</ins><span>d setting a large `max_tokens` value</span><del style="background:#ffe6e6;">s</del><span> without using </span><del style="background:#ffe6e6;">our</del><ins style="background:#e6ffe6;">the</ins><span> [streaming Messages API](/docs/en/build-with-claude/streaming)&para;<br>or [Message Batches API](/docs/en/api/creating-message-batches):&para;<br>&para;<br>- Some networks may drop idle connections after a variable period of time, which&para;<br>can cause the request to fail or timeout without receiving a response from Anthropic.&para;<br>- Networks differ in reliability; </span><del style="background:#ffe6e6;">our</del><ins style="background:#e6ffe6;">the</ins><span> [Message Batches API](/docs/en/api/creating-message-batches) can help you&para;<br>manage the risk of network issues by allowing you to poll for results rather than requiring an uninterrupted network connection.&para;<br>&para;<br>If you are building a direct API integration, you should be aware that setting a [TCP socket keep-alive](https://tldp.org/HOWTO/TCP-Keepalive-HOWTO/programming.html) can reduce the impact of idle connection timeouts on some networks.&para;<br>&para;<br></span><del style="background:#ffe6e6;">Our</del><ins style="background:#e6ffe6;">The</ins><span> [SDKs](/docs/en/api/client-sdks)</span><del style="background:#ffe6e6;"> will</del><span> validate that your non-streaming Messages API requests are not expected to exceed a 10 minute timeout and&para;<br>also will set a socket option for TCP keep-alive.&para;<br>&para;<br>If you don't need to process events incrementally, use `.stream()` with `.get_final_message()` (Python) or `.finalMessage()` (TypeScript) to get the complete `Message` object without writing event-handling code:&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>    ```python Python&para;<br>    with client.messages.stream(&para;<br>        max_tokens=128000,&para;<br>        messages=[{"role": "user", "content": "Write a detailed analysis..."}],&para;<br>        model="claude-opus-4-6",&para;<br>    ) as stream:&para;<br>        message = stream.get_final_message()&para;<br>    ```&para;<br>&para;<br>    ```typescript TypeScript&para;<br>    const stream = client.messages.stream({&para;<br>      max_tokens: 128000,&para;<br>      messages: [{ role: "user", content: "Write a detailed analysis..." }],&para;<br>      model: "claude-opus-4-6"&para;<br>    });&para;<br>    const message = await stream.finalMessage();&para;<br>    ```&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>See [Streaming Messages](/docs/en/build-with-claude/streaming#get-the-final-message-without-handling-events) for more details.&para;<br>&para;<br>## Common validation errors&para;<br>&para;<br>### Prefill not supported&para;<br>&para;<br>Claude Opus 4.6 does not support prefilling assistant messages. Sending a request with a prefilled last assistant message to this model returns a 400 `invalid_request_error`:&para;<br>&para;<br>```json&para;<br>{&para;<br>  "type": "error",&para;<br>  "error": {&para;<br>    "type": "invalid_request_error",&para;<br>    "message": "Prefilling assistant messages is not supported for this model."&para;<br>  }&para;<br>}&para;<br>```&para;<br>&para;<br>Use [structured outputs](/docs/en/build-with-claude/structured-outputs), system prompt instructions, or [`output_config.format`](/docs/en/build-with-claude/structured-outputs#json-outputs) instead.</span></div>
        </div>

        <h2 style="margin-top: 2rem; margin-bottom: 1rem;">Unified Diff</h2>
        <pre><code>--- a/api/errors.md
+++ b/api/errors.md
@@ -4,9 +4,9 @@
 
 ## HTTP errors
 
-Our API follows a predictable HTTP error code format:
+The API follows a predictable HTTP error code format:
 
-* 400 - `invalid_request_error`: There was an issue with the format or content of your request. We may also use this error type for other 4XX status codes not listed below.
+* 400 - `invalid_request_error`: There was an issue with the format or content of your request. This error type may also be used for other 4XX status codes not listed below.
 * 401 - `authentication_error`: There&#39;s an issue with your API key.
 * 403 - `permission_error`: Your API key does not have permission to use the specified resource.
 * 404 - `not_found_error`: The requested resource was not found.
@@ -34,7 +34,7 @@
 | [Batch API](/docs/en/build-with-claude/batch-processing) | 256 MB |
 | [Files API](/docs/en/build-with-claude/files) | 500 MB |
 
-If you exceed these limits, you&#39;ll receive a 413 `request_too_large` error. The error is returned from Cloudflare before the request reaches our API servers.
+If you exceed these limits, you&#39;ll receive a 413 `request_too_large` error. The error is returned from Cloudflare before the request reaches the API servers.
 
 ## Error shapes
 
@@ -51,13 +51,13 @@
 }
 ```
 
-In accordance with our [versioning](/docs/en/api/versioning) policy, we may expand the values within these objects, and it is possible that the `type` values will grow over time.
+In accordance with the [versioning](/docs/en/api/versioning) policy, the values within these objects may expand, and it is possible that the `type` values will grow over time.
 
 ## Request id
 
-Every API response includes a unique `request-id` header. This header contains a value such as `req_018EeWyXxfu5pfWkrYcMdjWG`. When contacting support about a specific request, please include this ID to help us quickly resolve your issue.
+Every API response includes a unique `request-id` header. This header contains a value such as `req_018EeWyXxfu5pfWkrYcMdjWG`. When contacting support about a specific request, please include this ID to help quickly resolve your issue.
 
-Our official SDKs provide this value as a property on top-level response objects, containing the value of the `request-id` header:
+The official SDKs provide this value as a property on top-level response objects, containing the value of the `request-id` header:
 
 &lt;CodeGroup&gt;
   ```python Python
@@ -92,20 +92,20 @@
 ## Long requests
 
 &lt;Warning&gt;
- We highly encourage using the [streaming Messages API](/docs/en/build-with-claude/streaming) or [Message Batches API](/docs/en/api/creating-message-batches) for long running requests, especially those over 10 minutes.
+ Consider using the [streaming Messages API](/docs/en/build-with-claude/streaming) or [Message Batches API](/docs/en/api/creating-message-batches) for long running requests, especially those over 10 minutes.
 &lt;/Warning&gt;
 
-We do not recommend setting a large `max_tokens` values without using our [streaming Messages API](/docs/en/build-with-claude/streaming)
+Avoid setting a large `max_tokens` value without using the [streaming Messages API](/docs/en/build-with-claude/streaming)
 or [Message Batches API](/docs/en/api/creating-message-batches):
 
 - Some networks may drop idle connections after a variable period of time, which
 can cause the request to fail or timeout without receiving a response from Anthropic.
-- Networks differ in reliability; our [Message Batches API](/docs/en/api/creating-message-batches) can help you
+- Networks differ in reliability; the [Message Batches API](/docs/en/api/creating-message-batches) can help you
 manage the risk of network issues by allowing you to poll for results rather than requiring an uninterrupted network connection.
 
 If you are building a direct API integration, you should be aware that setting a [TCP socket keep-alive](https://tldp.org/HOWTO/TCP-Keepalive-HOWTO/programming.html) can reduce the impact of idle connection timeouts on some networks.
 
-Our [SDKs](/docs/en/api/client-sdks) will validate that your non-streaming Messages API requests are not expected to exceed a 10 minute timeout and
+The [SDKs](/docs/en/api/client-sdks) validate that your non-streaming Messages API requests are not expected to exceed a 10 minute timeout and
 also will set a socket option for TCP keep-alive.
 
 If you don&#39;t need to process events incrementally, use `.stream()` with `.get_final_message()` (Python) or `.finalMessage()` (TypeScript) to get the complete `Message` object without writing event-handling code:
</code></pre>
    </div>
</body>
</html>