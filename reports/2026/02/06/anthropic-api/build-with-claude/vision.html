<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>build-with-claude/vision - Diff Report</title>
    <link rel="stylesheet" href="../../css/diff.css">
    <style>
        :root {
            --bg-color: #1a1a2e;
            --card-bg: #16213e;
            --text-color: #eee;
            --accent: #0f3460;
            --add-bg: #1a4d1a;
            --del-bg: #4d1a1a;
            --add-text: #4ade80;
            --del-text: #f87171;
        }
        @media (prefers-color-scheme: light) {
            :root {
                --bg-color: #f5f5f5;
                --card-bg: #fff;
                --text-color: #333;
                --accent: #e0e0e0;
                --add-bg: #d4edda;
                --del-bg: #f8d7da;
                --add-text: #155724;
                --del-text: #721c24;
            }
        }
        * { box-sizing: border-box; margin: 0; padding: 0; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: var(--bg-color);
            color: var(--text-color);
            line-height: 1.6;
            padding: 2rem;
        }
        .container { max-width: 1200px; margin: 0 auto; }
        header { margin-bottom: 2rem; }
        h1 { font-size: 1.5rem; margin-bottom: 0.5rem; }
        .meta { color: #888; font-size: 0.9rem; }
        .summary {
            background: var(--card-bg);
            padding: 1rem;
            border-radius: 8px;
            margin-bottom: 2rem;
            display: flex;
            gap: 2rem;
        }
        .stat { display: flex; align-items: center; gap: 0.5rem; }
        .stat.added { color: var(--add-text); }
        .stat.removed { color: var(--del-text); }
        .analysis {
            background: var(--card-bg);
            padding: 1.5rem;
            border-radius: 8px;
            margin-bottom: 2rem;
            border-left: 4px solid #8b5cf6;
        }
        .analysis-header {
            font-weight: 600;
            margin-bottom: 0.75rem;
            color: #8b5cf6;
        }
        .analysis-content {
            white-space: pre-wrap;
            font-size: 0.95rem;
            line-height: 1.7;
        }
        .diff-container {
            background: var(--card-bg);
            border-radius: 8px;
            overflow: hidden;
        }
        .diff-header {
            background: var(--accent);
            padding: 0.75rem 1rem;
            font-weight: 600;
        }
        .diff-content {
            padding: 1rem;
            overflow-x: auto;
        }
        .diff-content ins {
            background: var(--add-bg);
            color: var(--add-text);
            text-decoration: none;
            padding: 0.1em 0.2em;
            border-radius: 2px;
        }
        .diff-content del {
            background: var(--del-bg);
            color: var(--del-text);
            text-decoration: line-through;
            padding: 0.1em 0.2em;
            border-radius: 2px;
        }
        pre {
            background: var(--accent);
            padding: 1rem;
            border-radius: 8px;
            overflow-x: auto;
            font-size: 0.85rem;
            margin-top: 2rem;
        }
        a { color: #60a5fa; }
        .back-link { margin-bottom: 1rem; display: inline-block; }
    </style>
</head>
<body>
    <div class="container">
        <a href="../../index.html" class="back-link">&larr; Back to daily report</a>

        <header>
            <h1>build-with-claude/vision.md</h1>
            <p class="meta">Changed on 2026-02-06 18:20:36 EST</p>
        </header>

        <div class="summary">
            <div class="stat added">
                <span>+60</span> lines added
            </div>
            <div class="stat removed">
                <span>-17</span> lines removed
            </div>
        </div>

        

        <div class="diff-container">
            <div class="diff-header">Visual Diff</div>
            <div class="diff-content"><span># Vision&para;<br>&para;<br>Claude's vision capabilities allow it to understand and analyze images, opening up exciting possibilities for multimodal interaction.&para;<br>&para;<br>---&para;<br>&para;<br>This guide describes how to work with images in Claude, including best practices, code examples, and limitations to keep in mind.&para;<br>&para;<br>---&para;<br>&para;<br>## How to use vision&para;<br>&para;<br>Use Claude’s vision capabilities via:&para;<br>&para;<br>- [claude.ai](https://claude.ai/). Upload an image like you would a file, or drag and drop an image directly into the chat window.&para;<br>- The [Console Workbench](/workbench/). A button to add images appears at the top right of every User message block.&para;<br>- **API request**. See the examples in this guide.&para;<br>&para;<br>---&para;<br>&para;<br>## Before you upload&para;<br>&para;<br>### Basics and Limits&para;<br>&para;<br>You can include multiple images in a single request (up to 20 for [claude.ai](https://claude.ai/) and 100 for API requests). Claude will analyze all provided images when formulating its response. This can be helpful for comparing or contrasting images.&para;<br>&para;<br>If you submit an image larger than 8000x8000 px, it will be rejected. If you submit more than 20 images in one API request, this limit is 2000x2000 px.&para;<br>&para;<br>&lt;Note&gt;&para;<br>While the API supports 100 images per request, there is a [32MB request size limit](/docs/en/api/overview#request-size-limits) for standard endpoints.&para;<br>&lt;/Note&gt;&para;<br>&para;<br>### Evaluate image size&para;<br>&para;<br>For optimal performance,</span><del style="background:#ffe6e6;"> we recommend</del><span> resiz</span><del style="background:#ffe6e6;">ing</del><ins style="background:#e6ffe6;">e</ins><span> images before uploading if they are too large. If your image’s long edge is more than 1568 pixels, or your image is more than ~1,600 tokens, it will first be scaled down, preserving aspect ratio, until it’s within the size limits.&para;<br>&para;<br>If your input image is too large and needs to be resized, it will increase latency of [time-to-first-token](/docs/en/about-claude/glossary), without giving you any additional model performance. Very small images under 200 pixels on any given edge may degrade performance.&para;<br>&para;<br>&lt;Tip&gt;&para;<br>  To improve [time-to-first-token](/docs/en/about-claude/glossary), </span><del style="background:#ffe6e6;">we recommend</del><ins style="background:#e6ffe6;">consider</ins><span>&para;<br>  resizing images to no more than 1.15 megapixels (and within 1568 pixels in&para;<br>  both dimensions).&para;<br>&lt;/Tip&gt;&para;<br>&para;<br>Here is a table of maximum image sizes accepted by </span><del style="background:#ffe6e6;">our</del><ins style="background:#e6ffe6;">the</ins><span> API that will not be resized for common aspect ratios. With Claude Opus 4.6, these images use approximately 1,600 tokens and around $4.80/1K images.&para;<br>&para;<br>| Aspect ratio | Image size   |&para;<br>| ------------ | ------------ |&para;<br>| 1&amp;#58;1      | 1092x1092 px |&para;<br>| 3&amp;#58;4      | 951x1268 px  |&para;<br>| 2&amp;#58;3      | 896x1344 px  |&para;<br>| 9&amp;#58;16     | 819x1456 px  |&para;<br>| 1&amp;#58;2      | 784x1568 px  |&para;<br>&para;<br>### Calculate image costs&para;<br>&para;<br>Each image you include in a request to Claude counts towards your token usage. To calculate the approximate cost, multiply the approximate number of image tokens by the [per-token price of the model](https://claude.com/pricing) you’re using.&para;<br>&para;<br>If your image does not need to be resized, you can estimate the number of tokens used through this algorithm: `tokens = (width px * height px)/750`&para;<br>&para;<br>Here are examples of approximate tokenization and costs for different image sizes within </span><del style="background:#ffe6e6;">our</del><ins style="background:#e6ffe6;">the</ins><span> API's size constraints based on Claude Opus 4.6 per-token price of $3 per million input tokens:&para;<br>&para;<br>| Image size                    | \# of Tokens | Cost / image | Cost / 1K images |&para;<br>| ----------------------------- | ------------ | ------------ | ---------------- |&para;<br>| 200x200 px(0.04 megapixels)   | \~54         | \~$0.00016   | \~$0.16          |&para;<br>| 1000x1000 px(1 megapixel)     | \~1334       | \~$0.004     | \~$4.00          |&para;<br>| 1092x1092 px(1.19 megapixels) | \~1590       | \~$0.0048    | \~$4.80          |&para;<br>&para;<br>### Ensuring image quality&para;<br>&para;<br>When providing images to Claude, keep the following in mind for best results:&para;<br>&para;<br>- **Image format**: Use a supported image format: JPEG, PNG, GIF, or WebP.&para;<br>- **Image clarity**: Ensure images are clear and not too blurry or pixelated.&para;<br>- **Text**: If the image contains important text, make sure it’s legible and not too small. Avoid cropping out key visual context just to enlarge the text.&para;<br>&para;<br>---&para;<br>&para;<br>## Prompt examples&para;<br>&para;<br>Many of the [prompting techniques](/docs/en/build-with-claude/prompt-engineering/overview) that work well for text-based interactions with Claude can also be applied to image-based prompts.&para;<br>&para;<br>These examples demonstrate best practice prompt structures involving images.&para;<br>&para;<br>&lt;Tip&gt;&para;<br>  Just as with document-query placement, Claude works best when images come&para;<br>  before text. Images placed after text or interpolated with text will still&para;<br>  perform well, but if your use case allows it, </span><del style="background:#ffe6e6;">we recommend</del><ins style="background:#e6ffe6;">prefer</ins><span> an image-then-text&para;<br>  structure.&para;<br>&lt;/Tip&gt;&para;<br>&para;<br>### About the prompt examples&para;<br>&para;<br>The following examples demonstrate how to use Claude's vision capabilities using various programming languages and approaches. You can provide images to Claude in three ways:&para;<br>&para;<br>1. As a base64-encoded image in `image` content blocks&para;<br>2. As a URL reference to an image hosted online  &para;<br>3. Using the Files API (upload once, use multiple times)&para;<br>&para;<br>The base64 example prompts use these variables:&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>```bash Shell&para;<br>    # For URL-based images, you can use the URL directly in your JSON request&para;<br>    &para;<br>    # For base64-encoded images, you need to first encode the image&para;<br>    # Example of how to encode an image to base64 in bash:&para;<br>    BASE64_IMAGE_DATA=$(curl -s "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg" | base64)&para;<br>    &para;<br>    # The encoded data can now be used in your API calls&para;<br>```&para;<br>&para;<br>```python Python&para;<br>import base64&para;<br>import httpx&para;<br>&para;<br># For base64-encoded images&para;<br>image1_url = "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg"&para;<br>image1_media_type = "image/jpeg"&para;<br>image1_data = base64.standard_b64encode(httpx.get(image1_url).content).decode("utf-8")&para;<br>&para;<br>image2_url = "https://upload.wikimedia.org/wikipedia/commons/b/b5/Iridescent.green.sweat.bee1.jpg"&para;<br>image2_media_type = "image/jpeg"&para;<br>image2_data = base64.standard_b64encode(httpx.get(image2_url).content).decode("utf-8")&para;<br>&para;<br># For URL-based images, you can use the URLs directly in your requests&para;<br>```&para;<br>&para;<br>```typescript TypeScript&para;<br>import axios from 'axios';&para;<br>&para;<br>// For base64-encoded images&para;<br>async function getBase64Image(url: string): Promise&lt;string&gt; {&para;<br>  const response = await axios.get(url, { responseType: 'arraybuffer' });&para;<br>  return Buffer.from(response.data, 'binary').toString('base64');&para;<br>}&para;<br>&para;<br>// Usage&para;<br>async function prepareImages() {&para;<br>  const imageData = await getBase64Image('https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg');&para;<br>  // Now you can use imageData in your API calls&para;<br>}&para;<br>&para;<br>// For URL-based images, you can use the URLs directly in your requests&para;<br>```&para;<br>&para;<br>```java Java&para;<br>import java.io.IOException;&para;<br>import java.util.Base64;&para;<br>import java.io.InputStream;&para;<br>import java.net.URL;&para;<br>&para;<br>public class ImageHandlingExample {&para;<br>&para;<br>    public static void main(String[] args) throws IOException, InterruptedException {&para;<br>        // For base64-encoded images&para;<br>        String image1Url = "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg";&para;<br>        String image1MediaType = "image/jpeg";&para;<br>        String image1Data = downloadAndEncodeImage(image1Url);&para;<br>&para;<br>        String image2Url = "https://upload.wikimedia.org/wikipedia/commons/b/b5/Iridescent.green.sweat.bee1.jpg";&para;<br>        String image2MediaType = "image/jpeg";&para;<br>        String image2Data = downloadAndEncodeImage(image2Url);&para;<br>&para;<br>        // For URL-based images, you can use the URLs directly in your requests&para;<br>    }&para;<br>&para;<br>    private static String downloadAndEncodeImage(String imageUrl) throws IOException {&para;<br>        try (InputStream inputStream = new URL(imageUrl).openStream()) {&para;<br>            return Base64.getEncoder().encodeToString(inputStream.readAllBytes());&para;<br>        }&para;<br>    }&para;<br>&para;<br>}&para;<br>```</span><ins style="background:#e6ffe6;">&para;<br>&para;<br>```go Go&para;<br>package main&para;<br>&para;<br>import (&para;<br>    "encoding/base64"&para;<br>    "io"&para;<br>    "net/http"&para;<br>)&para;<br>&para;<br>func downloadAndEncodeImage(url string) (string, error) {&para;<br>    resp, err := http.Get(url)&para;<br>    if err != nil {&para;<br>        return "", err&para;<br>    }&para;<br>    defer resp.Body.Close()&para;<br>&para;<br>    data, err := io.ReadAll(resp.Body)&para;<br>    if err != nil {&para;<br>        return "", err&para;<br>    }&para;<br>&para;<br>    return base64.StdEncoding.EncodeToString(data), nil&para;<br>}&para;<br>&para;<br>// Usage:&para;<br>// imageData, _ := downloadAndEncodeImage("https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg")&para;<br>// For URL-based images, you can use the URLs directly in your requests&para;<br>```&para;<br>&para;<br>```ruby Ruby&para;<br>require "base64"&para;<br>require "net/http"&para;<br>require "uri"&para;<br>&para;<br># For base64-encoded images&para;<br>def download_and_encode_image(url)&para;<br>  uri = URI.parse(url)&para;<br>  response = Net::HTTP.get_response(uri)&para;<br>  Base64.strict_encode64(response.body)&para;<br>end&para;<br>&para;<br>image1_url = "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg"&para;<br>image1_media_type = "image/jpeg"&para;<br>image1_data = download_and_encode_image(image1_url)&para;<br>&para;<br># For URL-based images, you can use the URLs directly in your requests&para;<br>```&para;<br>&para;<br>```csharp C#&para;<br>using System;&para;<br>using System.Net.Http;&para;<br>using System.Threading.Tasks;&para;<br>&para;<br>// For base64-encoded images&para;<br>async Task&lt;string&gt; DownloadAndEncodeImageAsync(string url)&para;<br>{&para;<br>    using var client = new HttpClient();&para;<br>    var bytes = await client.GetByteArrayAsync(url);&para;<br>    return Convert.ToBase64String(bytes);&para;<br>}&para;<br>&para;<br>// Usage:&para;<br>// var imageData = await DownloadAndEncodeImageAsync("https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg");&para;<br>// For URL-based images, you can use the URLs directly in your requests&para;<br>```&para;<br>&para;<br>```php PHP&para;<br>&lt;?php&para;<br>// For base64-encoded images&para;<br>function downloadAndEncodeImage($url) {&para;<br>    $imageData = file_get_contents($url);&para;<br>    return base64_encode($imageData);&para;<br>}&para;<br>&para;<br>$image1Url = "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg";&para;<br>$image1MediaType = "image/jpeg";&para;<br>$image1Data = downloadAndEncodeImage($image1Url);&para;<br>&para;<br>// For URL-based images, you can use the URLs directly in your requests&para;<br>```</ins><span>&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>Below are examples of how to include images in a Messages API request using base64-encoded images and URL references:&para;<br>&para;<br>### Base64-encoded image example&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>    ```bash Shell&para;<br>    curl https://api.anthropic.com/v1/messages \&para;<br>      -H "x-api-key: $ANTHROPIC_API_KEY" \&para;<br>      -H "anthropic-version: 2023-06-01" \&para;<br>      -H "content-type: application/json" \&para;<br>      -d '{&para;<br>        "model": "claude-opus-4-6",&para;<br>        "max_tokens": 1024,&para;<br>        "messages": [&para;<br>          {&para;<br>            "role": "user",&para;<br>            "content": [&para;<br>              {&para;<br>                "type": "image",&para;<br>                "source": {&para;<br>                  "type": "base64",&para;<br>                  "media_type": "image/jpeg",&para;<br>                  "data": "'"$BASE64_IMAGE_DATA"'"&para;<br>                }&para;<br>              },&para;<br>              {&para;<br>                "type": "text",&para;<br>                "text": "Describe this image."&para;<br>              }&para;<br>            ]&para;<br>          }&para;<br>        ]&para;<br>      }'&para;<br>    ```&para;<br>    ```python Python&para;<br>    import anthropic&para;<br>&para;<br>    client = anthropic.Anthropic()&para;<br>    message = client.messages.create(&para;<br>        model="claude-opus-4-6",&para;<br>        max_tokens=1024,&para;<br>        messages=[&para;<br>            {&para;<br>                "role": "user",&para;<br>                "content": [&para;<br>                    {&para;<br>                        "type": "image",&para;<br>                        "source": {&para;<br>                            "type": "base64",&para;<br>                            "media_type": image1_media_type,&para;<br>                            "data": image1_data,&para;<br>                        },&para;<br>                    },&para;<br>                    {&para;<br>                        "type": "text",&para;<br>                        "text": "Describe this image."&para;<br>                    }&para;<br>                ],&para;<br>            }&para;<br>        ],&para;<br>    )&para;<br>    print(message)&para;<br>    ```&para;<br>    ```typescript TypeScript&para;<br>    import Anthropic from '@anthropic-ai/sdk';&para;<br>&para;<br>    const anthropic = new Anthropic({&para;<br>      apiKey: process.env.ANTHROPIC_API_KEY,&para;<br>    });&para;<br>&para;<br>    async function main() {&para;<br>      const message = await anthropic.messages.create({&para;<br>        model: "claude-opus-4-6",&para;<br>        max_tokens: 1024,&para;<br>        messages: [&para;<br>          {&para;<br>            role: "user",&para;<br>            content: [&para;<br>              {&para;<br>                type: "image",&para;<br>                source: {&para;<br>                  type: "base64",&para;<br>                  media_type: "image/jpeg",&para;<br>                  data: imageData, // Base64-encoded image data as string&para;<br>                }&para;<br>              },&para;<br>              {&para;<br>                type: "text",&para;<br>                text: "Describe this image."&para;<br>              }&para;<br>            ]&para;<br>          }&para;<br>        ]&para;<br>      });&para;<br>      &para;<br>      console.log(message);&para;<br>    }&para;<br>&para;<br>    main();&para;<br>    ```&para;<br>&para;<br>    ```java Java&para;<br>    import java.io.IOException;&para;<br>    import java.util.List;&para;<br>&para;<br>    import com.anthropic.client.AnthropicClient;&para;<br>    import com.anthropic.client.okhttp.AnthropicOkHttpClient;&para;<br>    import com.anthropic.models.messages.*;&para;<br>&para;<br>    public class VisionExample {&para;<br>        public static void main(String[] args) throws IOException, InterruptedException {&para;<br>            AnthropicClient client = AnthropicOkHttpClient.fromEnv();&para;<br>            String imageData = ""; // // Base64-encoded image data as string&para;<br>&para;<br>            List&lt;ContentBlockParam&gt; contentBlockParams = List.of(&para;<br>                    ContentBlockParam.ofImage(&para;<br>                            ImageBlockParam.builder()&para;<br>                                    .source(Base64ImageSource.builder()&para;<br>                                            .data(imageData)&para;<br>                                            .build())&para;<br>                                    .build()&para;<br>                    ),&para;<br>                    ContentBlockParam.ofText(TextBlockParam.builder()&para;<br>                            .text("Describe this image.")&para;<br>                            .build())&para;<br>            );&para;<br>            Message message = client.messages().create(&para;<br>                    MessageCreateParams.builder()&para;<br>                            .model(Model.CLAUDE_</span><del style="background:#ffe6e6;">SONNET_4_5_LATEST</del><ins style="background:#e6ffe6;">OPUS_4_6</ins><span>)&para;<br>                            .maxTokens(1024)&para;<br>                            .addUserMessageOfBlockParams(contentBlockParams)&para;<br>                            .build()&para;<br>            );&para;<br>&para;<br>            System.out.println(message);&para;<br>        }&para;<br>    }&para;<br>    ```&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>### URL-based image example&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>    ```bash Shell&para;<br>    curl https://api.anthropic.com/v1/messages \&para;<br>      -H "x-api-key: $ANTHROPIC_API_KEY" \&para;<br>      -H "anthropic-version: 2023-06-01" \&para;<br>      -H "content-type: application/json" \&para;<br>      -d '{&para;<br>        "model": "claude-opus-4-6",&para;<br>        "max_tokens": 1024,&para;<br>        "messages": [&para;<br>          {&para;<br>            "role": "user",&para;<br>            "content": [&para;<br>              {&para;<br>                "type": "image",&para;<br>                "source": {&para;<br>                  "type": "url",&para;<br>                  "url": "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg"&para;<br>                }&para;<br>              },&para;<br>              {&para;<br>                "type": "text",&para;<br>                "text": "Describe this image."&para;<br>              }&para;<br>            ]&para;<br>          }&para;<br>        ]&para;<br>      }'&para;<br>    ```&para;<br>    ```python Python&para;<br>    import anthropic&para;<br>&para;<br>    client = anthropic.Anthropic()&para;<br>    message = client.messages.create(&para;<br>        model="claude-opus-4-6",&para;<br>        max_tokens=1024,&para;<br>        messages=[&para;<br>            {&para;<br>                "role": "user",&para;<br>                "content": [&para;<br>                    {&para;<br>                        "type": "image",&para;<br>                        "source": {&para;<br>                            "type": "url",&para;<br>                            "url": "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg",&para;<br>                        },&para;<br>                    },&para;<br>                    {&para;<br>                        "type": "text",&para;<br>                        "text": "Describe this image."&para;<br>                    }&para;<br>                ],&para;<br>            }&para;<br>        ],&para;<br>    )&para;<br>    print(message)&para;<br>    ```&para;<br>    ```typescript TypeScript&para;<br>    import Anthropic from '@anthropic-ai/sdk';&para;<br>&para;<br>    const anthropic = new Anthropic({&para;<br>      apiKey: process.env.ANTHROPIC_API_KEY,&para;<br>    });&para;<br>&para;<br>    async function main() {&para;<br>      const message = await anthropic.messages.create({&para;<br>        model: "claude-opus-4-6",&para;<br>        max_tokens: 1024,&para;<br>        messages: [&para;<br>          {&para;<br>            role: "user",&para;<br>            content: [&para;<br>              {&para;<br>                type: "image",&para;<br>                source: {&para;<br>                  type: "url",&para;<br>                  url: "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg"&para;<br>                }&para;<br>              },&para;<br>              {&para;<br>                type: "text",&para;<br>                text: "Describe this image."&para;<br>              }&para;<br>            ]&para;<br>          }&para;<br>        ]&para;<br>      });&para;<br>      &para;<br>      console.log(message);&para;<br>    }&para;<br>&para;<br>    main();&para;<br>    ```&para;<br>    ```java Java&para;<br>    import java.io.IOException;&para;<br>    import java.util.List;&para;<br>&para;<br>    import com.anthropic.client.AnthropicClient;&para;<br>    import com.anthropic.client.okhttp.AnthropicOkHttpClient;&para;<br>    import com.anthropic.models.messages.*;&para;<br>&para;<br>    public class VisionExample {&para;<br>&para;<br>        public static void main(String[] args) throws IOException, InterruptedException {&para;<br>            AnthropicClient client = AnthropicOkHttpClient.fromEnv();&para;<br>&para;<br>            List&lt;ContentBlockParam&gt; contentBlockParams = List.of(&para;<br>                    ContentBlockParam.ofImage(&para;<br>                            ImageBlockParam.builder()&para;<br>                                    .source(UrlImageSource.builder()&para;<br>                                            .url("https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg")&para;<br>                                            .build())&para;<br>                                    .build()&para;<br>                    ),&para;<br>                    ContentBlockParam.ofText(TextBlockParam.builder()&para;<br>                            .text("Describe this image.")&para;<br>                            .build())&para;<br>            );&para;<br>            Message message = client.messages().create(&para;<br>                    MessageCreateParams.builder()&para;<br>                            .model(Model.CLAUDE_</span><del style="background:#ffe6e6;">SONNET_4_5_LATEST</del><ins style="background:#e6ffe6;">OPUS_4_6</ins><span>)&para;<br>                            .maxTokens(1024)&para;<br>                            .addUserMessageOfBlockParams(contentBlockParams)&para;<br>                            .build()&para;<br>            );&para;<br>            System.out.println(message);&para;<br>        }&para;<br>    }&para;<br>    ```&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>### Files API image example&para;<br>&para;<br>For images you'll use repeatedly or when you want to avoid encoding overhead, use the [Files API](/docs/en/build-with-claude/files):&para;<br>&para;<br>&lt;CodeGroup&gt;&para;<br>```bash Shell&para;<br># First, upload your image to the Files API&para;<br>curl -X POST https://api.anthropic.com/v1/files \&para;<br>  -H "x-api-key: $ANTHROPIC_API_KEY" \&para;<br>  -H "anthropic-version: 2023-06-01" \&para;<br>  -H "anthropic-beta: files-api-2025-04-14" \&para;<br>  -F "file=@image.jpg"&para;<br>&para;<br># Then use the returned file_id in your message&para;<br>curl https://api.anthropic.com/v1/messages \&para;<br>  -H "x-api-key: $ANTHROPIC_API_KEY" \&para;<br>  -H "anthropic-version: 2023-06-01" \&para;<br>  -H "anthropic-beta: files-api-2025-04-14" \&para;<br>  -H "content-type: application/json" \&para;<br>  -d '{&para;<br>    "model": "claude-opus-4-6",&para;<br>    "max_tokens": 1024,&para;<br>    "messages": [&para;<br>      {&para;<br>        "role": "user",&para;<br>        "content": [&para;<br>          {&para;<br>            "type": "image",&para;<br>            "source": {&para;<br>              "type": "file",&para;<br>              "file_id": "file_abc123"&para;<br>            }&para;<br>          },&para;<br>          {&para;<br>            "type": "text",&para;<br>            "text": "Describe this image."&para;<br>          }&para;<br>        ]&para;<br>      }&para;<br>    ]&para;<br>  }'&para;<br>```&para;<br>&para;<br>```python Python&para;<br>import anthropic&para;<br>&para;<br>client = anthropic.Anthropic()&para;<br>&para;<br># Upload the image file&para;<br>with open("image.jpg", "rb") as f:&para;<br>    file_upload = client.beta.files.upload(file=("image.jpg", f, "image/jpeg"))&para;<br>&para;<br># Use the uploaded file in a message&para;<br>message = client.beta.messages.create(&para;<br>    model="claude-opus-4-6",&para;<br>    max_tokens=1024,&para;<br>    betas=["files-api-2025-04-14"],&para;<br>    messages=[&para;<br>        {&para;<br>            "role": "user",&para;<br>            "content": [&para;<br>                {&para;<br>                    "type": "image",&para;<br>                    "source": {&para;<br>                        "type": "file",&para;<br>                        "file_id": file_upload.id&para;<br>                    }&para;<br>                },&para;<br>                {&para;<br>                    "type": "text",&para;<br>                    "text": "Describe this image."&para;<br>                }&para;<br>            ]&para;<br>        }&para;<br>    ],&para;<br>)&para;<br>&para;<br>print(message.content)&para;<br>```&para;<br>&para;<br>```typescript TypeScript&para;<br>import { Anthropic, toFile } from '@anthropic-ai/sdk';&para;<br>import fs from 'fs';&para;<br>&para;<br>const anthropic = new Anthropic();&para;<br>&para;<br>async function main() {&para;<br>  // Upload the image file&para;<br>  const fileUpload = await anthropic.beta.files.upload({&para;<br>    file: toFile(fs.createReadStream('image.jpg'), undefined, { type: "image/jpeg" })&para;<br>  }, {&para;<br>    betas: ['files-api-2025-04-14']&para;<br>  });&para;<br>&para;<br>  // Use the uploaded file in a message&para;<br>  const response = await anthropic.beta.messages.create({&para;<br>    model: 'claude-opus-4-6',&para;<br>    max_tokens: 1024,&para;<br>    betas: ['files-api-2025-04-14'],&para;<br>    messages: [&para;<br>      {&para;<br>        role: 'user',&para;<br>        content: [&para;<br>          {&para;<br>            type: 'image',&para;<br>            source: {&para;<br>              type: 'file',&para;<br>              file_id: fileUpload.id&para;<br>            }&para;<br>          },&para;<br>          {&para;<br>            type: 'text',&para;<br>            text: 'Describe this image.'&para;<br>          }&para;<br>        ]&para;<br>      }&para;<br>    ]&para;<br>  });&para;<br>&para;<br>  console.log(response);&para;<br>}&para;<br>&para;<br>main();&para;<br>```&para;<br>&para;<br>```java Java&para;<br>import java.io.IOException;&para;<br>import java.nio.file.Files;&para;<br>import java.nio.file.Path;&para;<br>import java.util.List;&para;<br>&para;<br>import com.anthropic.client.AnthropicClient;&para;<br>import com.anthropic.client.okhttp.AnthropicOkHttpClient;&para;<br>import com.anthropic.models.File;&para;<br>import com.anthropic.models.files.FileUploadParams;&para;<br>import com.anthropic.models.messages.*;&para;<br>&para;<br>public class ImageFilesExample {&para;<br>    public static void main(String[] args) throws IOException {&para;<br>        AnthropicClient client = AnthropicOkHttpClient.fromEnv();&para;<br>&para;<br>        // Upload the image file&para;<br>        File file = client.beta().files().upload(FileUploadParams.builder()&para;<br>                .file(Files.newInputStream(Path.of("image.jpg")))&para;<br>                .build());&para;<br>&para;<br>        // Use the uploaded file in a message&para;<br>        ImageBlockParam imageParam = ImageBlockParam.builder()&para;<br>                .fileSource(file.id())&para;<br>                .build();&para;<br>&para;<br>        MessageCreateParams params = MessageCreateParams.builder()&para;<br>                .model(Model.CLAUDE_</span><del style="background:#ffe6e6;">SONNET_4_5_LATEST</del><ins style="background:#e6ffe6;">OPUS_4_6</ins><span>)&para;<br>                .maxTokens(1024)&para;<br>                .addUserMessageOfBlockParams(&para;<br>                        List.of(&para;<br>                                ContentBlockParam.ofImage(imageParam),&para;<br>                                ContentBlockParam.ofText(&para;<br>                                        TextBlockParam.builder()&para;<br>                                                .text("Describe this image.")&para;<br>                                                .build()&para;<br>                                )&para;<br>                        )&para;<br>                )&para;<br>                .build();&para;<br>&para;<br>        Message message = client.messages().create(params);&para;<br>        System.out.println(message.content());&para;<br>    }&para;<br>}&para;<br>```&para;<br>&lt;/CodeGroup&gt;&para;<br>&para;<br>See [Messages API examples](/docs/en/api/messages) for more example code and parameter details.&para;<br>&para;<br>&lt;section title="Example: One image"&gt;&para;<br>&para;<br>It’s best to place images earlier in the prompt than questions about them or instructions for tasks that use them.&para;<br>&para;<br>Ask Claude to describe one image.&para;<br>&para;<br>| Role | Content                        |&para;<br>| ---- | ------------------------------ |&para;<br>| User | \[Image\] Describe this image. |&para;<br>&para;<br>&lt;Tabs&gt;&para;<br>  &lt;Tab title="Using Base64"&gt;&para;<br>    ```python Python&para;<br>    message = client.messages.create(&para;<br>        model="claude-opus-4-6",&para;<br>        max_tokens=1024,&para;<br>        messages=[&para;<br>            {&para;<br>                "role": "user",&para;<br>                "content": [&para;<br>                    {&para;<br>                        "type": "image",&para;<br>                        "source": {&para;<br>                            "type": "base64",&para;<br>                            "media_type": image1_media_type,&para;<br>                            "data": image1_data,&para;<br>                        },&para;<br>                    },&para;<br>                    {&para;<br>                        "type": "text",&para;<br>                        "text": "Describe this image."&para;<br>                    }&para;<br>                ],&para;<br>            }&para;<br>        ],&para;<br>    )&para;<br>    ```&para;<br>  &lt;/Tab&gt;&para;<br>  &lt;Tab title="Using URL"&gt;&para;<br>    ```python Python&para;<br>    message = client.messages.create(&para;<br>        model="claude-opus-4-6",&para;<br>        max_tokens=1024,&para;<br>        messages=[&para;<br>            {&para;<br>                "role": "user",&para;<br>                "content": [&para;<br>                    {&para;<br>                        "type": "image",&para;<br>                        "source": {&para;<br>                            "type": "url",&para;<br>                            "url": "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg",&para;<br>                        },&para;<br>                    },&para;<br>                    {&para;<br>                        "type": "text",&para;<br>                        "text": "Describe this image."&para;<br>                    }&para;<br>                ],&para;<br>            }&para;<br>        ],&para;<br>    )&para;<br>    ```&para;<br>  &lt;/Tab&gt;&para;<br>&lt;/Tabs&gt;&para;<br>&para;<br>&lt;/section&gt;&para;<br>&lt;section title="Example: Multiple images"&gt;&para;<br>&para;<br>In situations where there are multiple images, introduce each image with `Image 1:` and `Image 2:` and so on. You don’t need newlines between images or between images and the prompt.&para;<br>&para;<br>Ask Claude to describe the differences between multiple images.&para;<br>| Role | Content |&para;<br>| ---- | ------------------------------------------------------------------------- |&para;<br>| User | Image 1: \[Image 1\] Image 2: \[Image 2\] How are these images different? |&para;<br>&para;<br>&lt;Tabs&gt;&para;<br>  &lt;Tab title="Using Base64"&gt;&para;<br>    ```python Python&para;<br>    message = client.messages.create(&para;<br>        model="claude-opus-4-6",&para;<br>        max_tokens=1024,&para;<br>        messages=[&para;<br>            {&para;<br>                "role": "user",&para;<br>                "content": [&para;<br>                    {&para;<br>                        "type": "text",&para;<br>                        "text": "Image 1:"&para;<br>                    },&para;<br>                    {&para;<br>                        "type": "image",&para;<br>                        "source": {&para;<br>                            "type": "base64",&para;<br>                            "media_type": image1_media_type,&para;<br>                            "data": image1_data,&para;<br>                        },&para;<br>                    },&para;<br>                    {&para;<br>                        "type": "text",&para;<br>                        "text": "Image 2:"&para;<br>                    },&para;<br>                    {&para;<br>                        "type": "image",&para;<br>                        "source": {&para;<br>                            "type": "base64",&para;<br>                            "media_type": image2_media_type,&para;<br>                            "data": image2_data,&para;<br>                        },&para;<br>                    },&para;<br>                    {&para;<br>                        "type": "text",&para;<br>                        "text": "How are these images different?"&para;<br>                    }&para;<br>                ],&para;<br>            }&para;<br>        ],&para;<br>    )&para;<br>    ```&para;<br>  &lt;/Tab&gt;&para;<br>  &lt;Tab title="Using URL"&gt;&para;<br>    ```python Python&para;<br>    message = client.messages.create(&para;<br>        model="claude-opus-4-6",&para;<br>        max_tokens=1024,&para;<br>        messages=[&para;<br>            {&para;<br>                "role": "user",&para;<br>                "content": [&para;<br>                    {&para;<br>                        "type": "text",&para;<br>                        "text": "Image 1:"&para;<br>                    },&para;<br>                    {&para;<br>                        "type": "image",&para;<br>                        "source": {&para;<br>                            "type": "url",&para;<br>                            "url": "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg",&para;<br>                        },&para;<br>                    },&para;<br>                    {&para;<br>                        "type": "text",&para;<br>                        "text": "Image 2:"&para;<br>                    },&para;<br>                    {&para;<br>                        "type": "image",&para;<br>                        "source": {&para;<br>                            "type": "url",&para;<br>                            "url": "https://upload.wikimedia.org/wikipedia/commons/b/b5/Iridescent.green.sweat.bee1.jpg",&para;<br>                        },&para;<br>                    },&para;<br>                    {&para;<br>                        "type": "text",&para;<br>                        "text": "How are these images different?"&para;<br>                    }&para;<br>                ],&para;<br>            }&para;<br>        ],&para;<br>    )&para;<br>    ```&para;<br>  &lt;/Tab&gt;&para;<br>&lt;/Tabs&gt;&para;<br>&para;<br>&lt;/section&gt;&para;<br>&lt;section title="Example: Multiple images with a system prompt"&gt;&para;<br>&para;<br>Ask Claude to describe the differences between multiple images, while giving it a system prompt for how to respond.&para;<br>&para;<br>| Content |                                                                           |&para;<br>| ------- | ------------------------------------------------------------------------- |&para;<br>| System  | Respond only in Spanish.                                                  |&para;<br>| User    | Image 1: \[Image 1\] Image 2: \[Image 2\] How are these images different? |&para;<br>&para;<br>&lt;Tabs&gt;&para;<br>  &lt;Tab title="Using Base64"&gt;&para;<br>    ```python Python&para;<br>    message = client.messages.create(&para;<br>        model="claude-opus-4-6",&para;<br>        max_tokens=1024,&para;<br>        system="Respond only in Spanish.",&para;<br>        messages=[&para;<br>            {&para;<br>                "role": "user",&para;<br>                "content": [&para;<br>                    {&para;<br>                        "type": "text",&para;<br>                        "text": "Image 1:"&para;<br>                    },&para;<br>                    {&para;<br>                        "type": "image",&para;<br>                        "source": {&para;<br>                            "type": "base64",&para;<br>                            "media_type": image1_media_type,&para;<br>                            "data": image1_data,&para;<br>                        },&para;<br>                    },&para;<br>                    {&para;<br>                        "type": "text",&para;<br>                        "text": "Image 2:"&para;<br>                    },&para;<br>                    {&para;<br>                        "type": "image",&para;<br>                        "source": {&para;<br>                            "type": "base64",&para;<br>                            "media_type": image2_media_type,&para;<br>                            "data": image2_data,&para;<br>                        },&para;<br>                    },&para;<br>                    {&para;<br>                        "type": "text",&para;<br>                        "text": "How are these images different?"&para;<br>                    }&para;<br>                ],&para;<br>            }&para;<br>        ],&para;<br>    )&para;<br>    ```&para;<br>  &lt;/Tab&gt;&para;<br>  &lt;Tab title="Using URL"&gt;&para;<br>    ```python Python&para;<br>    message = client.messages.create(&para;<br>        model="claude-opus-4-6",&para;<br>        max_tokens=1024,&para;<br>        system="Respond only in Spanish.",&para;<br>        messages=[&para;<br>            {&para;<br>                "role": "user",&para;<br>                "content": [&para;<br>                    {&para;<br>                        "type": "text",&para;<br>                        "text": "Image 1:"&para;<br>                    },&para;<br>                    {&para;<br>                        "type": "image",&para;<br>                        "source": {&para;<br>                            "type": "url",&para;<br>                            "url": "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg",&para;<br>                        },&para;<br>                    },&para;<br>                    {&para;<br>                        "type": "text",&para;<br>                        "text": "Image 2:"&para;<br>                    },&para;<br>                    {&para;<br>                        "type": "image",&para;<br>                        "source": {&para;<br>                            "type": "url",&para;<br>                            "url": "https://upload.wikimedia.org/wikipedia/commons/b/b5/Iridescent.green.sweat.bee1.jpg",&para;<br>                        },&para;<br>                    },&para;<br>                    {&para;<br>                        "type": "text",&para;<br>                        "text": "How are these images different?"&para;<br>                    }&para;<br>                ],&para;<br>            }&para;<br>        ],&para;<br>    )&para;<br>    ```&para;<br>  &lt;/Tab&gt;&para;<br>&lt;/Tabs&gt;&para;<br>&para;<br>&lt;/section&gt;&para;<br>&lt;section title="Example: Four images across two conversation turns"&gt;&para;<br>&para;<br>Claude’s vision capabilities shine in multimodal conversations that mix images and text. You can have extended back-and-forth exchanges with Claude, adding new images or follow-up questions at any point. This enables powerful workflows for iterative image analysis, comparison, or combining visuals with other knowledge.&para;<br>&para;<br>Ask Claude to contrast two images, then ask a follow-up question comparing the first images to two new images.&para;<br>| Role | Content |&para;<br>| --------- | ------------------------------------------------------------------------------------ |&para;<br>| User | Image 1: \[Image 1\] Image 2: \[Image 2\] How are these images different? |&para;<br>| Assistant | \[Claude's response\] |&para;<br>| User | Image 1: \[Image 3\] Image 2: \[Image 4\] Are these images similar to the first two? |&para;<br>| Assistant | \[Claude's response\] |&para;<br>&para;<br>When using the API, simply insert new images into the array of Messages in the `user` role as part of any standard [multiturn conversation](/docs/en/api/messages) structure.&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>---&para;<br>&para;<br>## Limitations&para;<br>&para;<br>While Claude's image understanding capabilities are cutting-edge, there are some limitations to be aware of:&para;<br>&para;<br>- **People identification**: Claude [cannot be used](https://www.anthropic.com/legal/aup) to identify (i.e., name) people in images and will refuse to do so.&para;<br>- **Accuracy**: Claude may hallucinate or make mistakes when interpreting low-quality, rotated, or very small images under 200 pixels.&para;<br>- **Spatial reasoning**: Claude's spatial reasoning abilities are limited. It may struggle with tasks requiring precise localization or layouts, like reading an analog clock face or describing exact positions of chess pieces.&para;<br>- **Counting**: Claude can give approximate counts of objects in an image but may not always be precisely accurate, especially with large numbers of small objects.&para;<br>- **AI generated images**: Claude does not know if an image is AI-generated and may be incorrect if asked. Do not rely on it to detect fake or synthetic images.&para;<br>- **Inappropriate content**: Claude will not process inappropriate or explicit images that violate </span><del style="background:#ffe6e6;">our</del><ins style="background:#e6ffe6;">the</ins><span> [Acceptable Use Policy](https://www.anthropic.com/legal/aup).&para;<br>- **Healthcare applications**: While Claude can analyze general medical images, it is not designed to interpret complex diagnostic scans such as CTs or MRIs. Claude's outputs should not be considered a substitute for professional medical advice or diagnosis.&para;<br>&para;<br>Always carefully review and verify Claude's image interpretations, especially for high-stakes use cases. Do not use Claude for tasks requiring perfect precision or sensitive image analysis without human oversight.&para;<br>&para;<br>---&para;<br>&para;<br>## FAQ&para;<br>&para;<br>  &lt;section title="What image file types does Claude support?"&gt;&para;<br>&para;<br>    Claude currently supports JPEG, PNG, GIF, and WebP image formats, specifically:&para;<br>    - `image/jpeg`&para;<br>    - `image/png`&para;<br>    - `image/gif`&para;<br>    - `image/webp`&para;<br>  &para;<br>&lt;/section&gt;&para;<br>&para;<br>{" "}&para;<br>&para;<br>&lt;section title="Can Claude read image URLs?"&gt;&para;<br>&para;<br>  Yes, Claude can </span><del style="background:#ffe6e6;">now </del><span>process images from URLs with </span><del style="background:#ffe6e6;">our </del><span>URL image source blocks in the API.&para;<br>  Simply use the "url" source type instead of "base64" in your API requests. &para;<br>  Example:&para;<br>  ```json&para;<br>  {&para;<br>    "type": "image",&para;<br>    "source": {&para;<br>      "type": "url",&para;<br>      "url": "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg"&para;<br>    }&para;<br>  }&para;<br>  ```&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>  &lt;section title="Is there a limit to the image file size I can upload?"&gt;&para;<br>&para;<br>    Yes, there are limits:&para;<br>    - API: Maximum 5MB per image&para;<br>    - claude.ai: Maximum 10MB per image&para;<br>&para;<br>    Images larger than these limits will be rejected and return an error when using </span><del style="background:#ffe6e6;">our</del><ins style="background:#e6ffe6;">the</ins><span> API.&para;<br>&para;<br>  &para;<br>&lt;/section&gt;&para;<br>&para;<br>  &lt;section title="How many images can I include in one request?"&gt;&para;<br>&para;<br>    The image limits are:&para;<br>    - Messages API: Up to 100 images per request&para;<br>    - claude.ai: Up to 20 images per turn&para;<br>&para;<br>    Requests exceeding these limits will be rejected and return an error.&para;<br>&para;<br>  &para;<br>&lt;/section&gt;&para;<br>&para;<br>{" "}&para;<br>&para;<br>&lt;section title="Does Claude read image metadata?"&gt;&para;<br>&para;<br>  No, Claude does not parse or receive any metadata from images passed to it.&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>{" "}&para;<br>&para;<br>&lt;section title="Can I delete images I've uploaded?"&gt;&para;<br>&para;<br>  No. Image uploads are ephemeral and not stored beyond the duration of the API&para;<br>  request. Uploaded images are automatically deleted after they have been&para;<br>  processed.&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>{" "}&para;<br>&para;<br>&lt;section title="Where can I find details on data privacy for image uploads?"&gt;&para;<br>&para;<br>  </span><del style="background:#ffe6e6;">Please refer to our</del><ins style="background:#e6ffe6;">Refer to the Anthropic</ins><span> privacy policy page for information on how </span><del style="background:#ffe6e6;">we handle&para;<br>  </del><span>uploaded</span><ins style="background:#e6ffe6;">&para;<br> </ins><span> images and other data</span><del style="background:#ffe6e6;">. We</del><ins style="background:#e6ffe6;"> are handled. Anthropic</ins><span> do</span><ins style="background:#e6ffe6;">es</ins><span> not use uploaded images to</span><ins style="background:#e6ffe6;">&para;<br> </ins><span> train </span><del style="background:#ffe6e6;">our&para;<br>  </del><span>models.&para;<br>&para;<br>&lt;/section&gt;&para;<br>&para;<br>  &lt;section title="What if Claude's image interpretation seems wrong?"&gt;&para;<br>&para;<br>    If Claude's image interpretation seems incorrect:&para;<br>    1. Ensure the image is clear, high-quality, and correctly oriented.&para;<br>    2. Try prompt engineering techniques to improve results.&para;<br>    3. If the issue persists, flag the output in claude.ai (thumbs up/down) or contact </span><del style="background:#ffe6e6;">our </del><ins style="background:#e6ffe6;">the [</ins><span>support team</span><ins style="background:#e6ffe6;">](https://support.claude.com/)</ins><span>.&para;<br>&para;<br>    Your feedback helps </span><del style="background:#ffe6e6;">us </del><span>improve</span><ins style="background:#e6ffe6;"> Claude</ins><span>!&para;<br>&para;<br>  &para;<br>&lt;/section&gt;&para;<br>&para;<br>  &lt;section title="Can Claude generate or edit images?"&gt;&para;<br>&para;<br>    No, Claude is an image understanding model only. It can interpret and analyze images, but it cannot generate, produce, edit, manipulate, or create images.&para;<br>  &para;<br>&lt;/section&gt;&para;<br>&para;<br>---&para;<br>&para;<br>## Dive deeper into vision&para;<br>&para;<br>Ready to start building with images using Claude? Here are a few helpful resources:&para;<br>&para;<br>- [Multimodal cookbook](https://platform.claude.com/cookbook/multimodal-getting-started-with-vision): This cookbook has tips on [getting started with images](https://platform.claude.com/cookbook/multimodal-getting-started-with-vision) and [best practice techniques](https://platform.claude.com/cookbook/multimodal-best-practices-for-vision) to ensure the highest quality performance with images. See how you can effectively prompt Claude with images to carry out tasks such as [interpreting and analyzing charts](https://platform.claude.com/cookbook/multimodal-reading-charts-graphs-powerpoints) or [extracting content from forms](https://platform.claude.com/cookbook/multimodal-how-to-transcribe-text).&para;<br>- [API reference](/docs/en/api/messages): </span><del style="background:#ffe6e6;">Visit our d</del><ins style="background:#e6ffe6;">D</ins><span>ocumentation for the Messages API, including example [API calls involving images](/docs/en/build-with-claude/working-with-messages#vision).&para;<br>&para;<br>If you have any other questions,</span><del style="background:#ffe6e6;"> feel free to</del><span> reach out to </span><del style="background:#ffe6e6;">our</del><ins style="background:#e6ffe6;">the</ins><span> [support team](https://support.claude.com/). You can also join </span><del style="background:#ffe6e6;">our</del><ins style="background:#e6ffe6;">the</ins><span> [developer community](https://www.anthropic.com/discord) to connect with other creators and get help from Anthropic experts.</span></div>
        </div>

        <h2 style="margin-top: 2rem; margin-bottom: 1rem;">Unified Diff</h2>
        <pre><code>--- a/build-with-claude/vision.md
+++ b/build-with-claude/vision.md
@@ -32,17 +32,17 @@
 
 ### Evaluate image size
 
-For optimal performance, we recommend resizing images before uploading if they are too large. If your image’s long edge is more than 1568 pixels, or your image is more than ~1,600 tokens, it will first be scaled down, preserving aspect ratio, until it’s within the size limits.
+For optimal performance, resize images before uploading if they are too large. If your image’s long edge is more than 1568 pixels, or your image is more than ~1,600 tokens, it will first be scaled down, preserving aspect ratio, until it’s within the size limits.
 
 If your input image is too large and needs to be resized, it will increase latency of [time-to-first-token](/docs/en/about-claude/glossary), without giving you any additional model performance. Very small images under 200 pixels on any given edge may degrade performance.
 
 &lt;Tip&gt;
-  To improve [time-to-first-token](/docs/en/about-claude/glossary), we recommend
+  To improve [time-to-first-token](/docs/en/about-claude/glossary), consider
   resizing images to no more than 1.15 megapixels (and within 1568 pixels in
   both dimensions).
 &lt;/Tip&gt;
 
-Here is a table of maximum image sizes accepted by our API that will not be resized for common aspect ratios. With Claude Opus 4.6, these images use approximately 1,600 tokens and around $4.80/1K images.
+Here is a table of maximum image sizes accepted by the API that will not be resized for common aspect ratios. With Claude Opus 4.6, these images use approximately 1,600 tokens and around $4.80/1K images.
 
 | Aspect ratio | Image size   |
 | ------------ | ------------ |
@@ -58,7 +58,7 @@
 
 If your image does not need to be resized, you can estimate the number of tokens used through this algorithm: `tokens = (width px * height px)/750`
 
-Here are examples of approximate tokenization and costs for different image sizes within our API&#39;s size constraints based on Claude Opus 4.6 per-token price of $3 per million input tokens:
+Here are examples of approximate tokenization and costs for different image sizes within the API&#39;s size constraints based on Claude Opus 4.6 per-token price of $3 per million input tokens:
 
 | Image size                    | \# of Tokens | Cost / image | Cost / 1K images |
 | ----------------------------- | ------------ | ------------ | ---------------- |
@@ -85,7 +85,7 @@
 &lt;Tip&gt;
   Just as with document-query placement, Claude works best when images come
   before text. Images placed after text or interpolated with text will still
-  perform well, but if your use case allows it, we recommend an image-then-text
+  perform well, but if your use case allows it, prefer an image-then-text
   structure.
 &lt;/Tip&gt;
 
@@ -172,6 +172,87 @@
     }
 
 }
+```
+
+```go Go
+package main
+
+import (
+    &#34;encoding/base64&#34;
+    &#34;io&#34;
+    &#34;net/http&#34;
+)
+
+func downloadAndEncodeImage(url string) (string, error) {
+    resp, err := http.Get(url)
+    if err != nil {
+        return &#34;&#34;, err
+    }
+    defer resp.Body.Close()
+
+    data, err := io.ReadAll(resp.Body)
+    if err != nil {
+        return &#34;&#34;, err
+    }
+
+    return base64.StdEncoding.EncodeToString(data), nil
+}
+
+// Usage:
+// imageData, _ := downloadAndEncodeImage(&#34;https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg&#34;)
+// For URL-based images, you can use the URLs directly in your requests
+```
+
+```ruby Ruby
+require &#34;base64&#34;
+require &#34;net/http&#34;
+require &#34;uri&#34;
+
+# For base64-encoded images
+def download_and_encode_image(url)
+  uri = URI.parse(url)
+  response = Net::HTTP.get_response(uri)
+  Base64.strict_encode64(response.body)
+end
+
+image1_url = &#34;https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg&#34;
+image1_media_type = &#34;image/jpeg&#34;
+image1_data = download_and_encode_image(image1_url)
+
+# For URL-based images, you can use the URLs directly in your requests
+```
+
+```csharp C#
+using System;
+using System.Net.Http;
+using System.Threading.Tasks;
+
+// For base64-encoded images
+async Task&lt;string&gt; DownloadAndEncodeImageAsync(string url)
+{
+    using var client = new HttpClient();
+    var bytes = await client.GetByteArrayAsync(url);
+    return Convert.ToBase64String(bytes);
+}
+
+// Usage:
+// var imageData = await DownloadAndEncodeImageAsync(&#34;https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg&#34;);
+// For URL-based images, you can use the URLs directly in your requests
+```
+
+```php PHP
+&lt;?php
+// For base64-encoded images
+function downloadAndEncodeImage($url) {
+    $imageData = file_get_contents($url);
+    return base64_encode($imageData);
+}
+
+$image1Url = &#34;https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg&#34;;
+$image1MediaType = &#34;image/jpeg&#34;;
+$image1Data = downloadAndEncodeImage($image1Url);
+
+// For URL-based images, you can use the URLs directly in your requests
 ```
 &lt;/CodeGroup&gt;
 
@@ -303,7 +384,7 @@
             );
             Message message = client.messages().create(
                     MessageCreateParams.builder()
-                            .model(Model.CLAUDE_SONNET_4_5_LATEST)
+                            .model(Model.CLAUDE_OPUS_4_6)
                             .maxTokens(1024)
                             .addUserMessageOfBlockParams(contentBlockParams)
                             .build()
@@ -437,7 +518,7 @@
             );
             Message message = client.messages().create(
                     MessageCreateParams.builder()
-                            .model(Model.CLAUDE_SONNET_4_5_LATEST)
+                            .model(Model.CLAUDE_OPUS_4_6)
                             .maxTokens(1024)
                             .addUserMessageOfBlockParams(contentBlockParams)
                             .build()
@@ -600,7 +681,7 @@
                 .build();
 
         MessageCreateParams params = MessageCreateParams.builder()
-                .model(Model.CLAUDE_SONNET_4_5_LATEST)
+                .model(Model.CLAUDE_OPUS_4_6)
                 .maxTokens(1024)
                 .addUserMessageOfBlockParams(
                         List.of(
@@ -913,7 +994,7 @@
 - **Spatial reasoning**: Claude&#39;s spatial reasoning abilities are limited. It may struggle with tasks requiring precise localization or layouts, like reading an analog clock face or describing exact positions of chess pieces.
 - **Counting**: Claude can give approximate counts of objects in an image but may not always be precisely accurate, especially with large numbers of small objects.
 - **AI generated images**: Claude does not know if an image is AI-generated and may be incorrect if asked. Do not rely on it to detect fake or synthetic images.
-- **Inappropriate content**: Claude will not process inappropriate or explicit images that violate our [Acceptable Use Policy](https://www.anthropic.com/legal/aup).
+- **Inappropriate content**: Claude will not process inappropriate or explicit images that violate the [Acceptable Use Policy](https://www.anthropic.com/legal/aup).
 - **Healthcare applications**: While Claude can analyze general medical images, it is not designed to interpret complex diagnostic scans such as CTs or MRIs. Claude&#39;s outputs should not be considered a substitute for professional medical advice or diagnosis.
 
 Always carefully review and verify Claude&#39;s image interpretations, especially for high-stakes use cases. Do not use Claude for tasks requiring perfect precision or sensitive image analysis without human oversight.
@@ -936,7 +1017,7 @@
 
 &lt;section title=&#34;Can Claude read image URLs?&#34;&gt;
 
-  Yes, Claude can now process images from URLs with our URL image source blocks in the API.
+  Yes, Claude can process images from URLs with URL image source blocks in the API.
   Simply use the &#34;url&#34; source type instead of &#34;base64&#34; in your API requests. 
   Example:
   ```json
@@ -957,7 +1038,7 @@
     - API: Maximum 5MB per image
     - claude.ai: Maximum 10MB per image
 
-    Images larger than these limits will be rejected and return an error when using our API.
+    Images larger than these limits will be rejected and return an error when using the API.
 
   
 &lt;/section&gt;
@@ -995,9 +1076,9 @@
 
 &lt;section title=&#34;Where can I find details on data privacy for image uploads?&#34;&gt;
 
-  Please refer to our privacy policy page for information on how we handle
-  uploaded images and other data. We do not use uploaded images to train our
-  models.
+  Refer to the Anthropic privacy policy page for information on how uploaded
+  images and other data are handled. Anthropic does not use uploaded images to
+  train models.
 
 &lt;/section&gt;
 
@@ -1006,9 +1087,9 @@
     If Claude&#39;s image interpretation seems incorrect:
     1. Ensure the image is clear, high-quality, and correctly oriented.
     2. Try prompt engineering techniques to improve results.
-    3. If the issue persists, flag the output in claude.ai (thumbs up/down) or contact our support team.
-
-    Your feedback helps us improve!
+    3. If the issue persists, flag the output in claude.ai (thumbs up/down) or contact the [support team](https://support.claude.com/).
+
+    Your feedback helps improve Claude!
 
   
 &lt;/section&gt;
@@ -1026,6 +1107,6 @@
 Ready to start building with images using Claude? Here are a few helpful resources:
 
 - [Multimodal cookbook](https://platform.claude.com/cookbook/multimodal-getting-started-with-vision): This cookbook has tips on [getting started with images](https://platform.claude.com/cookbook/multimodal-getting-started-with-vision) and [best practice techniques](https://platform.claude.com/cookbook/multimodal-best-practices-for-vision) to ensure the highest quality performance with images. See how you can effectively prompt Claude with images to carry out tasks such as [interpreting and analyzing charts](https://platform.claude.com/cookbook/multimodal-reading-charts-graphs-powerpoints) or [extracting content from forms](https://platform.claude.com/cookbook/multimodal-how-to-transcribe-text).
-- [API reference](/docs/en/api/messages): Visit our documentation for the Messages API, including example [API calls involving images](/docs/en/build-with-claude/working-with-messages#vision).
-
-If you have any other questions, feel free to reach out to our [support team](https://support.claude.com/). You can also join our [developer community](https://www.anthropic.com/discord) to connect with other creators and get help from Anthropic experts.+- [API reference](/docs/en/api/messages): Documentation for the Messages API, including example [API calls involving images](/docs/en/build-with-claude/working-with-messages#vision).
+
+If you have any other questions, reach out to the [support team](https://support.claude.com/). You can also join the [developer community](https://www.anthropic.com/discord) to connect with other creators and get help from Anthropic experts.</code></pre>
    </div>
</body>
</html>